\documentclass[../vs-script-first-v01.tex]{subfiles}
\graphicspath{{\subfix{../}}}
\begin{document}

\section{Koordination, Konsens und Fehler}

In der heutigen vernetzten Welt spielen verteilte Systeme eine entscheidende Rolle bei der Unterstützung von Anwendungen und Diensten, die von Unternehmen und Endbenutzern eingesetzt werden. Die Koordination in verteilten Systemen ist ein zentrales Thema, das es ermöglicht, die Funktionsweise dieser Systeme effektiv und effizient zu verwalten. In dieser Einführung werden wir uns auf die grundlegenden Prinzipien der Koordination konzentrieren.

Ein verteiltes System ist ein Netzwerk von autonomen Computern oder Knoten, die zusammenarbeiten, um einen gemeinsamen Zweck zu erfüllen. Diese Knoten kommunizieren über Nachrichten und teilen Ressourcen, um Aufgaben gemeinsam zu erledigen. Die Koordination in verteilten Systemen bezieht sich auf den Prozess, bei dem verschiedene Komponenten des Systems zusammenarbeiten und Informationen austauschen, um ein konsistentes und kohärentes Verhalten zu erreichen. Das wir das kohärente Verhalten durch die Erreichung der Transparenzeigenschaften erhalten können ist uns bekannt, wie wir den Begriff der Konsistenz zu verstehen haben ist noch zu diskutieren. 

Eine der Hauptanforderungen an die Koordination in verteilten Systemen ist die Synchronisation. Die Synchronisation bezieht sich auf die Notwendigkeit, die Aktivitäten der verschiedenen Knoten im System aufeinander abzustimmen, um korrekte und vorhersehbare Ergebnisse zu erzielen. Hierfür gibt es verschiedene Ansätze, beispielsweise der Einsatz von globalen Uhren, logischen Uhren oder Vektoruhren, um die Reihenfolge der Ereignisse im System zu bestimmen und Konsistenzbedingungen zu erfüllen.

Ein weiterer wichtiger Aspekt der Koordination ist die Einigung (Konsens). In verteilten Systemen müssen Knoten oft auf ein gemeinsames Ergebnis oder eine Entscheidung einigen. Dies kann beispielsweise bei der Wahl eines Leaders oder der Bestätigung einer Transaktion erforderlich sein. Es gibt verschiedene Konsensalgorithmen, wie zum Beispiel Paxos, oder Raft, die sicherstellen, dass ein solcher Konsens auch in Anwesenheit von Fehlern und Verzögerungen im System erreicht wird.

Die Handhabung von Fehlern und Wiederherstellung ist ein weiterer entscheidender Aspekt der Koordination in verteilten Systemen. Knoten können aufgrund von Hardware-, Software- oder Netzwerkfehlern ausfallen, und das System muss in der Lage sein, solche Ausfälle zu erkennen und angemessen darauf zu reagieren. Wiederherstellungsstrategien wie Replikation, Sharding und Checkpointing helfen dabei, die Datenintegrität aufrechtzuerhalten und das System nach einem Ausfall wieder in einen konsistenten Zustand zu bringen.
\examplevs{
Eines der bekanntesten Beispiele für verteilte Systeme und ihre Koordination ist das Hadoop-Ökosystem. Hadoop ist ein Open-Source-Framework, das auf verteilten Systemen zum Speichern und Verarbeiten großer Datenmengen ausgelegt ist. Hadoop verwendet eine Master-Slave-Architektur, bei der der Hadoop Distributed File System (HDFS) NameNode die Metadaten speichert und die DataNodes die eigentlichen Daten speichern und verarbeiten. Koordination wird durch den YARN (Yet Another Resource Negotiator) erreicht, der als Cluster-Ressourcenmanager fungiert und die Ressourcen effizient auf die verschiedenen Anwendungen verteilt. In verteilten Datenbanken müssen Transaktionen, die auf unterschiedlichen Knoten ausgeführt werden, koordiniert werden, um die ACID-Eigenschaften (Atomicity, Consistency, Isolation und Durability) sicherzustellen. Hierzu kommen Techniken wie Zwei-Phasen-Commit oder Three-Phasen-Commit zum Einsatz, die eine globale Einigung über das Ergebnis einer Transaktion ermöglichen und so die Datenintegrität gewährleisten.
}
\examplevs{
In der Welt des Internets ist die Domain Name System (DNS)-Hierarchie ein weiteres Beispiel für ein verteiltes System, das Koordination erfordert. DNS ist ein hierarchisches und verteilt angelegtes System zur Zuordnung von Domainnamen zu IP-Adressen. Hierarchische Strukturen wie Root-, Top-Level- und Second-Level-Domain-Server arbeiten zusammen, um die Anfragen der Benutzer effizient aufzulösen und die korrekten IP-Adressen zurückzugeben.
}
Insgesamt ist die Koordination in verteilten Systemen eine komplexe und essenzielle Aufgabe, um die korrekte Funktion und Leistung des Systems sicherzustellen. 

\subsection{Konsistenz}

Konsistenz ist ein wichtiges Konzept in verteilten Systemen und bezieht sich darauf, wie Datenänderungen über verschiedene Knoten hinweg sichtbar sind. In einfachen Worten bedeutet Konsistenz, dass alle Knoten im verteilten System immer die gleiche Sicht auf die Daten haben sollten. Es gibt verschiedene Stufen der Konsistenz, von strikter Konsistenz bis hin zu schwacher oder sich annährende Konsistenz, je nach den Anforderungen der Anwendung und den zugrunde liegenden Mechanismen, die zur Gewährleistung der Konsistenz eingesetzt werden.

\paragraph{Strikte Konsistenz}\mbox{}\\
Strikte Konsistenz ist das stärkste Konsistenzmodell, bei dem alle Knoten im verteilten System sofort die gleichen Daten sehen, sobald eine Änderung vorgenommen wurde. Das bedeutet, wenn ein Knoten eine Aktualisierung vornimmt, sind alle anderen Knoten sofort über diese Aktualisierung informiert, bevor sie weitere Lese- oder Schreiboperationen durchführen. In der Praxis ist es jedoch schwierig, strikte Konsistenz in verteilten Systemen zu erreichen, insbesondere aufgrund der physikalischen Begrenzungen der Informationsübertragung.
\examplevs{
Licht ist das schnellste Medium, mit dem Informationen übertragen werden können, aber selbst Licht hat eine endliche Geschwindigkeit von etwa 299.792 Kilometern pro Sekunde (km/s) im Vakuum. Diese Geschwindigkeit begrenzt, wie schnell Informationen zwischen verschiedenen Knoten in einem verteilten System ausgetauscht werden können.

Um zu zeigen, dass selbst Licht zu langsam ist, um strikte Konsistenz zu erreichen, betrachten wir ein hypothetisches verteiltes System mit zwei Knoten, die 3.000 Kilometer voneinander entfernt sind. Um die strikte Konsistenz aufrechtzuerhalten, müssen Informationen zwischen diesen Knoten sofort ausgetauscht werden, sobald eine Änderung vorgenommen wurde.

Die minimale Zeit, die benötigt wird, um Informationen über diese Entfernung mit Lichtgeschwindigkeit zu übertragen, kann berechnet werden, indem man die Entfernung durch die Lichtgeschwindigkeit teilt:
}
\begin{lstlisting}[caption={Berechnung Lichtgeschwindigkeit},captionpos=b,label={lst:licht}]
t = Distanz / Lichtgeschwindigkeit
t = 3.000 km / 299.792 km/s
t =  0,01 s
\end{lstlisting}
\examplevs{
In diesem Beispiel würde es also mindestens 0,01 Sekunden dauern, um Informationen über die Datenaktualisierung zwischen den beiden Knoten auszutauschen. Dies ist eine Ewigkeit im Kontext einer Datenbankanwendung, in der wir Lokal in einem Takt von mehreren GHz auf diesen Daten Operationen ausführen. In dieser Zeit wäre das verteilte System inkonsistent, da der zweite Knoten noch keine Kenntnis von der Aktualisierung hätte. Daher ist es praktisch unmöglich, strikte Konsistenz in verteilten Systemen zu erreichen, selbst wenn die Informationsübertragung mit Lichtgeschwindigkeit stattfindet.
}
In realen verteilten Systemen sind Konsistenzmodelle wie sequentielle Konsistenz, kausale Konsistenz oder sich annährende Konsistenz häufiger anzutreffen, da sie ein ausgewogenes Verhältnis zwischen Leistung und Konsistenz bieten und besser mit den inhärenten Latenzen und Unwägbarkeiten in verteilten Systemen umgehen können.

Neben physikalischen Größen hält aber bereits die Logik eine Herausforderung für die Konsistenz  bereit. 

\subsection{CAP Theorem}
Das CAP-Theorem, auch bekannt als Brewer's Theorem, ist ein fundamentales Prinzip, das die inhärenten Trade-offs in verteilten Systemen beschreibt. Es besagt, dass ein verteiltes System nur zwei der folgenden drei Eigenschaften gleichzeitig erfüllen kann: Konsistenz (C), Verfügbarkeit (A) und Partitionstoleranz (P).
\begin{itemize}
\item \textbf{Konsistenz} (C): Alle Knoten im System sehen zur gleichen Zeit dieselben Daten.
\item \textbf{Verfügbarkeit} (A): Alle Knoten sind stets in der Lage, Anfragen von Clients zu bearbeiten und korrekte Antworten zu liefern.
\item \textbf{Partitionstoleranz} (P): Das System kann trotz Netzwerkpartitionen, bei denen die Kommunikation zwischen Knoten unterbrochen ist, weiterhin korrekt funktionieren.
\end{itemize}

Das CAP-Theorem impliziert, dass verteilte Systeme in der Praxis immer zwischen Konsistenz und Verfügbarkeit abwägen müssen, da Partitionstoleranz als grundlegende Anforderung für verteilte Systeme angesehen wird.

Der Grund für diesen Trade-off liegt in den Unwägbarkeiten und Latenzen, die in verteilten Systemen vorhanden sind. Netzwerkpartitionen können aufgrund von Hardware-, Software- oder Konfigurationsfehlern auftreten. Wenn ein System auf strikte Konsistenz besteht, kann es während einer Netzwerkpartition nicht verfügbar sein, da es nicht möglich ist, alle Knoten zu synchronisieren, bis die Partition behoben ist. Andererseits, wenn ein System auf hohe Verfügbarkeit besteht, müssen Anfragen auch während einer Netzwerkpartition beantwortet werden, selbst wenn dies bedeutet, dass die Konsistenz beeinträchtigt wird.
\examplevs{
In realen Anwendungen ist der Trade-off zwischen Konsistenz und Verfügbarkeit häufig von den spezifischen Anforderungen der Anwendung abhängig. Zum Beispiel sind in einigen Anwendungen, wie Finanztransaktionssystemen, Konsistenz und Datenintegrität von größter Bedeutung. In solchen Fällen wäre ein System, das stärker auf Konsistenz ausgerichtet ist, wie beispielsweise ein System, das auf dem Paxos- oder Raft-Konsensalgorithmus basiert, besser geeignet.

In anderen Anwendungen, wie beispielsweise sozialen Netzwerken oder Content-Delivery-Netzwerken, ist Verfügbarkeit möglicherweise wichtiger als strenge Konsistenz. In solchen Fällen können Systeme, die auf schwacher Konsistenz oder  sich annährende Konsistenz basieren, wie beispielsweise Amazon's Dynamo oder Apache Cassandra, besser geeignet sein, um den Anforderungen gerecht zu werden.
}
Insgesamt zeigt das CAP-Theorem die fundamentale Herausforderung bei der Gestaltung von verteilten Systemen auf und betont die Notwendigkeit, den Trade-off zwischen Konsistenz und Verfügbarkeit in Abhängigkeit von den spezifischen Anforderungen und Prioritäten der Anwendung sorgfältig abzuwägen.

\subsection{Konsistenzmodell}

Da verteilte Systeme immer häufiger in der modernen Computertechnik eingesetzt werden, ist es wichtig, fortgeschrittene Techniken und Ansätze zu entwickeln, um den Konsistenz-Verfügbarkeits-Trade-off effektiv zu bewältigen. Einige solcher Ansätze umfassen:
\begin{itemize}
\item \textbf{Tunable Consistency:} Eine Möglichkeit, den Konsistenz-Verfügbarkeits-Trade-off zu bewältigen, besteht darin, Systeme mit anpassbarer Konsistenz (tunable consistency) zu entwerfen. In solchen Systemen kann die Konsistenzstufe für verschiedene Teile der Anwendung oder sogar für verschiedene Anfragen dynamisch angepasst werden. Ein Beispiel hierfür ist Apache Cassandra, bei dem die Konsistenzstufe für Lese- und Schreiboperationen auf einer Per-Anfrage-Basis angepasst werden kann.
\item \textbf{Quorum-Systeme:} Quorum-Systeme sind ein weiterer Ansatz zur Bewältigung des Konsistenz-Verfügbarkeits-Trade-offs. In einem Quorum-System wird die Mehrheit (oder ein festgelegter Prozentsatz) der Knoten benötigt, um eine Entscheidung zu treffen oder eine Operation durchzuführen. Dies ermöglicht eine gewisse Konsistenz und Verfügbarkeit, auch in Anwesenheit von Netzwerkpartitionen. Beispiele für Quorum-basierte Systeme sind Google Spanner und Amazon DynamoDB.
\item \textbf{CRDTs (Conflict-free Replicated Data Types):} CRDTs sind spezielle Datenstrukturen, die entwickelt wurden, um in verteilten Systemen repliziert zu werden, ohne dass es zu Konflikten kommt. Sie ermöglichen das Zusammenführen von Updates aus verschiedenen Knoten, ohne dass ein zentraler Koordinator erforderlich ist. CRDTs können dazu beitragen, die Verfügbarkeit zu erhöhen, während sie gleichzeitig eine gewisse Konsistenz aufrechterhalten. Ein Beispiel für ein System, das CRDTs verwendet, ist Riak.
\item \textbf{Hybride Ansätze:} In einigen Fällen kann es sinnvoll sein, hybride Ansätze zu verwenden, die verschiedene Konsistenzmodelle und Techniken kombinieren, um den Konsistenz-Verfügbarkeits-Trade-off effektiv zu bewältigen. Ein Beispiel hierfür ist das COPS-System (Clusters of Order-Preserving Servers), das eine Kombination aus sequentieller Konsistenz und eventual Konsistenz verwendet, um Daten über mehrere Rechenzentren hinweg zu replizieren.
\end{itemize}
\warningvs{
Mit welchen Mitteln man sich auch immer hilft, wichtig ist das/ein Konsistenzmodell zu verstehen, dass die Freiheitsgrade deutlich macht in dem man sich bewegen kann. Konsistenzmodelle beschreiben, wie ein verteiltes System den Zustand seiner Daten unter den verschiedenen Knoten synchronisiert und aufrechterhält. 
}
Es gibt verschiedene Konsistenzmodelle, wie jenes, das von Kyle Kingsbury entwickelt wurde. Das Modell ist allerdings  kein spezifisches Konsistenzmodell, sondern ein Framework zur Analyse und Validierung von verteilten Systemen hinsichtlich ihrer Datenkonsistenz- und Sicherheitseigenschaften, das verschiedene Modelle aufnimmt und sie ordnet. Diese Ordnung ist nicht standardisiert, so dass es in der Praxis Überlappungen und unterschiedliche Interpretationen geben kann. 
\\\\
In dieser Ausarbeitung konzentriert sich das Modellkonzept auf die Unterscheidung von datenzentrische Konsistenzmodelle und client-zentrische Konsistenzmodelle. datenzentrische Konsistenzmodelle konzentrieren sich darauf, wie verteilte Systeme den Zustand ihrer Daten unter den verschiedenen Knoten synchronisieren und aufrechterhalten. Sie beschreiben die Konsistenzanforderungen auf Systemebene und betreffen die Sichtbarkeit und Reihenfolge von Lese- und Schreiboperationen auf den Knoten.
\\\\
Client-zentrische Konsistenzmodelle hingegen legen den Fokus auf die Sichtbarkeit und Reihenfolge von Lese- und Schreiboperationen aus der Perspektive eines einzelnen Clients. Sie beschreiben, welche Garantien ein verteiltes System in Bezug auf die Konsistenz für einen bestimmten Client oder eine Gruppe von Clients bietet.
\importantvs{
Kurz gesagt, datenzentrische Konsistenzmodelle beziehen sich auf die Konsistenz auf der Ebene des verteilten Systems, während client-zentrische Konsistenzmodelle die Konsistenz aus der Perspektive der Clients betrachten. Zunächst konzentriert sich das Skript auf die datenzentrische Sicht. 
}
\subsection{Datenzentrische Konsistenzmodelle}
Einige der datenzentrischen Konsistenzmodelle, die im Rahmen der Diskussion analysiert werden sollten, sind:
\begin{itemize}
\item \textbf{Strong Consistency}: Eine verteilte Datenbank stellt sicher, dass alle Operationen auf allen Knoten gleichzeitig abgeschlossen werden. Diese Art von Konsistenzmodell stellt sicher, dass jeder Benutzer immer die neuesten Daten sieht.
\item \textbf{Linearizability}: Linearizability stellt sicher, dass alle Operationen auf allen Knoten in einer einzigen, atomaren Reihenfolge ausgeführt werden, die den Echtzeit-Verhalten entspricht.
\item \textbf{Sequential Consistency}: In diesem Modell müssen alle Operationen in einer einzigen, globalen Reihenfolge ausgeführt werden, die für alle Knoten gleich ist. Dieses Modell stellt jedoch keine kausale Beziehung zwischen Operationen her.
\item \textbf{Causal Consistency}: Causal Consistency stellt sicher, dass alle Operationen, die kausal voneinander abhängig sind, in der gleichen Reihenfolge auf allen Knoten angewendet werden. Unabhängige Operationen können jedoch in unterschiedlicher Reihenfolge ausgeführt werden.
\item \textbf{Eventual Consistency}: In diesem Modell werden Änderungen an Daten auf verschiedenen Knoten schließlich synchronisiert, aber nicht sofort. Dadurch kann es zu vorübergehenden Inkonsistenzen kommen, die jedoch im Laufe der Zeit behoben werden.
\end{itemize}

In diesem Skript wird versucht sich mit systematischen Methoden, insbesondere den Konsistenz- und Sicherheitseigenschaften von verteilten Systemen zu nähern, um sie entsprechend dem Anwendungsfall analysieren und sicherzustellen zu können. Da wir bereits diskutiert haben das Strong Consistency in einem verteilten System kaum zu erreichen ist, konzentriert man sich auf Modelle mit schwächerer Konsistenz, somit wäre das nächste in der Liste Linearizability. 

\subsubsection{Atomare Konsistenz}

Linearizability, auch als atomare Konsistenz bezeichnet oder manchmal mit starker (strong) Konsistenz gleichgesetzt, ist ein strenges Konsistenzmodell, bei dem jede Operation in einem verteilten System so aussieht, als ob sie sofort und in einer atomaren Weise auf alle Knoten im System angewendet wird. Linearizability stellt sicher, dass es eine globale Reihenfolge für alle Operationen gibt und dass diese Reihenfolge den Echtzeit-Verlauf der Operationen widerspiegelt.
\examplevs{
In der Praxis kann die Umsetzung von Linearizability in verteilten Systemen eine Herausforderung darstellen, da sie strenge Anforderungen an die Synchronisation und Kommunikation zwischen Knoten stellt. Hier sind einige Faktoren, die bei der praktischen Umsetzung von Linearizability berücksichtigt werden müssen:

\begin{itemize}
\item Latenz: Da Linearizability erfordert, dass alle Knoten im System synchronisiert werden, bevor eine Operation als abgeschlossen betrachtet werden kann, kann dies zu erhöhter Latenz bei Lese- und Schreiboperationen führen. Insbesondere in geografisch verteilten Systemen kann die Netzwerklatenz erhebliche Auswirkungen auf die Leistung haben.
\item Durchsatz: Die Anforderungen an die Synchronisation und Kommunikation zwischen Knoten, die für die Umsetzung von Linearizability erforderlich sind, können auch den Durchsatz des Systems beeinträchtigen, da Knoten möglicherweise auf die Bestätigung anderer Knoten warten müssen, bevor sie weitere Operationen durchführen können.
\item Verfügbarkeit: In Anbetracht des CAP-Theorems kann die Umsetzung von Linearizability die Verfügbarkeit des Systems beeinträchtigen, insbesondere in Szenarien, in denen Netzwerkpartitionen auftreten.
\end{itemize}
}
\paragraph{Zyklus-basiert}\mbox{}\\
Um Linearizability in verteilten Systemen praktisch umzusetzen, werden häufig Konsensalgorithmen wie Paxos, Raft oder Zab verwendet. Diese Protokolle führen die Idee eines Zyklus ein, welches das System Synchronisiert und Konsens etabliert. Die Einhaltungen der Anforderungen im Zyklus können herausfordernd sein, und nicht alle Abweichungen im Verhalten können einer Lösung zugeführt werden. Dennoch, diese Algorithmen ermöglichen es den Knoten, sich auf eine gemeinsame Reihenfolge von Operationen zu einigen und sicherzustellen, dass die Linearizability-Anforderungen erfüllt sind. Diese Algorithmen werden im späteren Kapitel nochmals genauer betrachtet. Trotz der Herausforderungen bei der Umsetzung von Linearizability kann dieses Konsistenzmodell in bestimmten Anwendungsfällen, in denen Datenintegrität und Konsistenz von größter Bedeutung sind (z. B. in Finanztransaktionssystemen), von Vorteil sein. Dennoch müssen Systemarchitekten und Entwickler die Auswirkungen auf Latenz, Durchsatz und Verfügbarkeit sorgfältig abwägen und möglicherweise weniger strenge Konsistenzmodelle in Betracht ziehen, wenn die Anforderungen der Anwendung dies zulassen.

\subsubsection{Sequentielle Konsistenz}
Sequential Consistency, oder sequentielle Konsistenz, ist ein Konsistenzmodell, bei dem die Operationen zum Beispiel in einer verteilten Datenbank in einer Reihenfolge ausgeführt werden, die für alle Knoten gleich ist. Während die tatsächliche Synchronisation der Knoten verzögert auftreten kann, bleibt die Reihenfolge der Operationen über alle Knoten hinweg konsistent.
\examplevs{
Um dies zu veranschaulichen, betrachten wir ein verteiltes System mit drei Knoten A, B und C, das einen gemeinsamen Zähler speichert. Nehmen wir an, es gibt zwei Benutzer, Benutzer 1 und Benutzer 2, die gleichzeitig den Zähler inkrementieren möchten. Der anfängliche Wert des Zählers ist 0.

Benutzer 1 sendet eine Inkrementanforderung an Knoten A, während Benutzer 2 eine Inkrementanforderung an Knoten B sendet. Da die beiden Anforderungen gleichzeitig erfolgen, ist die Reihenfolge der Operationen unklar. Um sequentielle Konsistenz zu gewährleisten, müssen alle Knoten jedoch eine gemeinsame Reihenfolge der Operationen einhalten.
\\\\
Angenommen, das verteilte System einigt sich darauf, dass die Operation von Benutzer 1 vor der Operation von Benutzer 2 ausgeführt wird. In diesem Fall müssen alle Knoten die Inkrementanforderung von Benutzer 1 zuerst verarbeiten und den Zähler auf 1 erhöhen. Anschließend verarbeiten sie die Inkrementanforderung von Benutzer 2 und erhöhen den Zähler auf 2.
Diese Vereinbarung kann auf vielfältige Weise getroffen werden, wie zum Beispiel vordefiniert oder über ein Abstimmungsverhalten. 
}
Wichtig ist, dass die Reihenfolge der Operationen auf allen Knoten gleich ist, auch wenn die tatsächliche Synchronisation der Knoten verzögert erfolgen kann. Zum Beispiel kann Knoten C die Inkrementanforderungen von Benutzer 1 und Benutzer 2 etwas später als Knoten A und B erhalten. Solange Knoten C jedoch die Operationen in derselben Reihenfolge verarbeitet, wird die sequentielle Konsistenz eingehalten.
\\\\
Dieses Konsistenzmodell bietet eine ausgewogene Mischung aus Konsistenz und Leistung und wird häufig in verteilten Systemen verwendet, bei denen eine strikte oder kausale Konsistenz nicht unbedingt erforderlich ist.


\subsubsection{Kausale Konsistenz}
Kausale Konsistenz ist ein Konsistenzmodell in verteilten Systemen, das darauf abzielt, die kausalen Beziehungen zwischen Operationen zu erhalten. Im Wesentlichen bedeutet dies, dass Operationen, die kausal voneinander abhängig sind, in der gleichen Reihenfolge auf allen Knoten im verteilten System ausgeführt werden müssen. Im Gegensatz dazu können Operationen, die keine kausale Beziehung zueinander haben, in unterschiedlicher Reihenfolge auf verschiedenen Knoten ausgeführt werden, ohne die Konsistenz zu beeinträchtigen.
\examplevs{
Ein praktisches Beispiel zur Veranschaulichung der kausalen Konsistenz wäre ein verteiltes soziales Netzwerk, bei dem Benutzer Nachrichten posten und auf Nachrichten anderer Benutzer antworten können. Die kausale Konsistenz stellt sicher, dass Antworten in der richtigen Reihenfolge angezeigt werden, bezogen auf die zugrunde liegenden Nachrichten.

Betrachten Sie folgendes Szenario: Alice und Bob sind Benutzer des sozialen Netzwerks und haben Zugriff auf verschiedene Knoten des verteilten Systems. Alice postet eine Nachricht (Nachricht A) und Bob sieht diese Nachricht und antwortet darauf (Antwort B). In diesem Fall gibt es eine kausale Beziehung zwischen Nachricht A und Antwort B, da Antwort B eine direkte Reaktion auf Nachricht A ist.

Da kausale Konsistenz die kausalen Beziehungen zwischen Operationen erhalten muss, muss Antwort B in der richtigen Reihenfolge nach Nachricht A auf allen Knoten im verteilten System angezeigt werden. Unabhängig von der tatsächlichen Zeit, zu der die Knoten die Informationen über die Nachricht A und Antwort B erhalten, stellt die kausale Konsistenz sicher, dass die Antwort B niemals vor der Nachricht A angezeigt wird.

Angenommen, ein anderer Benutzer, Carol, postet währenddessen eine unabhängige Nachricht (Nachricht C), die keine Beziehung zu den Nachrichten von Alice oder Bob hat. Da es keine kausale Beziehung zwischen Nachricht C und den anderen Nachrichten gibt, kann Nachricht C in einer beliebigen Reihenfolge in Bezug auf Nachricht A und Antwort B auf verschiedenen Knoten erscheinen, ohne die kausale Konsistenz zu beeinträchtigen.

In diesem Beispiel haben wir gesehen, wie kausale Konsistenz dazu beiträgt, die kausalen Beziehungen zwischen Operationen in verteilten Systemen zu erhalten, indem sie sicherstellt, dass kausal abhängige Operationen in der richtigen Reihenfolge auf allen Knoten ausgeführt werden. Kausale Konsistenz ist besonders nützlich in Anwendungen, bei denen die zeitliche Abfolge von Ereignissen wichtig ist, wie beispielsweise in sozialen Netzwerken, Foren oder Kommunikationssystemen.
}
Kausale Konsistenz bietet eine nützliche Balance zwischen Leistung und Konsistenz in verteilten Systemen, indem sie eine natürliche Ordnung für kausal verwandte Operationen aufrechterhält, ohne die Systemleistung übermäßig zu beeinträchtigen. Um kausale Konsistenz in der Praxis umzusetzen, werden häufig Vektoruhren oder andere Techniken zur Erfassung von kausalen Beziehungen eingesetzt.

Ein weiterer Ansatz zur Implementierung kausaler Konsistenz ist die Verwendung von Version Vektoren. Sie ähneln Vektoruhren, erfassen jedoch die Versionen von Objekten anstelle von Ereignissen. Version Vektoren ermöglichen es, Konflikte zwischen kausalen Versionen von Objekten zu erkennen und aufzulösen.

\subsubsection{Gelegentliche Konsistent}
Eventual Consistency ist ein Konsistenzmodell für verteilte Systeme, bei dem die Daten im System möglicherweise für eine gewisse Zeit inkonsistent sein können, aber schließlich eine konsistente Zustand erreichen, wenn keine weiteren Updates mehr erfolgen. Dieses Modell bietet eine höhere Verfügbarkeit und Skalierbarkeit, indem es vorübergehende Inkonsistenzen in Kauf nimmt und eine lockere Konsistenz zwischen den Knoten des Systems zulässt.

In einem verteilten System, das Eventual Consistency implementiert, kann es vorkommen, dass verschiedene Knoten unterschiedliche Versionen von Daten haben, insbesondere wenn gleichzeitige Updates stattfinden oder die Kommunikation zwischen den Knoten verzögert ist. Im Laufe der Zeit werden jedoch die Knoten die Updates replizieren und die Daten synchronisieren, bis alle Knoten eine konsistente Ansicht der Daten haben.

Ein praktisches Beispiel für Eventual Consistency ist das Amazon DynamoDB-System, ein hochverfügbarer und skalierbarer NoSQL-Datenbankservice. Amazon DynamoDB verwendet Eventual Consistency, um eine hohe Verfügbarkeit und Leistung zu gewährleisten, selbst wenn das System über mehrere Rechenzentren und geografische Standorte verteilt ist.
\examplevs{
Angenommen, ein E-Commerce-Unternehmen verwendet Amazon DynamoDB, um die Bestandsinformationen für seine Produkte zu verwalten. Wenn ein Kunde eine Bestellung aufgibt und ein Produkt kauft, wird der Bestand des Produkts in DynamoDB aktualisiert. Aufgrund der Eventual Consistency kann es jedoch vorkommen, dass verschiedene Knoten im DynamoDB-System unterschiedliche Bestandszahlen für das Produkt haben, während die Updates repliziert werden.

Ein weiterer Kunde, der zur gleichen Zeit die Produktseite besucht, sieht möglicherweise die alte Bestandszahl, die noch nicht aktualisiert wurde. Im Laufe der Zeit wird jedoch das Update auf alle Knoten im System repliziert, und alle Kunden werden schließlich die korrekte und konsistente Bestandszahl sehen.

Dieses Beispiel verdeutlicht das Konzept der Eventual Consistency, bei dem verteilte Systeme vorübergehende Inkonsistenzen zulassen, um eine höhere Verfügbarkeit und Skalierbarkeit zu erzielen, und schließlich eine konsistente Ansicht der Daten erreichen, wenn keine weiteren Updates mehr erfolgen.
}
Eventual Consistency ist für Entwickler von großer Bedeutung, insbesondere wenn sie verteilte Systeme oder Anwendungen mit hohen Verfügbarkeits- und Skalierbarkeitsanforderungen entwerfen. Die Implementierung von Eventual Consistency in einer Anwendung kann dazu beitragen, einige Herausforderungen im Zusammenhang mit verteilten Systemen zu bewältigen.


\subsection{Client-zentrische Konsistenzmodelle}
Client-zentrische Konsistenzmodelle sind eine Kategorie von Konsistenzmodellen in verteilten Systemen, die sich darauf konzentrieren, die Konsistenz aus der Perspektive der Clients oder Benutzer des Systems aufrechtzuerhalten. Im Gegensatz zu datenzentrischen Konsistenzmodellen, die sich auf die Konsistenz der Daten innerhalb des verteilten Systems konzentrieren, stellen client-zentrische Modelle sicher, dass die Clients eine konsistente Ansicht der Daten erhalten, auch wenn die Daten im System selbst möglicherweise nicht vollständig konsistent sind.

\subsubsection{Monotonic Reads}

Monotonic Reads ist ein client-zentrisches Konsistenzmodell, das die Konsistenz der Daten aus der Perspektive eines Clients oder Benutzers gewährleistet. Bei Monotonic Reads erhält ein Client, der wiederholt Lesevorgänge auf einem verteilten System ausführt, niemals ältere Daten als die, die er zuvor gelesen hat. Sobald ein Client eine bestimmte Version der Daten gelesen hat, werden alle nachfolgenden Lesevorgänge des Clients Daten liefern, die gleich oder neuer als die zuvor gelesene Version sind. Dieses Modell verhindert, dass ein Client Inkonsistenzen aufgrund von veralteten Daten bemerkt.
\examplevs{
Ein konkretes Beispiel für Monotonic Reads ist ein verteiltes E-Commerce-System, bei dem Benutzer den Lagerbestand von Artikeln abfragen können. Angenommen, ein Benutzer fragt den Lagerbestand eines bestimmten Artikels ab und erhält die Antwort, dass 10 Einheiten auf Lager sind. Kurz darauf wird der Lagerbestand aufgrund einer neuen Lieferung auf 15 Einheiten erhöht. Wenn der Benutzer später erneut den Lagerbestand abfragt, sollte das System nach dem Monotonic Reads-Prinzip sicherstellen, dass der Benutzer mindestens 15 Einheiten als Antwort erhält und nicht die ältere Information von 10 Einheiten, die er zuvor gesehen hat.
}
In der Praxis kann die Umsetzung von Monotonic Reads in einem verteilten System verschiedene Ansätze erfordern, abhängig von der Architektur und den Anforderungen des Systems. Eine mögliche Methode zur Implementierung von Monotonic Reads besteht darin, einen Zeitstempel oder eine Versionsnummer für jeden Datensatz zu speichern, die bei jeder Aktualisierung des Datensatzes erhöht wird. Wenn ein Client eine Leseanfrage stellt, kann das System den Zeitstempel oder die Versionsnummer der zuletzt gelesenen Version speichern und sicherstellen, dass alle nachfolgenden Leseanfragen nur Daten zurückgeben, die gleich oder neuer als dieser Zeitstempel oder diese Versionsnummer sind.
\examplevs{
Ein weiterer praktischer Einsatz von Monotonic Reads könnte beispielsweise in einem verteilten Datenbanksystem oder einer Anwendung zur Verwaltung verteilter Dateisysteme erfolgen. In solchen Systemen ist es wichtig, dass Clients eine konsistente Ansicht der Daten erhalten, um Inkonsistenzen oder Verwirrung bei den Benutzern zu vermeiden. Durch die Implementierung von Monotonic Reads kann das System sicherstellen, dass die Benutzer immer eine konsistente und fortschreitende Ansicht der Daten erhalten, selbst wenn das System selbst mit Replikations- oder Synchronisationsherausforderungen konfrontiert ist.
}
\subsubsection{Monotonic Writes}

Monotonic Writes ist ein client-zentrisches Konsistenzmodell, das darauf abzielt, die Konsistenz der Daten aus der Perspektive eines Clients oder Benutzers zu gewährleisten, indem sichergestellt wird, dass die Schreibvorgänge eines Clients in der Reihenfolge ausgeführt werden, in der sie vom Client eingereicht wurden. Im Gegensatz zu Monotonic Reads, bei dem es um die Konsistenz von Lesevorgängen geht, konzentriert sich Monotonic Writes darauf, die richtige Reihenfolge von Schreibvorgängen beizubehalten, um Inkonsistenzen zu vermeiden, die durch ungeordnete Schreibvorgänge entstehen können.
\examplevs{
Ein Fallbeispiel für Monotonic Writes ist ein verteiltes System zur Verwaltung von Banktransaktionen. Angenommen, ein Benutzer führt zwei Überweisungen in einer bestimmten Reihenfolge aus: zunächst eine Überweisung von 100 € von Konto A auf Konto B und anschließend eine Überweisung von 50 € von Konto B auf Konto C. Monotonic Writes stellt sicher, dass diese Transaktionen in der korrekten Reihenfolge verarbeitet werden, um Konsistenzprobleme zu vermeiden, die entstehen könnten, wenn die zweite Transaktion vor der ersten Transaktion verarbeitet würde.
}
In der Praxis kann auch die Implementierung von Monotonic Writes in einem verteilten System verschiedene Ansätze erfordern, abhängig von der Systemarchitektur und den Anforderungen. Eine mögliche Methode zur Umsetzung von Monotonic Writes besteht darin, die Schreibvorgänge mit Zeitstempeln oder Versionsnummern zu versehen und die Schreibvorgänge in einer Warteschlange zu halten, bis sie in der richtigen Reihenfolge verarbeitet werden können. Eine weitere Möglichkeit besteht darin, ein verteiltes Transaktionsprotokoll zu verwenden, um die Reihenfolge der Schreibvorgänge zu verfolgen und sicherzustellen, dass sie in der richtigen Reihenfolge ausgeführt werden.

\subsubsection{Read your Writes}
Read Your Writes ist ein client-zentrisches Konsistenzmodell, das darauf abzielt, die Konsistenz der Daten aus der Perspektive eines Clients oder Benutzers zu gewährleisten, indem sichergestellt wird, dass ein Client nach dem Ausführen eines Schreibvorgangs immer die von ihm geschriebenen Daten lesen kann. Dies stellt sicher, dass der Client die Auswirkungen seiner eigenen Schreibvorgänge sofort sieht und eine konsistente Ansicht der Daten erhält.
\examplevs{
Ein Fallbeispiel für Read Your Writes ist ein verteiltes System für soziale Netzwerke, bei dem Benutzer Statusaktualisierungen veröffentlichen können. Angenommen, ein Benutzer veröffentlicht eine neue Statusaktualisierung. Nach dem Veröffentlichen der Aktualisierung möchte der Benutzer die Liste seiner eigenen Statusaktualisierungen anzeigen. Read Your Writes stellt sicher, dass der Benutzer seine neueste Aktualisierung in der Liste sieht, selbst wenn das verteilte System noch dabei ist, die Aktualisierung auf alle Knoten zu replizieren.
}
Eine mögliche Methode zur Umsetzung von Read Your Writes besteht darin, einen Cache auf Clientseite zu verwenden, um die kürzlich geschriebenen Daten zu speichern, sodass der Client die eigenen Schreibvorgänge sofort lesen kann, selbst wenn sie noch nicht auf alle Knoten im verteilten System repliziert wurden. Eine weitere Möglichkeit besteht darin, ein verteiltes Transaktionsprotokoll zu verwenden, um sicherzustellen, dass alle Lesevorgänge, die nach einem Schreibvorgang ausgeführt werden, die neuesten Daten enthalten.

\subsubsection{Writes follow Reads}
Kausale Konsistenz und das \enquote{Writes follow Reads}-Prinzip sind eng miteinander verknüpft, da beide darauf abzielen, kausale Abhängigkeiten zwischen Operationen in verteilten Systemen aufrechtzuerhalten. \enquote{Writes follow Reads} ist eine Regel, die besagt, dass nach einer Leseoperation, die von einem bestimmten Knoten ausgeführt wird, alle Schreiboperationen, die von diesem Knoten initiiert werden und sich auf das gleiche Objekt beziehen, die gelesene Version oder eine neuere Version des Objekts berücksichtigen müssen.

Diese Regel hilft dabei, die kausale Ordnung der Operationen zu erhalten, indem sie sicherstellt, dass Schreiboperationen, die auf Leseoperationen basieren, in einer logisch konsistenten Reihenfolge erfolgen. Kausale Konsistenz und das \enquote{Writes follow Reads}-Prinzip ergänzen sich, da beide darauf abzielen, die kausale Reihenfolge der Operationen in verteilten Systemen zu respektieren und ein konsistentes Verhalten über verschiedene Knoten hinweg sicherzustellen.

In einem System, das kausale Konsistenz und \enquote{Writes follow Reads} implementiert, werden sowohl Schreib- als auch Leseoperationen in einer Weise ausgeführt, die ihre kausalen Abhängigkeiten berücksichtigt. Dies kann durch den Einsatz von Techniken wie Vektoruhren oder Version Vektoren erreicht werden, die dabei helfen, die kausalen Beziehungen zwischen Operationen zu erfassen und sicherzustellen, dass alle Knoten im verteilten System kausal abhängige Operationen in der richtigen Reihenfolge ausführen.

Ein reales Beispiel für die Umsetzung des \enquote{Writes follow Reads}-Prinzips ist in verteilten Datenbanken und Speichersystemen wie Apache Cassandra zu finden. 

In Cassandra basiert die Konsistenz der Daten auf einem kausalen Konsistenzmodell, das das \enquote{Writes follow Reads}-Prinzip unterstützt. Um dies zu erreichen, verwendet Cassandra Version Vektoren, sogenannte Timestamps, um kausale Beziehungen zwischen Schreib- und Leseoperationen zu erfassen und zu verwalten.

Wenn ein Benutzer in Cassandra eine Leseoperation durchführt, erhält er die neueste Version des angeforderten Objekts zusammen mit dessen Timestamp. Wenn der Benutzer daraufhin eine Schreiboperation auf demselben Objekt ausführt, muss er sicherstellen, dass der Timestamp der neuen Version höher ist als der Timestamp der gelesenen Version. Dies gewährleistet, dass Schreiboperationen auf den zuvor gelesenen Daten basieren und in einer logisch konsistenten Reihenfolge erfolgen.
\examplevs{
Ein konkretes Beispiel dafür ist die Verwendung von Cassandra zur Speicherung und Verwaltung von Benutzerprofilen in einem sozialen Netzwerk. Angenommen, ein Benutzer liest sein Profil und ändert dann seine E-Mail-Adresse. Im Rahmen des \enquote{Writes follow Reads}-Prinzips stellt Cassandra sicher, dass die neue E-Mail-Adresse auf der gelesenen Version des Profils basiert und in der richtigen Reihenfolge gespeichert wird.
}
\examplevs{
Ein weiteres Beispiel kann auch in einem Mehrbenutzersystem besprochen werden. Google Docs ist ein webbasiertes kollaboratives Textverarbeitungssystem, das es mehreren Benutzern ermöglicht, in Echtzeit an einem gemeinsamen Dokument zu arbeiten. Google Docs verwendet das Operational Transformation (OT) Framework, um die Konsistenz in Echtzeit zu gewährleisten und gleichzeitige Änderungen von verschiedenen Benutzern zu verwalten.

Angenommen, Alice und Bob arbeiten gleichzeitig an einem gemeinsamen Dokument in Google Docs. Alice liest einen Absatz und entscheidet, dass sie eine Änderung daran vornehmen möchte. Während sie ihre Änderungen vornimmt, liest Bob denselben Absatz und beschließt, ihn ebenfalls zu bearbeiten.

In diesem Szenario ist es wichtig, dass das System das \enquote{Writes follow Reads}-Prinzip einhält, um Konsistenz und kausale Ordnung der Operationen zu gewährleisten. Das OT-Framework in Google Docs stellt sicher, dass die Schreiboperationen von Alice und Bob auf den zuvor gelesenen Versionen des Absatzes basieren und in einer logisch konsistenten Reihenfolge angewendet werden.

Wenn Alice ihre Änderungen vornimmt, erfasst das System die kausale Beziehung zwischen ihrer Lese- und Schreiboperation und wendet ihre Änderung auf den zuvor gelesenen Absatz an. Gleichzeitig wird Bobs Schreiboperation ebenfalls auf der Grundlage seiner gelesenen Version des Absatzes durchgeführt. Anschließend verwendet das OT-Framework Transformationsfunktionen, um mögliche Konflikte zwischen Alices und Bobs Änderungen aufzulösen und eine konsistente Ansicht des Dokuments für beide Benutzer zu gewährleisten.
}
\subsection{Alternative Konsistensmodelle und Sonderformen}
Alternative Konsistenzmodelle sind Ansätze zur Datenkonsistenz in verteilten Systemen, die von den traditionellen ACID-Eigenschaften (Atomicity, Consistency, Isolation, Durability) abweichen. Diese Modelle wurden entwickelt, um die Leistung und Verfügbarkeit von verteilten Systemen zu verbessern, indem sie auf einige der Einschränkungen von ACID-basierten Ansätzen verzichten.

Einige der alternativen Konsistenzmodelle sind:
\begin{itemize}
\item BASE (Basically Available, Soft state, Eventually consistent): Dieses Modell legt den Fokus auf Verfügbarkeit und Partitionstoleranz, anstatt auf strikte Konsistenz. Es akzeptiert, dass Daten in verteilten Systemen vorübergehend inkonsistent sein können, solange sie sich langfristig wieder konsistent verhalten. Es wird oft in NoSQL-Datenbanken und Cloud-Systemen eingesetzt.
\item PACELC (Partition-tolerance, Availability, Consistency, Eventual consistency, Latency, and Consistency trade-offs): Dieses Modell berücksichtigt die trade-offs zwischen Konsistenz, Verfügbarkeit und Partitionstoleranz. Es geht davon aus, dass es unmöglich ist, alle drei Eigenschaften gleichzeitig in einem verteilten System zu erreichen, und dass eine Abwägung der Prioritäten erforderlich ist.
\end{itemize}
Diese alternativen Konsistenzmodelle bieten verschiedene Vor- und Nachteile gegenüber den traditionellen ACID-Modellen. Auch existieren Konsistenzmodelle, die keine reine Form repräsentieren sondern eher als Sonderform oder hybride Form betrachtet werden. Folgend sollen einige Beispiele eingebracht werden. 

\subsubsection{Kontinuierliche Konsistenz (hybrid)}
Continuous Consistency (kontinuierliche Konsistenz) ist ein Konsistenzmodell, das versucht, einen Kompromiss zwischen strikter Konsistenz und verfügbarkeitsorientierten Konsistenzmodellen wie eventual consistency zu finden. Anstatt die Konsistenzbedingungen strikt einzuhalten oder zu lockern, setzt Continuous Consistency auf eine kontinuierliche Verbesserung der Konsistenz im Laufe der Zeit.

Die Idee hinter Continuous Consistency besteht darin, Metriken und Schwellenwerte für die Konsistenz der Daten in einem verteilten System festzulegen und darauf hinzuarbeiten, diese Schwellenwerte im Laufe der Zeit einzuhalten oder zu überschreiten. Diese Metriken können beispielsweise die maximale Anzahl von Inkonsistenzen, die maximale Inkonsistenzdauer oder die maximale Inkonsistenzgröße umfassen.

In einem System mit kontinuierlicher Konsistenz wird die Konsistenz schrittweise verbessert, indem inkonsistente Daten erkannt und synchronisiert werden, bis die festgelegten Schwellenwerte erreicht oder überschritten sind. Dieser Ansatz ermöglicht eine bessere Balance zwischen Konsistenz und Verfügbarkeit, indem er es erlaubt, Konsistenzanforderungen basierend auf den Anforderungen der Anwendung und den zugrunde liegenden Systembedingungen flexibel anzupassen.

Continuous Consistency ist besonders nützlich für Anwendungen und Systeme, bei denen eine gewisse Toleranz gegenüber temporären Inkonsistenzen besteht, aber dennoch ein gewisses Maß an Konsistenz erforderlich ist. Ein Beispiel hierfür sind kollaborative Online-Editoren, bei denen Benutzer möglicherweise verschiedene Versionen eines Dokuments sehen, aber das System im Laufe der Zeit die Konsistenz verbessert, indem es die Änderungen zwischen den Benutzern synchronisiert.
\examplevs{
Hier ist ein vereinfachtes Fallbeispiel zur Veranschaulichung des Einsatzes von Metriken.

Angenommen, Sie betreiben eine Online-Nachrichtenplattform, auf der Redakteure Artikel veröffentlichen und Benutzer Kommentare hinterlassen können. In diesem Szenario gibt es mehrere wichtige Konsistenzanforderungen:
\begin{itemize}
\item Redakteure sollten in der Lage sein, Änderungen an Artikeln in Echtzeit vorzunehmen, ohne dass es zu langen Verzögerungen kommt.
\item Benutzer sollten die neuesten Artikel und Kommentare sehen können, wobei jedoch eine gewisse Verzögerung toleriert werden kann.
\end{itemize}
Um das Modell in dieser Anwendung zu implementieren, legen wir folgende Metriken und Schwellenwerte fest:
\begin{itemize}
\item Inkonsistenzdauer (ID): Die maximale Zeitdauer, während der ein Knoten im System eine inkonsistente Version der Daten haben darf. Zum Beispiel 5 Minuten für Artikel und 10 Minuten für Kommentare.
\item Inkonsistenzgröße (IS): Die maximale Anzahl von Inkonsistenzen, die in einem bestimmten Zeitraum auftreten dürfen. Zum Beispiel 10 Inkonsistenzen pro Stunde für Artikel und 20 Inkonsistenzen pro Stunde für Kommentare.
\end{itemize}

Die Online-Nachrichtenplattform verwendet in unserem Beispiel eine verteilte Datenbank, um Artikel und Kommentare zu speichern. Um das Konsistenzanforderungen umzusetzen, können Sie folgende Schritte ausführen:
\begin{itemize}
\item Bei jeder Aktualisierung der Daten (z. B. Hinzufügen/Ändern eines Artikels oder Hinzufügen eines Kommentars) messen Sie die Inkonsistenzdauer und die Inkonsistenzgröße. Diese Informationen können beispielsweise in Metadaten der Datenbank gespeichert werden.
\item Anhand der gemessenen ID und IS können Sie entscheiden, wann und wie oft Aktualisierungen zwischen den Knoten der verteilten Datenbank synchronisiert werden sollen. Wenn beispielsweise die ID oder IS für Artikel die festgelegten Schwellenwerte überschreitet, kann die Synchronisationsfrequenz erhöht werden, um die Konsistenz schneller wiederherzustellen.
\end{itemize}
}
Im Falle der Nichteinhaltung der festgelegten Metriken im CONIT-Modell (Inkonsistenzdauer oder Inkonsistenzgröße) kann das verteilte System verschiedene Maßnahmen ergreifen, um die Konsistenz zu verbessern oder die Auswirkungen der Inkonsistenzen zu minimieren. Diese Maßnahmen hängen von den spezifischen Anforderungen und Prioritäten des Systems ab.

Einige mögliche Maßnahmen bei Nichteinhaltung der Metriken sind:
\begin{itemize}
\item Erhöhen der Synchronisationsfrequenz: Das System kann die Frequenz erhöhen, mit der Updates zwischen den Knoten repliziert werden, um die Konsistenz schneller wiederherzustellen. Dies kann die Inkonsistenzdauer reduzieren, aber möglicherweise die Netzwerklast und Latenz erhöhen.
\item Benachrichtigung von Administratoren oder Entwicklern: Im Falle einer Nichteinhaltung der Metriken kann das System Benachrichtigungen an die verantwortlichen Administratoren oder Entwickler senden, damit sie die Situation untersuchen und angemessene Maßnahmen ergreifen können.
\item Anpassung der Schwellenwerte: Wenn die Nichteinhaltung der Metriken auf eine unzureichende Festlegung der Schwellenwerte zurückzuführen ist, können diese angepasst werden, um realistischere Ziele für das System zu setzen. Eine sorgfältige Analyse der Systemleistung und der Anwendungsanforderungen kann dazu beitragen, geeignete Schwellenwerte festzulegen.
\item Dynamische Anpassung der Konsistenzanforderungen: In einigen Fällen kann das System die Konsistenzanforderungen basierend auf der aktuellen Last oder den Prioritäten der Anwendung dynamisch anpassen. Zum Beispiel kann das System während Zeiten hoher Last eine lockere Konsistenz akzeptieren, um die Verfügbarkeit und Leistung aufrechtzuerhalten, und während Zeiten niedriger Last strengere Konsistenzanforderungen durchsetzen.
\end{itemize}
Es ist wichtig zu betonen, dass die Reaktion auf Nichteinhaltung der Metriken von den spezifischen Anforderungen und dem Kontext der Anwendung abhängt. Entwickler sollten sorgfältig abwägen, welche Maßnahmen am besten geeignet sind, um die Konsistenz in ihrem verteilten System aufrechtzuerhalten oder wiederherzustellen, bishin zur Einstellung des Dienstes. 




\subsubsection{Fork Consistency}

Traditionelle Konsistenzmodelle, wie Sequentielle Konsistenz und Linearisierbare Konsistenz, stellen strenge Anforderungen an die Reihenfolge, in der Operationen und ihre Ergebnisse zwischen den Knoten sichtbar sind. Diese Modelle sind zwar einfach zu verstehen und ermöglichen eine leichtere Programmierung, sie führen jedoch häufig zu Leistungseinbußen, da sie eine hohe Kommunikations- und Synchronisationslast erfordern.


In den letzten Jahren wurden daher neue, schwächere Konsistenzmodelle entwickelt, die bessere Leistung und Skalierbarkeit ermöglichen. Eines dieser Modelle ist die Fork-Konsistenz. Fork Consistency ist ein Konsistenzmodell, das die Sicherheitsanforderungen für Systeme mit mehreren Autoren lockert, indem es zulässt, dass Benutzer eine inkonsistente Ansicht der Daten sehen, solange sie auf getrennten \enquote{Forks} oder \enquote{Verzweigungen} des Systems arbeiten.


Fork Consistency ist daher  ein relativ neueres Konsistenzmodell, das im Bereich der verteilten Systeme verwendet wird. Bevor wir auf das Modell selbst eingehen, ist es wichtig, den Kontext von Konsistenzmodellen in verteilten Systemen zu verstehen. In verteilten Systemen arbeiten mehrere Knoten oder Server zusammen, um gemeinsam Daten und Rechenressourcen bereitzustellen. Eine der größten Herausforderungen dabei ist die Koordination und Synchronisation der Daten zwischen den Knoten, um eine konsistente Ansicht für die Clients sicherzustellen.

Die Hauptidee hinter Fork Consistency ist, dass das System nicht versucht, alle Änderungen sofort zwischen allen Knoten zu synchronisieren. Stattdessen werden Änderungen lokal an den Knoten vorgenommen und erst später, wenn nötig, mit anderen Knoten synchronisiert. Dabei entstehen \enquote{Forks}, also Verzweigungen in der Versionshistorie der Daten. Solange diese Verzweigungen getrennt bleiben, kann das System weiterarbeiten, ohne sich um die Konsistenz der Daten zwischen den Knoten sorgen zu müssen.
Während Fork Consistency einige Vorteile in Bezug auf Leistung und Skalierbarkeit bietet, hat es auch einige Nachteile und Herausforderungen:
\\\\
Ein Herausforderung ist, dass das Modell keine unmittelbare Synchronisation erfordert, daher können Benutzer eine inkonsistente Ansicht der Daten erhalten, was zu Anwendungsfehlern führen kann.
\\\\
Weiter müssen irgendwann die verschiedenen Verzweigungen der Daten wieder zusammengeführt werden. Dies kann ein komplexer Prozess sein, insbesondere wenn mehrere Autoren beteiligt sind und Konflikte in den Daten auftreten.
\\\\
Nicht zu letzt ist es eine schwierige Programmierung. Im Gegensatz zu strengeren Konsistenzmodellen müssen Entwickler, die mit Fork Consistency arbeiten, möglicherweise zusätzliche Anstrengungen unternehmen, um sicherzustellen, dass ihre Anwendungen korrekt funktionieren, wenn inkonsistente Daten vorhanden sind.
\\\\
Trotz dieser Herausforderungen bietet Fork Consistency in bestimmten Szenarien, insbesondere solchen mit einer hohen Anzahl von Knoten und Schreiboperationen, erhebliche Vorteile in Bezug auf Leistung und Skalierbarkeit. Um die Herausforderungen der Fork Consistency zu bewältigen, können Entwickler und Systemarchitekten verschiedene Strategien anwenden:
Konfliktlösung: Die Implementierung einer effizienten und robusten Strategie zur Konfliktlösung ist entscheidend, um die verschiedenen Verzweigungen der Daten erfolgreich zusammenzuführen. Dies kann beispielsweise durch den Einsatz von speziellen Algorithmen zur Zusammenführung von Daten, sogenannten Merge- oder Reconciliation-Algorithmen, erreicht werden. In einigen Fällen kann die Konfliktlösung auch manuell oder semi-manuell durch Benutzer oder Administratoren durchgeführt werden.

\subsubsection{Anwendungsspezifische Konsistenz}
In vielen Fällen ist es möglich, die Anforderungen an die Konsistenz auf Anwendungsebene zu definieren und anzupassen. Entwickler können dabei spezifische Mechanismen zur Handhabung von Inkonsistenzen implementieren, die den Anforderungen ihrer Anwendung am besten entsprechen. Ein Beispiel dafür ist die Verwendung von Convergent Replicated Data Types (CRDTs) oder Conflict-Free Replicated Data Types, die eine automatische Konfliktlösung ohne Koordination zwischen den Knoten ermöglichen.
\\\\
Um die Auswirkungen von Inkonsistenzen auf Benutzer und Anwendungen zu minimieren, können Systeme Strategien zur Steuerung der Sichtbarkeit von Änderungen auf Client-Seite implementieren. Beispielsweise können Clients dazu angehalten werden, nur konsistente Daten anzuzeigen, bis alle Verzweigungen erfolgreich zusammengeführt wurden. In einigen Fällen kann es sinnvoll sein, den Konsistenzgrad dynamisch an die aktuellen Anforderungen und Bedingungen des Systems anzupassen. Dies kann durch die Implementierung von Mechanismen erreicht werden, die es ermöglichen, zwischen verschiedenen Konsistenzmodellen zu wechseln, je nach Last, Netzwerkbedingungen oder Benutzeranforderungen.
Insgesamt bietet Fork Consistency ein interessantes und flexibles Konsistenzmodell für verteilte Systeme mit hoher Schreiblast und Skalierungsanforderungen. Um die damit verbundenen Herausforderungen zu bewältigen, ist es jedoch wichtig, sowohl auf System- als auch auf Anwendungsebene geeignete Mechanismen zur Handhabung von Inkonsistenzen, Konfliktlösung und Synchronisation zu implementieren.


\subsubsection{Multidimensionale Konsistenz }

Multidimensionale Konsistenz (Multidimensional Consistency) ist ein Konzept, das in verschiedenen Disziplinen wie Statistik, maschinellem Lernen, Datenanalyse und anderen verwandten Bereichen verwendet wird. Es bezieht sich auf das Maß der Übereinstimmung oder Konsistenz in den Daten oder Ergebnissen über verschiedene Dimensionen oder Aspekte eines Problems oder einer Analyse. Im Wesentlichen bedeutet es, dass die Ergebnisse in verschiedenen Dimensionen konsistent und plausibel sein sollten.

Die multidimensionale Konsistenz kann in verschiedenen Kontexten betrachtet werden:
\begin{itemize}
\item Datenqualität: Bei der Sammlung, Verarbeitung und Analyse von Daten ist es wichtig, die Qualität der Daten über verschiedene Dimensionen hinweg zu gewährleisten. Multidimensionale Konsistenz bedeutet hier, dass die Daten über verschiedene Attribute oder Dimensionen hinweg konsistent sind und keine Inkonsistenzen oder Widersprüche aufweisen, die die Analyse beeinträchtigen könnten.

\item Modellierung: In der Modellierung, insbesondere bei der Anwendung von maschinellem Lernen und statistischen Methoden, ist es wichtig, dass die Modelle, die auf den Daten trainiert werden, multidimensionale Konsistenz aufweisen. Dies bedeutet, dass die Modelle in der Lage sein sollten, konsistente und plausible Ergebnisse über verschiedene Dimensionen oder Aspekte des Problems hinweg zu liefern.

\item Ergebnisse und Interpretation: Die multidimensionale Konsistenz erstreckt sich auch auf die Ergebnisse und Interpretationen, die aus den Daten und Modellen abgeleitet werden. Es ist wichtig, dass die Ergebnisse über verschiedene Dimensionen oder Aspekte des Problems hinweg konsistent sind und plausibel erscheinen, um die Gültigkeit und Relevanz der Analyse zu gewährleisten.
\end{itemize}
Um die multidimensionale Konsistenz zu erreichen, können verschiedene Techniken und Ansätze verwendet werden, wie zum Beispiel:
\begin{itemize}
\item Datenvorverarbeitung: Sorgfältige Datenaufbereitung, -bereinigung und -validierung sind entscheidend, um Inkonsistenzen und Widersprüche in den Daten zu identifizieren und zu beheben.
\item Auswahl von Merkmalen und Dimensionen: Eine sorgfältige Auswahl von Merkmalen und Dimensionen kann dazu beitragen, die Relevanz und Konsistenz der Daten und Modelle zu gewährleisten.
\item Kreuzvalidierung: Bei der Anwendung von maschinellem Lernen und statistischen Methoden kann die Kreuzvalidierung dazu beitragen, die Konsistenz der Modelle und Ergebnisse über verschiedene Datensätze und Dimensionen hinweg zu überprüfen.
\item Visualisierung und Exploration: Die Visualisierung und Exploration der Daten und Ergebnisse kann dazu beitragen, Muster und Zusammenhänge aufzudecken, die zur multidimensionalen Konsistenz beitragen.
\end{itemize}
Insgesamt ist die multidimensionale Konsistenz ein wichtiger Aspekt bei der Gewährleistung der Qualität und Gültigkeit von Daten, Modellen und Ergebnissen in verschiedenen Anwendungsbereichen. Es trägt dazu bei, eine konsistente und fundierte Grundlage für Entscheidungen und Maßnahmen auf der Grundlage von Datenanalysen zu schaffen.

\subsubsection{Adaptable Consistency}

Adaptable Consistency ist ein Konzept, das in verteilten Systemen verwendet wird, um die Konsistenzanforderungen an die spezifischen Bedürfnisse und Anforderungen einer Anwendung oder Situation anzupassen. Es ermöglicht, dass die Konsistenz in einem verteilten System flexibel gestaltet wird, um sowohl Leistung als auch Datenkonsistenz zu optimieren, je nach den Anforderungen der Anwendung und den zugrunde liegenden Systembedingungen.

Ein  Beispiel für adaptable Consistency könnte ein verteiltes Key-Value-Store-System sein, das sowohl eventual consistency als auch strong consistency unterstützt, abhängig von den Anforderungen der Anwendung oder der Situation.

Angenommen, wir haben ein verteiltes System mit drei Knoten (A, B und C), die einen Key-Value-Store verwalten. Für dieses Beispiel verwenden wir einfache Lese- und Schreiboperationen.
\begin{itemize}
\item In einer Situation, in der die Latenz der Operationen von entscheidender Bedeutung ist und eine gewisse Inkonsistenz toleriert werden kann, könnte das System eventual consistency verwenden. In diesem Fall schreibt der Client die Daten an einen der Knoten (z.B. Knoten A) und das Update wird später auf die anderen Knoten (B und C) repliziert. Bei Leseanfragen können die Clients die Daten von jedem Knoten lesen, auch wenn sie möglicherweise noch nicht konsistent sind, was zu einer niedrigeren Latenz führt.
\item In einer anderen Situation, in der Datenkonsistenz von größter Bedeutung ist und höhere Latenzen toleriert werden können, könnte das System strong consistency verwenden. In diesem Fall schreibt der Client die Daten an einen der Knoten (z.B. Knoten A) und wartet, bis das Update auf die anderen Knoten (B und C) repliziert wurde, bevor die Schreiboperation als erfolgreich gemeldet wird. Bei Leseanfragen erhalten die Clients konsistente Daten, da das System sicherstellt, dass alle Knoten den gleichen Wert für einen bestimmten Schlüssel haben.
\end{itemize}
Das verteilte System kann seine Konsistenzstrategie an die Anforderungen der Anwendung oder die Systembedingungen anpassen, z.B. indem es eine niedrigere Konsistenzstufe wählt, wenn die Netzwerklatenz hoch ist oder ein Knotenausfall auftritt, oder indem es eine höhere Konsistenzstufe wählt, wenn die Datenintegrität von entscheidender Bedeutung ist. Durch die Anpassung der Konsistenzstrategie kann das System eine bessere Balance zwischen Leistung und Datenkonsistenz erreichen und so den spezifischen Bedürfnissen und Anforderungen der Anwendung gerecht werden.

\subsubsection{View Consistency}

View Consistency ist ein Konsistenzmodell, das in verteilten Systemen verwendet wird, um sicherzustellen, dass alle Prozesse oder Knoten, die auf Daten zugreifen, eine konsistente Sicht auf diese Daten haben. Im Wesentlichen bedeutet dies, dass alle Prozesse, die zur gleichen Zeit auf Daten zugreifen, dieselben Werte sehen. View Consistency ist ein schwächeres Konsistenzmodell als Strong Consistency, aber stärker als Eventual Consistency.
\\\\
Ein  Beispiel für View Consistency ist ein verteiltes Chat-System, in dem Nachrichten zwischen Benutzern ausgetauscht werden.

Angenommen, wir haben ein verteiltes Chat-System mit drei Knoten (A, B und C), die Nachrichten für verschiedene Benutzer speichern und verwalten. In diesem System gibt es zwei Benutzer, Alice und Bob, die miteinander chatten.
\begin{itemize}
\item Alice sendet eine Nachricht \enquote{Hallo} an Bob. Die Nachricht wird zuerst auf Knoten A gespeichert.
\item Das System repliziert die Nachricht auf den anderen Knoten (B und C) gemäß der View Consistency-Anforderung.
\item Während der Replikation können sowohl Alice als auch Bob weiterhin Nachrichten senden und empfangen. Das System stellt jedoch sicher, dass alle Nachrichten, die während der Replikation gesendet werden, in der richtigen Reihenfolge auf allen Knoten gespeichert werden, um die View Consistency aufrechtzuerhalten.
\item Sobald die Replikation abgeschlossen ist, sehen sowohl Alice als auch Bob die gleiche Sicht auf die Nachrichten, einschließlich der Reihenfolge, in der sie gesendet wurden.
\end{itemize}
In diesem Beispiel ermöglicht View Consistency, dass alle Benutzer eine konsistente Sicht auf die Chat-Nachrichten haben, ohne die strengeren Anforderungen von Strong Consistency, die höhere Latenzen verursachen könnten. Gleichzeitig gewährleistet es eine höhere Konsistenz als Eventual Consistency, bei der Inkonsistenzen zwischen Knoten für einen gewissen Zeitraum toleriert werden.

\subsubsection{Write Write Conflicts}
In verteilten Systemen können Write-Write-Konflikte auftreten, wenn zwei oder mehr Schreibvorgänge von verschiedenen Clients gleichzeitig oder nahezu gleichzeitig auf denselben Datensatz angewendet werden. Solche Konflikte sind von Bedeutung, da sie zu Inkonsistenzen führen können, wenn die Schreibvorgänge nicht ordnungsgemäß koordiniert und synchronisiert werden. Write-Write-Konflikte stellen eine Herausforderung für verteilte Systeme dar, da sie die Integrität und Konsistenz der Daten beeinträchtigen können, wenn sie nicht angemessen behandelt werden.

Ein Beispiel für einen Write-Write-Konflikt könnte in einem verteilten Kollaborationswerkzeug wie einem Textdokument auftreten, an dem mehrere Benutzer gleichzeitig arbeiten. Wenn zwei Benutzer zur gleichen Zeit unterschiedliche Änderungen am gleichen Absatz vornehmen, entsteht ein Write-Write-Konflikt, da das System entscheiden muss, welche der beiden Änderungen Vorrang haben sollte oder wie diese Änderungen zusammengeführt werden können, ohne den Inhalt des Dokuments zu beeinträchtigen.

Um Write-Write-Konflikte in verteilten Systemen zu bewältigen, können verschiedene Ansätze verfolgt werden, darunter:
\begin{itemize}
\item \textbf{Sperren und Transaktionen:} Das System kann exklusive Sperren für Datensätze verwenden, um sicherzustellen, dass nur ein Client gleichzeitig auf einen Datensatz zugreifen kann. Transaktionen können ebenfalls eingesetzt werden, um mehrere Schreibvorgänge atomar zu behandeln und sicherzustellen, dass sie entweder vollständig abgeschlossen oder abgebrochen werden, um Konsistenzprobleme zu vermeiden.
Datenbanksysteme: Relationale Datenbanksysteme wie PostgreSQL und MySQL verwenden Sperren und Transaktionen, um Konsistenz und Datenintegrität in verteilten Umgebungen sicherzustellen. Bei diesen Systemen können Clients Transaktionen verwenden, um mehrere Schreibvorgänge zusammenzufassen und sicherzustellen, dass sie entweder vollständig abgeschlossen oder abgebrochen werden, um Konsistenzprobleme zu vermeiden.
\item  \textbf{Optimistische Nebenläufigkeitskontrolle:} Bei dieser Methode wird angenommen, dass Konflikte selten auftreten. Clients können ihre Schreibvorgänge ausführen, ohne auf Sperren zu warten. Vor dem Commit wird überprüft, ob Konflikte aufgetreten sind. Im Falle eines Konflikts wird eine der Transaktionen zurückgerollt und später erneut ausgeführt.
Apache Cassandra: Dieses verteilte NoSQL-Datenbanksystem verwendet die optimistische Nebenläufigkeitskontrolle, um hohe Leistung und Skalierbarkeit zu ermöglichen. Clients führen Schreibvorgänge aus, ohne auf Sperren zu warten, und das System verwendet Zeitstempel, um Konflikte aufzulösen, wenn sie auftreten. Die neueste Änderung (basierend auf dem Zeitstempel) hat Vorrang und überschreibt ältere Änderungen.
\item  \textbf{Versionskontrolle und Zusammenführungsstrategien:} In einigen Systemen, insbesondere in kollaborativen Anwendungen, kann es sinnvoll sein, verschiedene Versionen der Daten beizubehalten und Strategien zum Zusammenführen von Änderungen zu implementieren, die gleichzeitig vorgenommen wurden. Diese Strategien können automatisch sein oder Benutzerinteraktion erfordern, um die Zusammenführung abzuschließen.
Ein anderes Beispiel neben Google Docs ist Git. Git ist ein verteiltes Versionskontrollsystem, das häufig von Softwareentwicklern zur Verwaltung von Quellcode verwendet wird. Git behält verschiedene Versionen der Dateien bei und ermöglicht es Benutzern, Änderungen zusammenzuführen, die von verschiedenen Entwicklern gleichzeitig vorgenommen wurden. Wenn ein Write-Write-Konflikt auftritt, fordert Git den Benutzer auf, die Konflikte manuell zu lösen, bevor die Änderungen zusammengeführt werden können.
\end{itemize}
Die aller Beste Strategie ist allerdings dem grundlegenden Problem aus dem Wege zu gehen und die Schreibvorgänge auf einem System zu sequenzialisieren. Ein gängiger Ansatz zur Sequenzialisierung von Schreibvorgängen in verteilten Systemen besteht darin, einen sogenannten \enquote{Primary} oder \enquote{Master} Knoten zu verwenden. Bei diesem Ansatz werden alle Schreibvorgänge an einen zentralen Knoten gesendet, der dafür verantwortlich ist, die Schreibvorgänge in einer bestimmten Reihenfolge auszuführen und die aktualisierten Daten an die anderen Knoten im verteilten System zu replizieren.
\examplevs{
Ein Beispiel für ein verteiltes System, das Schreibzugriffe sequenziell verarbeitet, ist MongoDB im Primary-Secondary-Modus. In dieser Konfiguration empfängt der Primary-Knoten alle Schreibvorgänge und führt sie in einer bestimmten Reihenfolge aus, bevor die aktualisierten Daten an die sekundären Knoten repliziert werden. Die sekundären Knoten können Lesevorgänge ausführen, um die Last auf dem Primary-Knoten zu verringern.
}
Es gibt jedoch auch Nachteile bei der Verwendung von sequenziellen Schreibvorgängen in verteilten Systemen. Durch die Sequenzialisierung der Schreibvorgänge kann die Skalierbarkeit eingeschränkt werden, da der zentrale Knoten ein Engpass für die Leistung und Verfügbarkeit des Systems werden kann. Aus diesem Grund verwenden viele verteilte Systeme die anderen Ansätze trotz ihrer Nachteile. Die Synchronization der Master mit den Replikationen ist zudem auch wiederum eine eigene Herausforderung die aber nicht nur in diesem sondern jedem anderen Szenario besteht.  
\\\\
Jede dieser Lösungsstrategien hat ihre eigenen Vor- und Nachteile, und die Wahl der am besten geeigneten Strategie hängt von den spezifischen Anforderungen und Merkmalen des verteilten Systems ab. Die Beispiele hier veranschaulichen die Vielfalt der Ansätze, die in der Praxis angewendet werden, um Write-Write-Konflikte zu bewältigen und die Konsistenz und Datenintegrität in verteilten Systemen aufrechtzuerhalten. Dennoch werden in der Praxis auch immer wieder Strategien wie replicated-write protocols eingesetzt die ein hohes Mass an Abstimmung und Konsenz bedürfen und in einem späteren Kapitel im Kontext von Raft und Paxos nochmal betrachtet werden.  

\subsection{Synchronisation}

Die Synchronisation in verteilten Systemen ist eine komplexe Herausforderung, da mehrere Prozesse oder Knoten auf gemeinsame Ressourcen zugreifen können, ohne dass eine klare Ordnung oder ein gemeinsame Zeit vorhanden ist. In einem verteilten System kann es schwierig sein, sicherzustellen, dass die verschiedenen Kopien der Ressourcen konsistent sind und dass die Daten und Aktionen in der richtigen Reihenfolge ausgeführt werden.
\examplevs{
Ein Beispiel für eine Herausforderung der Synchronisation in verteilten Systemen ist die Replikation von Daten beispielhaft in einem verteilten Datenbanksystem. Wenn mehrere Kopien einer Datenbank auf verschiedenen Knoten im Netzwerk ausgeführt werden, müssen die Änderungen an den Daten in Echtzeit zwischen den Knoten synchronisiert werden, um die Konsistenz der Daten zu gewährleisten. Da es keine gemeinsame Uhr gibt, die die Zeit auf allen Knoten synchronisiert, kann es schwierig sein, die Reihenfolge der Änderungen zu bestimmen und sicherzustellen, dass alle Knoten die neuesten Daten haben.
}
\textbf{Remote-write protocols} und \textbf{Local-write protocols} sind zwei Ansätze zur Synchronisation von Schreibzugriffen in verteilten Systemen. Remote-write protocols erlauben es einem Knoten, Schreibzugriffe auf gemeinsame Ressourcen auszuführen, wobei die Änderungen dann an andere Knoten im Netzwerk übertragen werden. Local-write protocols hingegen erlauben nur einem Knoten, Schreibzugriffe auf eine Ressource auszuführen, und synchronisieren dann die Änderungen mit den anderen Knoten im Netzwerk.
\examplevs{
Ein Beispiel für den Einsatz von remote-write protocols ist eine Anwendung, die auf einer verteilten Datenbank aufbaut und gleichzeitige Schreibzugriffe von mehreren Knoten erfordert. Wenn mehrere Knoten gleichzeitig Änderungen an einer Tabelle der Datenbank vornehmen, kann es zu Konflikten kommen, die die Konsistenz der Datenbank beeinträchtigen können. Ein Ansatz zur Vermeidung dieser Konflikte besteht darin, dass jeder Knoten Remote-Schreibzugriffe auf die Datenbank ausführt, um Änderungen auf anderen Knoten im Netzwerk zu aktualisieren. Ein Beispiel für eine solche Anwendung ist ein Echtzeit-Börsensystem, bei dem mehrere Knoten gleichzeitig Trades auf die Datenbank schreiben. Durch die Verwendung von remote-write protocols kann die Konsistenz der Datenbank gewährleistet werden, ohne dass es zu Konflikten oder Inkonsistenzen kommt.
}
\examplevs{
Ein dem gegenüberstehendes Beispiel für den Einsatz von Local-write protocols ist eine Anwendung, bei der ein Knoten eine hohe Anzahl von Schreibzugriffen auf eine Ressource ausführt. Wenn ein Knoten mehrere Schreibzugriffe hintereinander ausführt, kann die Latenz und Netzwerkbelastung hoch sein, wenn jede Änderung an andere Knoten im Netzwerk übertragen werden muss. Ein Ansatz zur Optimierung dieser Prozesse besteht darin, dass jeder Knoten nur lokale Schreibzugriffe auf seine eigene Kopie der Ressource ausführt und dann Änderungen zwischen den Knoten synchronisiert, um sicherzustellen, dass alle Knoten die gleichen Daten haben. Ein Beispiel für eine solche Anwendung ist ein Produktkatalog, bei dem ein Knoten Produktbeschreibungen und -bilder in die Datenbank schreibt. Durch die Verwendung von Local-write protocols kann die Latenz und Netzwerkbelastung reduziert werden, während gleichzeitig die Konsistenz der Datenbank gewährleistet wird.
}
De Wahl zwischen remote-write protocols und local-write protocols ist von den spezifischen Anforderungen und Einschränkungen des verteilten Systems abhängig. Wie es auch sei, die Wahl dieser Protokolle negiert nicht die Herausforderungen der Koordination über die verschiedenen Systeme. Daher gibt es verschiedene weitere Lösungsstrategien für die Synchronisation von verschiedenen nodes in verteilten Systemen, die je nach Anwendungsanforderungen und Systemarchitektur verwendet werden können:
\\\\
Die folgenden Absätze geben einen detaillierteren Blick in die Ansätze \textbf{Physikalische Uhren}, \textbf{Logische Uhren} und \textbf{Locking}. 

\subsubsection{Physikalische Uhr}

Eine Möglichkeit für einen globalen Zeitstempel ist die physikalische Uhr. Diese bietet eine Basis für eine gemeinsame Zeitbasis, wenn die Uhren selbst synchronisiert sind. Eine physikalische Uhr ist im Wesentlichen ein Gerät oder eine Komponente, die Zeit misst und darstellt, basierend auf einem physikalischen Prozess, wie der Schwingung eines Quarzkristalls.
\\\\
Die Verwendung von physikalischen Uhren in verteilten Systemen kann jedoch komplex sein. Ein Hauptproblem ist die Tatsache, dass physikalische Uhren auf verschiedenen Knoten aufgrund von Unterschieden in den Quarzkristallen oder anderen physikalischen Prozessen, die zur Zeiterfassung verwendet werden, leicht auseinander driften können. Dieses Drift kann dazu führen, dass die Uhren auf verschiedenen Knoten unterschiedliche Zeiten anzeigen, was zu Inkonsistenzen in der Reihenfolge von Ereignissen führen kann.
\\\\
Um dieses Problem zu lösen, verwenden verteilte Systeme häufig Synchronisationsprotokolle, um die Uhren auf den verschiedenen Knoten abzugleichen. Ein bekanntes Beispiel für ein solches Protokoll ist das \textbf{Network Time Protocol} (NTP), das im Internet verwendet wird, um die Uhren auf verschiedenen Computern und Netzwerkgeräten zu synchronisieren. NTP verwendet einen hierarchischen Ansatz, bei dem eine kleine Anzahl von Servern mit sehr genauen Uhren (z. B. Atomuhren) als Referenz für andere Server und Geräte dienen.
\\\\
Ein weiteres Beispiel ist das Google TrueTime API, das in Googles Spanner-Datenbanksystem verwendet wird. TrueTime verwendet eine Kombination von GPS und Atomuhren, um eine sehr genaue Zeitbasis für die Synchronisierung von Operationen im Spanner-System zu bieten. Dies ermöglicht Spanner, konsistente Transaktionen über eine globale Skala von Datenzentren hinweg durchzuführen.
\\\\
In der Uhren- und Messtechnik bezieht sich die \textbf{Präzision} auf die Konsistenz von Messungen oder Wiederholbarkeit, während die \textbf{Akkuratesse} (Genauigkeit) sich auf die Nähe von Messungen zum tatsächlichen, wahren Wert bezieht.
\importantvs{
Die \textbf{Präzision} ist die Standardabweichung der Messungen. Angenommen, wir haben eine Reihe von Messungen $x_1, x_2, \ldots, x_n$, dann ist die Präzision definiert als:
\begin{equation}
\sigma = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}
\end{equation}
wobei $\bar{x}$ der Durchschnittswert der Messungen ist.
\\\\
}
\importantvs{
Die \textbf{Akkuratesse} ist der Unterschied zwischen dem Durchschnittswert der Messungen und dem wahren Wert. Wenn $T$ der wahre Wert ist, dann ist die Akkuratesse definiert als:
\begin{equation}
A = |T - \bar{x}|
\end{equation}
}
In einer idealen Situation wäre eine Uhr sowohl präzise als auch akkurat: Sie würde konsequent die gleiche Zeit anzeigen (hohe Präzision) und diese Zeit wäre nahe an der tatsächlichen Zeit (hohe Akkuratesse). In der Praxis gibt es jedoch oft einen Kompromiss zwischen Präzision und Akkuratesse.
\paragraph{UTC}\mbox{}\\
Häufig wird die UTC als Basis für eine präzise und akkurate Uhr gewählt.
Die \textbf{Universal Time Coordinated (UTC)} ist der Zeitstandard, der zur Koordination von Weltzeit verwendet wird. Es handelt sich dabei um eine atomare Zeitskala, die auf International Atomic Time (TAI), mit Sprüngen von einer Sekunde, basiert, um sie nahe an der mittleren Sonnenzeit (UT1) zu halten.

UTC ist die Zeit, die in allen Bereichen der Wissenschaft und Technik, in der Luft- und Raumfahrt, in der Navigation und in der Datenverarbeitung verwendet wird. Sie ist auch die Zeit, die von Zeitservern im Internet zur Synchronisation von Computern, Mobilgeräten und anderen digitalen Geräten verwendet wird.
Die Verwendung von UTC als Akronym für Coordinated Universal Time in Englisch oder Temps Universel Coordonné in Französisch ist tatsächlich ein Kompromiss zwischen den beiden Sprachen.


\subsubsection{Globale Zeitstempel}
Globale Zeitstempel sind ein Synchronisationsmechanismus in verteilten Systemen, der auf einer gemeinsamen Uhr basiert. Die Idee besteht darin, dass alle Knoten oder Prozesse in einem verteilten System ihre Uhren synchronisieren und jeder Operation oder jedem Ereignis einen eindeutigen Zeitstempel zuweisen. Diese Zeitstempel ermöglichen es, Ereignisse und Operationen in der richtigen Reihenfolge auszuführen und Inkonsistenzen zu vermeiden. Einige Vorteile von globalen Zeitstempeln sind die einfache Handhabung von Ereignisreihenfolgen und die Möglichkeit, gleichzeitige Ereignisse leicht zu erkennen.
\examplevs{
Ein minimales Beispiel für die Verwendung von globalen Zeitstempeln in der Praxis ist ein verteiltes Auktionssystem, bei dem Benutzer Gebote für Artikel abgeben.

Angenommen, wir haben ein verteiltes Auktionssystem mit drei Knoten (A, B und C), die Gebote für verschiedene Artikel speichern und verwalten. In diesem System gibt es zwei Benutzer, Alice und Bob, die Gebote für denselben Artikel abgeben.
\begin{itemize}
\item Alice sendet ein Gebot von 50 € an Knoten A. Knoten A weist dem Gebot einen globalen Zeitstempel T1 zu, der auf der gemeinsamen Uhr basiert.
\item Bob sendet ein Gebot von 60 € an Knoten B. Knoten B weist dem Gebot einen globalen Zeitstempel T2 zu, der auf der gemeinsamen Uhr basiert.
\item Die Gebote werden zwischen den Knoten repliziert, um sicherzustellen, dass alle Knoten über die aktuellsten Informationen verfügen.
\item Die Knoten vergleichen die globalen Zeitstempel der Gebote (T1 und T2), um die Reihenfolge der Gebote zu bestimmen und den Gewinner der Auktion zu ermitteln.
\end{itemize}
In diesem Beispiel ermöglichen die globalen Zeitstempel, dass alle Knoten im verteilten Auktionssystem eine einheitliche Sicht auf die Reihenfolge der Gebote haben, wodurch potenzielle Inkonsistenzen vermieden werden. Es ist wichtig, dass die Knoten ihre Uhren regelmäßig synchronisieren, um eine hohe Genauigkeit der globalen Zeitstempel zu gewährleisten.
}
Um eine gemeinsame Uhr in verteilten Systemen zu etablieren, gibt es neben den beschriebenen Ansätzen weitere Algorithmen und Protokolle um dies zu erlangen. Die Hauptziele dieser Ansätze sind die Synchronisation der Uhren der einzelnen Knoten und die Minimierung der Abweichungen zwischen ihnen, hier spielt der Einsatz zusätlicher Hardware eine Rolle, oder die Abkehr von einen zentralen Zeitgeber, wie einer Atomuhr:
\begin{itemize}
\item \textbf{Precision Time Protocol} (PTP): PTP ist ein alternatives Protokoll zu NTP, das entwickelt wurde, um eine präzise Zeitsynchronisation in verteilten Systemen zu erreichen. Im Gegensatz zu NTP ist PTP speziell für lokale Netzwerke (LANs) entwickelt worden und ermöglicht eine höhere Genauigkeit in der Zeitsynchronisation. PTP verwendet einen sogenannten \enquote{Grandmaster Clock} sowie \enquote{Ordinary Clocks} und \enquote{Boundary Clocks}, um eine präzise Synchronisation über das Netzwerk zu erreichen.
\item \textbf{Cristian's Algorithm}: Cristian's Algorithm ist ein einfacherer Ansatz zur Uhrensynchronisation in verteilten Systemen, bei dem ein Zeitserver als Referenz dient. Die Knoten stellen regelmäßig Anfragen an den Zeitserver, um ihre Uhren zu synchronisieren. Bei jeder Anfrage berechnet der Knoten die Netzwerkverzögerung und passt seine Uhr entsprechend an.
\item \textbf{Berkeley Algorithm}: Der Berkeley Algorithm ist ein weiterer Algorithmus zur Synchronisation der Uhren in verteilten Systemen. In diesem Ansatz wird ein Koordinator ausgewählt, der die Zeitinformationen von allen Knoten im System sammelt und einen gewichteten Durchschnitt berechnet. Anschließend verteilt der Koordinator die berechnete Zeit an alle Knoten, die ihre Uhren entsprechend anpassen.
\item \textbf{Logische Uhren}: Obwohl logische Uhren keine physische Uhrensynchronisation bieten, bieten sie eine Möglichkeit, die Reihenfolge von Ereignissen in einem verteilten System zu bestimmen, ohne eine gemeinsame Uhr zu etablieren. Diese Methode verwendet logische Zähler, die bei jedem Ereignis oder jeder Nachricht inkrementiert werden, um eine partielle Ordnung der Ereignisse zu etablieren.
\end{itemize}
Alle Verfahren, inklusive insbesondere NTP, sind nur eine Auswahl, aber von solch einem besonderem Interesse, das sie nochmals im Folgenden mit höheren Detailgrad besprochen werden.


\subsubsection{Network Time Protocol (NTP)}
Das Network Time Protocol (NTP) ist ein weit verbreitetes Protokoll zur Synchronisation der Systemuhren von Computern in einem Netzwerk. Die mathematischen Grundlagen von NTP basieren auf der Schätzung von Netzwerkverzögerungen und der Verwendung von Zeitservern, um eine genaue Zeitsynchronisation zu erreichen.
\importantvs{
Um die Netzwerkverzögerung zu schätzen, verwendet NTP vier Zeitstempel:

\begin{enumerate}
\item t1: Die lokale Zeit, zu der der Client eine Anfrage an den Server sendet.
\item t2: Die Serverzeit, zu der der Server die Anfrage vom Client erhält.
\item t3: Die Serverzeit, zu der der Server eine Antwort an den Client sendet.
\item t4: Die lokale Zeit, zu der der Client die Antwort vom Server erhält.
\end{enumerate}
Mit diesen Zeitstempeln kann NTP die Netzwerkverzögerung und die Offset-Zeit berechnen, die zum Synchronisieren der Uhr des Clients benötigt werden. Die Netzwerkverzögerung (D) und der Offset (\(\theta\)) werden wie folgt berechnet:

\[ D = (t4 - t1) - (t3 - t2) \]
\[ \theta = \frac{(t2 - t1) + (t3 - t4)}{2} \]
Die Netzwerkverzögerung ist die Zeit, die benötigt wird, um Nachrichten zwischen Client und Server zu senden und zu empfangen. Der Offset ist die durchschnittliche Zeitdifferenz zwischen dem Client und dem Server. Ob die Annahme für die Berechnung im Internet immer zutrifft, darf aber bezweifelt werden.

Dennoch, der Offset ist die durchschnittliche Zeitdifferenz zwischen dem Client und dem Server. Nachdem der Offset und die Netzwerkverzögerung berechnet wurden, verwendet der Client diese Informationen, um seine Uhr anzupassen und mit der Serverzeit zu synchronisieren.
}
NTP ist ein hierarchisches Protokoll, das mehrere Schichten von Zeitservern verwendet, um eine genaue Zeitsynchronisation zu erreichen. An der Spitze der Hierarchie steht der Stratum-1-Server, der direkt mit einer externen Zeitquelle wie einem GPS- oder Atomuhr-Referenzsignal verbunden ist. Die Server der nächsten Schicht (Stratum-2) sind mit Stratum-1-Servern verbunden und so weiter. Clients wählen in der Regel den Server mit der geringsten Verzögerung und dem geringsten Stratum für die Synchronisation aus.
\examplevs{
Problem Netzwerkverzögerungsschwankungen:
\begin{align*}
t1 &= 10 \text{ ms} \quad &(\text{Client sendet Anfrage}) \\
t2 &= 15 \text{ ms} \quad &(\text{Server empfängt Anfrage}) \\
t3 &= 20 \text{ ms} \quad &(\text{Server sendet Antwort}) \\
t4 &= 30 \text{ ms} \quad &(\text{Client empfängt Antwort})
\end{align*}
}
\examplevs{
Die Netzwerkverzögerung (D) und der Offset (\(\theta\)) können wie folgt berechnet werden:
\begin{align*}
D &= (t4 - t1) - (t3 - t2) = 15 \text{ ms} \\
\theta &= \frac{(t2 - t1) + (t3 - t4)}{2} = -2.5 \text{ ms}
\end{align*}
In diesem Fall beträgt die Netzwerkverzögerung 15 ms und der Offset -2,5 ms. Der Client würde seine Uhr um -2,5 ms anpassen, um mit dem Server synchronisiert zu werden. Wenn jedoch die Netzwerkverzögerung während der Synchronisation plötzlich schwankt, kann dies zu Fehlern bei der Uhrenanpassung führen. Beispielsweise könnte die Netzwerkverzögerung bei der nächsten Synchronisation auf 20 ms ansteigen, was zu einer inkorrekten Berechnung des Offsets und möglicherweise zu einer inkorrekten Uhrenanpassung führen würde.
}
Um Probleme mit Verzögerungen zu vermeiden, verwendet NTP verschiedene Techniken wie die Auswahl mehrerer Zeitserver und die Filterung von Zeitstempeln, um die Genauigkeit der Zeitsynchronisation zu erhöhen und die Auswirkungen von Netzwerkverzögerungsschwankungen zu minimieren.
\\\\
NTP kann eine hohe Genauigkeit beim Abgleich von verteilten Knoten erreichen, wenn es ordnungsgemäß konfiguriert und betrieben wird. Die Genauigkeit von NTP hängt von verschiedenen Faktoren ab, wie der Qualität der Netzwerkverbindungen, der Anzahl und Qualität der Zeitserver, der Latenz und der Stabilität der Verbindungen.

In einem lokalen Netzwerk (LAN) kann NTP eine Genauigkeit von unter 1 Millisekunde erreichen. In einigen Fällen, mit sorgfältiger Konfiguration und unter idealen Bedingungen, kann die Genauigkeit sogar im Bereich von Mikrosekunden liegen. Bei Verwendung von NTP über das Internet kann die Genauigkeit je nach Netzwerkbedingungen und Serverqualität auf 1 bis 50 Millisekunden variieren.
\\\\
Es ist wichtig zu beachten, dass NTP nicht für (harte) Echtzeitanwendungen oder Anwendungen entwickelt wurde, die extrem präzise Zeitsynchronisation erfordern, wie beispielsweise Finanztransaktionen oder wissenschaftliche Experimente. In solchen Fällen kann das Precision Time Protocol (PTP) verwendet werden, das Genauigkeiten im Nanosekundenbereich bieten kann.

\subsubsection{Precision Time Protocol (PTP)}

Das Precision Time Protocol (PTP), definiert in IEEE 1588, ist ein Protokoll zur Zeitsynchronisation von Computern in einem Netzwerk, das höhere Genauigkeit als NTP bietet. PTP wird häufig in Anwendungen eingesetzt, die eine extrem präzise Zeitsynchronisation erfordern, wie beispielsweise Finanztransaktionen oder wissenschaftliche Experimente.
\\\\
PTP verwendet das Master-Slave-Modell für die Zeitsynchronisation, bei dem ein Master-Zeitgeber eine Zeitskala bereitstellt, die von Slave-Zeitgebern im Netzwerk synchronisiert wird. Das Protokoll verwendet Nachrichten wie Sync, Follow\_Up, Delay\_Request und Delay\_Response, um die Synchronisation durchzuführen.
Nachdem der Offset und die Netzwerkverzögerung berechnet wurden, verwendet der Slave-Zeitgeber diese Informationen, um seine Uhr anzupassen und mit der Master-Zeit zu synchronisieren. PTP implementiert auch verschiedene Techniken, um die Genauigkeit zu erhöhen, wie beispielsweise die Verwendung von Hardware-Zeitstempeln und die Best-Master-Clock-Algorithmus zur Auswahl des besten Master-Zeitgebers im Netzwerk.

PTP kann in verschiedenen Topologien und Netzwerken eingesetzt werden, einschließlich LANs, WANs und drahtlosen Netzwerken. PTP unterstützt zwei Profile: das Default Profile und das Power Profile. Das Default Profile ist für allgemeine Anwendungen geeignet, während das Power Profile speziell für den Einsatz in der Energieversorgung optimiert ist.
\\\\
Ein wichtiger Aspekt von PTP ist die Qualität der Taktquelle, die als Taktgenauigkeit bezeichnet wird. Die Taktgenauigkeit wird in Stufen oder Strata klassifiziert, wobei Stratum 1 die höchste Genauigkeit aufweist. PTP verwendet den Best-Master-Clock-Algorithmus (BMCA), um den besten verfügbaren Master im Netzwerk auszuwählen. Der BMCA vergleicht die Taktgenauigkeit, das Stratum und andere Faktoren, um den besten Master auszuwählen. Wenn sich die Taktquelle im Laufe der Zeit ändert, kann der BMCA dynamisch einen neuen Master auswählen, um die Zeitsynchronisation im Netzwerk aufrechtzuerhalten.

Die Fähigkeit von PTP, Genauigkeiten im Nanosekundenbereich zu erreichen, macht es zu einer idealen Lösung für Anwendungen, die eine sehr präzise Zeitsynchronisation erfordern. Allerdings erfordert PTP im Allgemeinen spezielle Hardware-Unterstützung, wie beispielsweise PTP-fähige Netzwerkgeräte und Taktgeneratoren, um seine volle Leistungsfähigkeit auszuschöpfen. Darüber hinaus kann die Implementierung und Konfiguration von PTP komplexer sein als die von NTP.
\\\\
Wie besprochen, erzielt PTP seine hohe Genauigkeit durch den Einsatz von Hardware-Zeitstempeln und speziellen Netzwerkgeräten. Dies bedeutet, dass PTP-Implementierungen tendenziell teurer und komplexer sind als NTP-Implementierungen. NTP spielt hier sehr häufig sein Vorteile als ein softwarebasiertes Protokoll aus, da häufig die Genauigkeit hinsichtlich des Preises an Bedeutung verliert.
Sicher, PTP kann auch ohne Hardwareunterstützung betrieben werden, indem es auf Software-Zeitstempel und Standard-Netzwerkgeräte zurückgreift. Allerdings hat dies einige Konsequenzen:
\begin{itemize}
\item Reduzierte Genauigkeit: Ohne Hardwareunterstützung kann PTP nicht die extrem hohe Genauigkeit im Mikro- bis Nanosekundenbereich erreichen, die es normalerweise bietet. Stattdessen wird die Genauigkeit eher im Mikro- bis Millisekundenbereich liegen, abhängig von den spezifischen Netzwerkbedingungen und der Qualität der Zeitstempel, die von der Software bereitgestellt werden.
\item Größere Empfindlichkeit gegenüber Netzwerklatenz: Bei der Verwendung von Software-Zeitstempeln ist PTP anfälliger für Schwankungen in der Netzwerklatenz und kann daher weniger präzise sein, wenn es darum geht, die tatsächliche Netzwerkverzögerung zu berücksichtigen.
\item Höhere CPU-Auslastung: Da Software-Zeitstempel von der CPU verarbeitet werden, kann die Verwendung von PTP ohne Hardwareunterstützung zu einer höheren CPU-Auslastung führen, insbesondere bei hohen Paketraten oder in großen Netzwerken.
\end{itemize}
In solchen Fällen ist PTP weniger effektiv und sehr häufig nicht besser als NTP geeignet für Anwendungen.

\subsubsection{Cristian's Algorithm}
Cristian's Algorithmus ist ein Zeit-Synchronisationsprotokoll, welches entwickelt wurde, um die Zeitabweichung zwischen einem Zeitserver und einem Client in einem verteilten System zu reduzieren. Der Algorithmus basiert auf der Kommunikation zwischen dem Client und dem Zeitserver, um die Netzwerkverzögerung zu schätzen und die Client-Uhr entsprechend anzupassen.
\\\\
Der Ablauf des Cristian's Algorithmus ist wie folgt:
\begin{enumerate}
\item Der Client sendet eine Anfrage an den Zeitserver, um die aktuelle Zeit zu erfahren.
\item Der Zeitserver empfängt die Anfrage und speichert den aktuellen Zeitstempel T1.
\item Der Zeitserver sendet eine Antwort mit dem Zeitstempel T1 an den Client zurück.
\item Der Client empfängt die Antwort und speichert den aktuellen Zeitstempel T2.
\item Der Client schätzt die Netzwerkverzögerung und passt seine Uhr entsprechend an.
\end{enumerate}
Um die Netzwerkverzögerung zu schätzen, berechnet der Client die Round-Trip-Time (RTT) und teilt sie durch zwei:
\begin{align*}
\text{RTT} &= T2 - T0 \\
\text{Netzwerkverzögerung} &= \frac{\text{RTT}}{2}
\end{align*}
Dann wird der Client seine Uhr auf die empfangene Serverzeit T1 plus die geschätzte Netzwerkverzögerung einstellen:
\begin{align*}
\text{Neue Client-Zeit} &= T1 + \text{Netzwerkverzögerung}
\end{align*}

\examplevs{
Angenommen, ein Client möchte seine Uhr mit einem Zeitserver synchronisieren. Die folgenden Zeitstempel werden während des Prozesses aufgezeichnet:
\begin{itemize}
\item T0 (Anfrage vom Client gesendet): 10:00:00,000
\item T1 (Anfrage vom Server empfangen): 10:00:01,000
\item T2 (Antwort vom Server empfangen): 10:00:01,500
\end{itemize}
Die RTT beträgt:
\begin{align*}
\text{RTT} &= T2 - T0 \
&= 10:00:01,500 - 10:00:00,000 \
&= 1,5\text{ Sekunden}
\end{align*}
Die geschätzte Netzwerkverzögerung beträgt:
\begin{align*}
\text{Netzwerkverzögerung} &= \frac{\text{RTT}}{2} \\
&= \frac{1,5}{2} \\
&= 0,75\text{ Sekunden}
\end{align*}
Die neue Client-Zeit wird auf 10:00:01,000 + 0,75 = 10:00:01,750 eingestellt.
}
Cristian's Algorithmus ist ein einfaches Protokoll zur Zeit-Synchronisation, das aufgrund seiner Einfachheit und Leistungsfähigkeit in vielen Anwendungen eingesetzt werden kann. Es ist jedoch nicht das präziseste Protokoll und wird oft durch fortschrittlichere Protokolle wie NTP oder PTP ersetzt, insbesondere wenn eine höhere Genauigkeit erforderlich ist.
\\\\
Ein Problem bei der Verwendung von Cristian's Algorithmus ist, dass es anfällig für unvorhergesehene Netzwerkverzögerungen und Jitter sein kann, insbesondere wenn das Netzwerk überlastet oder überlastet ist. Dies kann zu inkonsistenten Ergebnissen führen und die Genauigkeit der Zeit-Synchronisation beeinträchtigen.
\examplevs{
Ein Beispiel, in dem Cristian's Algorithmus in der Praxis eingesetzt wird, ist in der Telekommunikationsindustrie zu finden. Hier werden häufig mehrere Netzwerk-Knoten verwendet, um die Übertragung von Sprach- und Datensignalen zu synchronisieren. Cristian's Algorithmus kann verwendet werden, um die Uhrzeit auf diesen Knoten zu synchronisieren und so eine genaue Übertragung von Signalen zu gewährleisten. Allerdings ist es in einigen Fällen möglicherweise nicht genau genug, um den hohen Anforderungen dieser Anwendungen gerecht zu werden, insbesondere wenn die Netzwerkverzögerung schwankt.
}
\subsubsection{Berkeley Algorithm}

Der Berkeley-Algorithmus, benannt nach der University of California, Berkeley, wo er entwickelt wurde, ist ein verteiltes Zeitsynchronisationsprotokoll, welches in Netzwerken eingesetzt wird, um die Uhrzeiten von Computern oder anderen Knoten zu synchronisieren.  Der Berkeley-Algorithmus unterscheidet sich von anderen Zeitsynchronisationsprotokollen wie dem Network Time Protocol (NTP) dadurch, dass er auf einem Master-Slave-Modell basiert und keine Hierarchie von Zeitservern erfordert.
\\\\
Der Berkeley-Algorithmus beruht auf dem grundlegenden Prinzip, dass ein ausgewählter Knoten im Netzwerk, der sogenannte \enquote{Master}, für die Zeitsynchronisation verantwortlich ist. Die anderen Knoten, die als \enquote{Slaves} bezeichnet werden, stellen ihre Uhrzeiten anhand der vom Master bereitgestellten Informationen ein. 
\examplevs{
Der Algorithmus läuft in mehreren Schritten ab, die im Folgenden erläutert werden.

Zunächst wählt der Master zufällig oder auf Grundlage bestimmter Kriterien, wie beispielsweise der Zuverlässigkeit, aus den Knoten im Netzwerk aus. Sobald ein Master festgelegt ist, sendet er eine Anfrage an alle Slave-Knoten, um deren aktuelle Uhrzeiten zu ermitteln. Die Slaves antworten mit ihren jeweiligen Uhrzeiten, und der Master sammelt diese Informationen.

Anschließend berechnet der Master den mittleren Zeitwert der gesammelten Uhrzeiten, wobei er auch seine eigene Uhrzeit berücksichtigt. Der resultierende Mittelwert stellt die referenzierte Synchronisationszeit dar, die an alle Slave-Knoten im Netzwerk weitergegeben wird. Die Slaves aktualisieren daraufhin ihre Uhrzeiten entsprechend der empfangenen Synchronisationszeit.
}
\examplevs{
Ein praxisnahes Beispiel für die Anwendung des Berkeley-Algorithmus könnte ein verteiltes System sein, das aus mehreren Sensoren besteht, die in einer industriellen Anlage Umgebungsdaten wie Temperatur, Druck und Feuchtigkeit erfassen. In einem solchen Szenario ist es wichtig, dass die Sensoren ihre Daten zeitlich korrekt protokollieren, um eine präzise Überwachung und Steuerung der Anlage zu ermöglichen.
Ein Sensor könnte in diesem Fall als Master fungieren und regelmäßig Anfragen an die anderen Sensoren im Netzwerk senden, um deren Uhrzeiten zu ermitteln. Nachdem der Master die Uhrzeiten der anderen Sensoren erhalten und den Mittelwert berechnet hat, teilt er diesen Wert mit den Slave-Sensoren, die daraufhin ihre Uhrzeiten entsprechend aktualisieren. Durch diesen Prozess wird sichergestellt, dass alle Sensoren im Netzwerk synchronisiert sind und die erfassten Daten korrekt zeitlich abgestimmt sind.
}
Mitnehmen kann man, das dieser Ansatz eine effiziente und einfache Methode zur Zeitsynchronisation bietet. Er eignet sich insbesondere für Anwendungen, bei denen eine hohe Genauigkeit der Zeitsynchronisation nicht unbedingt erforderlich ist, da der Algorithmus aufgrund von Netzwerklatenzen und Uhrzeitabweichungen möglicherweise keine extrem präzise Synchronisation erreicht. Dennoch erfüllt der Berkeley-Algorithmus in vielen Fällen die Anforderungen an eine angemessene Zeitsynchronisation und kann die Koordination von Aktionen und die Konsistenz von Daten in verteilten Systemen effektiv gewährleisten.
\examplevs{
Ein weiteres praxisnahes Beispiel für den Einsatz des Berkeley-Algorithmus könnte ein verteiltes System von Computern in einem Unternehmen sein, das gemeinsam an der Verarbeitung von Transaktionen oder der Durchführung von Analysen arbeitet. In diesem Fall wäre es wichtig, dass alle Computer ihre Aufgaben in einer synchronisierten Weise ausführen, um Inkonsistenzen oder Verzögerungen bei der Bearbeitung von Aufgaben zu vermeiden.

Ein zentraler Computer oder Server könnte als Master ausgewählt werden und regelmäßig Zeitabfragen an die anderen Computer im Netzwerk senden. Nachdem der Master die Uhrzeiten der anderen Computer gesammelt hat und den Mittelwert berechnet hat, teilt er die Synchronisationszeit mit den Slave-Computern. Diese passen daraufhin ihre Uhrzeiten entsprechend an, wodurch ein synchronisiertes Verhalten im Netzwerk ermöglicht wird.
}
Obwohl er in vielen Situationen nützlich ist, muss man beachten, dass er nicht immer die optimale Lösung für Zeitsynchronisationsprobleme darstellt. In Szenarien, in denen eine extrem präzise Zeitsynchronisation erforderlich ist oder in denen die Latenzzeiten im Netzwerk erheblich variieren, könnte der Einsatz anderer Synchronisationsprotokolle wie dem Network Time Protocol (NTP) oder dem Precision Time Protocol (PTP) angebracht sein. In diesen Fällen bieten diese Protokolle eine höhere Genauigkeit und Zuverlässigkeit bei der Zeitsynchronisation.
\\\\
%Die Genauigkeit hängt von verschiedenen Faktoren ab, wie zum Beispiel der Netzwerklatenz, der Anzahl der Knoten im Netzwerk und der Häufigkeit, mit der die Synchronisationsanfragen durchgeführt werden. Eine exakte Angabe der Genauigkeit des Algorithmus ist daher schwierig, da sie von den spezifischen Bedingungen des jeweiligen Systems abhängt. Insbesonde die Netzwerklatenz beeinflusst die Genauigkeit des Algorithmus maßgeblich, da sie die Zeitdifferenz zwischen dem Senden und Empfangen von Nachrichten im Netzwerk darstellt. In Systemen mit hohen oder stark variierenden Latenzen kann der Berkeley-Algorithmus Schwierigkeiten haben, eine hohe Genauigkeit bei der Zeitsynchronisation zu erreichen. Die durch Latenz bedingte Ungenauigkeit kann minimiert werden, indem man die Latenzzeit bei der Berechnung der mittleren Uhrzeit berücksichtigt. Allerdings bleibt eine gewisse Ungenauigkeit bestehen, insbesondere in Netzwerken mit stark variierenden Latenzzeiten.
\\\\
Auch die Konvergenzzeit, also die Zeit, die benötigt wird, um eine stabile Synchronisation der Uhrzeiten in einem Netzwerk zu erreichen, hat Abhängigkeiten.  Insbonsere hängt diese von der Häufigkeit ab, mit der der Master Synchronisationsanfragen an die Slaves sendet. Wenn der Master beispielsweise alle 10 Sekunden eine Synchronisationsanfrage sendet, würde es bei einem synchronisierten System möglicherweise mehrere Zyklen von 10 Sekunden dauern, um eine stabile Synchronisation zu erreichen. 
\\\\
Interessant ist noch wahrzunehmen, dass der Berkeley-Algorithmus nicht notwendigerweise auf einer kontinuierlichen Synchronisation basiert. Stattdessen kann die Synchronisation in bestimmten Intervallen oder als Reaktion auf bestimmte Ereignisse stattfinden. In solchen Fällen hängt die Konvergenzzeit von der Häufigkeit dieser Intervalle oder Ereignisse ab

\subsection{Logische Uhren}
Logische Uhren stellen einen grundlegenden Ansatz zur Ordnung von Ereignissen in verteilten Systemen dar, der unabhängig von der tatsächlichen, physischen Zeit funktioniert. Sie wurden 1978 von Leslie Lamport eingeführt und ermöglichen es, eine konsistente, globale Ordnung von Ereignissen in einem verteilten System zu etablieren. Im Gegensatz zu physischen Uhren, die auf einer gemeinsamen Zeitbasis beruhen, basieren logische Uhren auf kausalen Beziehungen zwischen Ereignissen.
\\\\
Mathematisch gesehen repräsentieren logische Uhren eine Funktion $C$ (auch als \enquote{Lamport-Uhr} bezeichnet), die jedem Ereignis $e$ in einem verteilten System einen eindeutigen Zeitstempel $C(e)$ zuweist. Die logischen Zeitstempel sind ganzzahlige Werte, die in einer streng monotonen Weise fortschreiten. Für jeden Prozess $P_i$ in einem verteilten System wird eine separate logische Uhr $C_i$ verwendet, und die Uhr wird bei jedem internen Ereignis inkrementiert.

Die grundlegenden Regeln für logische Uhren sind:
\begin{itemize}
\item Für jeden Prozess $P_i$ wird die logische Uhr $C_i$ bei jedem Ereignis, das innerhalb von $P_i$ auftritt, inkrementiert: $C_i := C_i + 1$.
\item Bei jedem Nachrichtenaustausch zwischen zwei Prozessen $P_i$ und $P_j$ (wobei $P_i$ die Nachricht sendet und $P_j$ sie empfängt) gelten die folgenden Regeln:
\begin{itemize}
\item Die Uhr des sendenden Prozesses $P_i$ wird vor dem Senden der Nachricht inkrementiert: $C_i := C_i + 1$.
\item Die Uhr des empfangenden Prozesses $P_j$ wird auf das Maximum der eigenen Uhr und des empfangenen Zeitstempels (plus eins) gesetzt: $C_j := \max(C_j, C_i + 1)$.
\end{itemize}    
\end{itemize}
\warningvs{
Die \enquote{happens-before} Relation, auch als kausale Ordnung bezeichnet, ist eine binäre Relation $\to$ auf der Menge der Ereignisse in einem verteilten System. Die Relation definiert eine partielle Ordnung auf der Menge der Ereignisse und erfasst die kausalen Beziehungen zwischen den Ereignissen. Mathematisch gesehen ist die \enquote{happens-before} Relation transitiv, asymmetrisch und irreflexiv.
}

Für zwei Ereignisse $e_1$ und $e_2$ gilt die \enquote{happens-before} Relation $e_1 \to e_2$, wenn eine der folgenden Bedingungen erfüllt ist:
\begin{itemize}
\item $e_1$ und $e_2$ sind Ereignisse im selben Prozess, und $e_1$ tritt vor $e_2$ auf.
\item $e_1$ ist das Senden einer Nachricht, und $e_2$ ist das Empfangen dieser Nachricht.
\end{itemize}  
Die logischen Uhren von Lamport ermöglichen es, die \enquote{happens-before} Relation in verteilten Systemen konsistent abzubilden. Wenn $e_1 \to e_2$ gilt, dann ist auch $C(e_1) < C(e_2)$, das heißt, der logische Zeitstempel des Ereignisses $e_1$ ist kleiner als der logische Zeitstempel des Ereignisses $e_2$. Es ist wichtig zu beachten, dass die Umkehrung dieser Aussage nicht unbedingt wahr ist: Wenn $C(e_1) < C(e_2)$, bedeutet dies nicht zwangsläufig, dass $e_1 \to e_2$. Die logischen Uhren erfassen die kausale Ordnung der Ereignisse, können aber keine vollständige Ordnung der Ereignisse liefern.
\examplevs{
Ein Beispiel für die Verwendung von logischen Uhren in einem verteilten System wäre die folgende Ereignisabfolge:
\begin{itemize}
\item Prozess $P_1$ führt ein internes Ereignis aus (Uhrzeit $C_1 = 1$).
\item Prozess $P_2$ führt ein internes Ereignis aus (Uhrzeit $C_2 = 1$).
\item Prozess $P_1$ sendet eine Nachricht an Prozess $P_2$ (Uhrzeit $C_1 = 2$).
\item Prozess $P_2$ empfängt die Nachricht von Prozess $P_1$ (Uhrzeit $C_2 = \max(1, 2) + 1 = 3$).
\end{itemize}  

In diesem Beispiel ist das Ereignis 3 kausal vor dem Ereignis 4, da die Nachricht von $P_1$ an $P_2$ gesendet wird. Die logischen Uhren reflektieren diese kausale Ordnung korrekt, da $C(e_3) < C(e_4)$ gilt. Allerdings kann aus den logischen Uhren allein keine vollständige Ordnung der Ereignisse abgeleitet werden, da beispielsweise die Ereignisse 1 und 2 unabhängig voneinander sind und keine direkte kausale Beziehung besteht.
}
\paragraph{Ordnungsbegriffe\\\\}
In der Theorie der verteilten Systeme werden die Begriffe \enquote{teilweise Ordnung}, \enquote{totale Ordnung} und \enquote{kausale Ordnung} häufig verwendet, um die Beziehungen zwischen Ereignissen in solchen Systemen zu beschreiben.
\\\\
\textbf{Teilweise Ordnung} (oder partielle Ordnung) ist ein Ordnungsprinzip, bei dem nicht alle Elemente verglichen werden müssen. In einem verteilten System bedeutet dies, dass einige Ereignisse nicht direkt miteinander in Beziehung stehen. Zum Beispiel, wenn Ereignisse A und B  in verschiedenen Prozessen geschehen und es gibt keine Kommunikation zwischen diesen Prozessen, dann haben A und B keine bestimmte Ordnung zueinander - sie sind in Bezug aufeinander nicht geordnet.
\\\\
\textbf{Totale Ordnung} hingegen ist ein Ordnungsprinzip, bei dem jedes Paar von Elementen in Beziehung zueinander steht. In einem verteilten System bedeutet dies, dass jedes Ereignis in Bezug auf jedes andere Ereignis geordnet werden kann. Beispielsweise, wenn wir eine globale Uhr hätten, die alle Ereignisse in einem verteilten System markiert, könnten wir eine totale Ordnung aller Ereignisse entsprechend den Zeitstempeln dieser globalen Uhr erstellen.
\\\\
\textbf{Kausale Ordnung} ist eine spezielle Art von teilweiser Ordnung, die die kausalen Beziehungen zwischen den Ereignissen in einem verteilten System darstellt. In einer kausalen Ordnung, wenn ein Ereignis A ein Ereignis B verursacht (direkt oder indirekt), dann wird A immer vor B geordnet. Kausale Ordnung ist besonders wichtig in verteilten Systemen, da sie hilft, die korrekte Ausführung von Operationen in solchen Systemen zu gewährleisten.

Sowohl Lamport-Uhren als auch Vektoruhren sind Mechanismen zur Erfassung dieser kausalen Ordnung in verteilten Systemen. Lamport-Uhren können eine kausale Ordnung erstellen, aber sie können keine konkurrierenden Ereignisse erkennen - Ereignisse, die in Bezug aufeinander nicht geordnet sind. Vektoruhren hingegen können sowohl eine kausale Ordnung erstellen als auch konkurrierende Ereignisse erkennen.

\subsubsection{Lamport Clock}
In einem Transaktionskonzept können Lamport-Uhren verwendet werden, um eine konsistente, globale Ordnung der Transaktionen in einem verteilten System zu etablieren und somit mögliche Konflikte zu erkennen und aufzulösen. Zeitstempel, die auf Lamport-Uhren basieren, werden dabei den Transaktionen zugeordnet, um ihre relative Ordnung im System zu bestimmen.

Betrachten wir ein verteiltes System mit mehreren Prozessen, die Transaktionen ausführen. Wir bezeichnen eine Transaktion als $T_i$, wobei $i$ einen eindeutigen Identifikator für die Transaktion darstellt. 

\importantvs{
Um Lamport-Uhren in diesem Transaktionskonzept einzubinden, verwenden wir die folgenden Schritte:
\begin{itemize}
\item Jeder Prozess $P_j$ im verteilten System führt eine logische Uhr $C_j$ mit. Jedes Mal, wenn ein Prozess eine Transaktion initiiert, wird die logische Uhr $C_j$ inkrementiert, und der Transaktion $T_i$ wird der Zeitstempel $C_j(T_i)$ zugeordnet.

\item Wenn ein Prozess $P_j$ eine Transaktion $T_i$ an einen anderen Prozess $P_k$ sendet, wird die logische Uhr $C_j$ inkrementiert und zusammen mit der Transaktion an $P_k$ gesendet. Bei Empfang der Transaktion wird die logische Uhr $C_k$ des empfangenden Prozesses auf das Maximum von $C_k$ und dem empfangenen Zeitstempel (plus eins) gesetzt: $C_k := \max(C_k, C_j(T_i) + 1)$.

\item Bei der Ausführung von Transaktionen werden die zugeordneten Zeitstempel verwendet, um die relative Ordnung der Transaktionen zu bestimmen und mögliche Konflikte aufzulösen. Zum Beispiel kann ein Konflikt in Form eines schreibgeschützten Zugriffs auf dieselben Daten auftreten. In solchen Fällen kann der Zeitstempel verwendet werden, um die Transaktionen konsistent zu ordnen, indem die Transaktion mit dem kleineren Zeitstempel vor der Transaktion mit dem größeren Zeitstempel ausgeführt wird.
\end{itemize}
}
\examplevs{
Ein praktisches Beispiel für die Anwendung von Lamport-Uhren in einem Transaktionskonzept ist die Google Spanner-Datenbank. Spanner ist eine globale, verteilte Datenbank, die konsistente und konfliktfreie Transaktionen über mehrere Rechenzentren hinweg gewährleistet. Obwohl Spanner in seiner Implementierung nicht ausschließlich auf Lamport-Uhren basiert, verwendet es ein ähnliches Konzept, das als TrueTime bezeichnet wird. TrueTime ermöglicht es, eine globale Ordnung von Ereignissen und Transaktionen in der Spanner-Datenbank herzustellen, indem jedem Ereignis ein Zeitstempel zugeordnet wird, der sowohl aus einer logischen als auch aus einer physischen Komponente besteht.
}
Die Implementierung von Lamport-Uhren in verteilten Systemen bringt einige Herausforderungen mit sich. Einige der wesentlichen Schwierigkeiten sind:
\begin{itemize}
\item Skalierbarkeit: Lamport-Uhren funktionieren gut in kleinen verteilten Systemen, können jedoch bei einer großen Anzahl von Prozessen oder Knoten zu einer erhöhten Kommunikationslast führen. Dies liegt daran, dass jeder Prozess bei der Kommunikation sowohl seinen eigenen Zeitstempel als auch den des empfangenen Ereignisses aktualisieren muss.
\item Unvollständige Ordnung: Obwohl Lamport-Uhren die kausale Ordnung der Ereignisse in verteilten Systemen effektiv abbilden, können sie keine vollständige Ordnung liefern. Das bedeutet, dass bei Ereignissen, die nicht kausal verbunden sind (d. h. sie stehen in keiner \enquote{happens-before} Beziehung), keine eindeutige Ordnung festgelegt werden kann. Dies kann in bestimmten Anwendungen, die eine vollständige Ordnung der Ereignisse erfordern, problematisch sein.
\item Uhrsynchronisation: Lamport-Uhren basieren auf der Annahme, dass alle logischen Uhren in den Prozessen des verteilten Systems unabhängig voneinander funktionieren. In der Praxis kann es jedoch vorkommen, dass einige Prozesse langsamer arbeiten oder ihre Uhren ungenau sind. Diese Unterschiede in der Uhrzeit können zu Inkonsistenzen in der Ordnung der Ereignisse führen.
\item Overhead: Die Verwendung von Lamport-Uhren führt zu einem zusätzlichen Overhead bei der Kommunikation zwischen den Prozessen. Jede Nachricht muss den Zeitstempel des sendenden Prozesses enthalten, und die logischen Uhren müssen bei jedem Nachrichtenaustausch aktualisiert werden. Dies erhöht den Kommunikationsaufwand und die Komplexität der Implementierung.
\item Fehlertoleranz: In verteilten Systemen können Fehler wie Netzwerk- oder Prozessausfälle auftreten. Die Implementierung von Lamport-Uhren muss in der Lage sein, solche Fehler zu erkennen und angemessen darauf zu reagieren, um die konsistente Ordnung der Ereignisse aufrechtzuerhalten.
\end{itemize}
Um einige dieser Herausforderungen zu bewältigen, wurden alternative Ansätze entwickelt. 

\subsubsection{Vector Clock}
Vektoruhren sind eine Erweiterung der Lamport-Uhren, die zur Ordnung von Ereignissen in verteilten Systemen verwendet werden. Im Gegensatz zu Lamport-Uhren, die nur eine partielle Ordnung der Ereignisse ermöglichen, können Vektoruhren eine partielle Ordnungsrelation  über die Ereignisse herstellen, indem sie kausale Beziehungen und Konkurrenz zwischen Ereignissen präzise erfassen. Somit sind, anders als bei der Lamport Uhr, die kausalen Ordnungen auch umkehrbar.
\importantvs{
Mathematisch gesehen besteht eine Vektoruhr aus einem Vektor von Zeitstempeln, wobei jede Komponente des Vektors die Uhr eines bestimmten Prozesses im verteilten System repräsentiert. Wir bezeichnen den Vektor der logischen Uhren für einen Prozess $P_i$ als $V_i$, und die Komponente $V_i[j]$ repräsentiert die logische Uhr von $P_i$ für Prozess $P_j$. Die Vektoruhren folgen den folgenden Regeln:
\begin{itemize}
\item Jeder Prozess $P_i$ im verteilten System führt eine Vektoruhr $V_i$ mit der Länge $n$ (Anzahl der Prozesse im System) und initialisiert alle Komponenten auf Null.

\item Bei jedem internen Ereignis, das innerhalb von $P_i$ auftritt, wird die Komponente $V_i[i]$ der Vektoruhr inkrementiert: $V_i[i] := V_i[i] + 1$.

\item Bei jedem Nachrichtenaustausch zwischen zwei Prozessen $P_i$ und $P_j$ (wobei $P_i$ die Nachricht sendet und $P_j$ sie empfängt) gelten die folgenden Regeln:
\begin{itemize}
\item Die Komponente $V_i[i]$ der sendenden Vektoruhr wird vor dem Senden der Nachricht inkrementiert: $V_i[i] := V_i[i] + 1$.
\item Die Vektoruhr des empfangenden Prozesses $P_j$ wird auf das Elementweises Maximum der eigenen Vektoruhr und der empfangenen Vektoruhr gesetzt: $V_j[k] := \max(V_j[k], V_i[k])$, für $k = 1, 2, \dots, n$.
\end{itemize}
\end{itemize}	
Die Ordnung der Ereignisse in einem verteilten System mit Vektoruhren kann durch die folgenden Relationen definiert werden:
\begin{itemize}
\item $E_1 \to E_2$ (happens-before): Wenn für alle $k$, $V_1[k] \leq V_2[k]$ und für mindestens ein $k$, $V_1[k] < V_2[k]$ gilt.
\item $E_1 \parallel E_2$ (konkurrierend): Wenn für mindestens ein $k$, $V_1[k] < V_2[k]$ und für mindestens ein $k$, $V_2[k] < V_1[k]$ gilt.
\end{itemize}
}
\importantvs{
Um Vektoruhren in einem Transaktionskonzept zu integrieren, können wir die folgenden Schritte ausführen:
\begin{itemize}
\item Jeder Prozess $P_j$ im verteilten System führt eine Vektoruhr $V_j$ mit und weist jeder initiierten Transaktion $T_i$ den aktuellen Vektorzeitstempel $V_j(T_i)$ zu.
\item Bei der Kommunikation zwischen Prozessen zur Koordination von Transaktionen (z. B. zum Sperren von Ressourcen oder zur Synchronisation) werden die Vektoruhren der beteiligten Prozesse entsprechend den oben beschriebenen Regeln aktualisiert.
\item Bei der Ausführung von Transaktionen werden die zugeordneten Vektorzeitstempel verwendet, um die relative Ordnung der Transaktionen zu bestimmen und mögliche Konflikte aufzulösen. Zum Beispiel kann ein Konflikt in Form eines schreibgeschützten Zugriffs auf dieselben Daten auftreten. In solchen Fällen kann der Vektorzeitstempel verwendet werden, um die Transaktionen konsistent zu ordnen, indem die Transaktion, die gemäß der \enquote{happens-before} Relation früher stattfindet, vor der anderen Transaktion ausgeführt wird.
\end{itemize}
}

Ein praktisches Beispiel für die Anwendung von Vektoruhren in einem Transaktionskonzept ist die Implementierung von verteilten Datenbanksystemen, die konsistente und konfliktfreie Transaktionen über mehrere Knoten hinweg gewährleisten müssen. Vektoruhren können dazu verwendet werden, eine globale Ordnung von Ereignissen und Transaktionen in der Datenbank herzustellen und dabei sowohl kausale Beziehungen als auch Konkurrenzverhältnisse präzise abzubilden. Dies ermöglicht es, die Datenbank auf einem konsistenten Zustand zu halten und mögliche Anomalien oder Inkonsistenzen in den verarbeiteten Transaktionen zu vermeiden.


\subsubsection{Conflict-Free Replicated Data Types}
Conflict-Free Replicated Data Types (CRDTs) sind eine Klasse von verteilten Datenstrukturen, die es ermöglichen, Replikationen von Daten in verteilten Systemen auf einfache Weise und ohne Koordination zu aktualisieren und zu synchronisieren. Sie sind besonders nützlich in Anwendungen, in denen es schwierig oder unpraktisch ist, eine globale Synchronisation oder Locking-Strategie einzusetzen. CRDTs bieten eine starke Eventualkonsistenz, was bedeutet, dass alle Replikationen des Datenbestands letztendlich den gleichen Zustand erreichen, solange keine weiteren Updates durchgeführt werden.
\examplevs{
Der mathematische Unterbau von CRDTs basiert auf den Konzepten der Halbgruppen, Monoiden und Gittern. Diese algebraischen Strukturen ermöglichen es, CRDTs durch ihre Operationen und Verknüpfungen zu definieren und deren Konvergenz- und Konsistenz-Eigenschaften zu untersuchen.

Eine Halbgruppe ist eine algebraische Struktur $(S, \cdot)$, bei der $S$ eine Menge und $\cdot$ eine assoziative binäre Operation ist, die zwei Elemente aus $S$ zu einem weiteren Element aus $S$ verknüpft. Eine Halbgruppe wird zu einem Monoid, wenn es ein neutrales Element in $S$ gibt, so dass die Verknüpfung jedes Elements aus $S$ mit dem neutralen Element das ursprüngliche Element unverändert lässt.

Ein Gitter ist eine algebraische Struktur $(L, \wedge, \vee)$, wobei $L$ eine Menge und $\wedge$, $\vee$ zwei binäre Operationen sind, die die Verknüpfung in Form von \enquote{meet} (min) und \enquote{join} (max) darstellen. Ein Gitter erfüllt die Idempotenz-, Kommutativ- und Assoziativgesetze sowie das Absorptionsgesetz.
}
CRDTs können in zwei grundlegende Kategorien eingeteilt werden: operation-basierte CRDTs (CmRDTs) und zustandsbasierte CRDTs (CvRDTs). Bei CmRDTs werden die Operationen auf den Replikationen ausgeführt und die entsprechenden Operationen an die anderen Replikationen weitergegeben. Bei CvRDTs hingegen wird der vollständige Zustand der Replikation übertragen und durch die Verwendung von Lattice-basierten Merge-Funktionen vereinigt.
\paragraph{G-Counter)}\mbox{}\\
Ein grundlegender CvRDT ist der Grow-only Counter (G-Counter). Sein Zustand kann als Monoid $(\mathbb{N}, +, 0)$ dargestellt werden, wobei $\mathbb{N}$ die Menge der natürlichen Zahlen, $+$ die Addition und $0$ das neutrale Element ist. Die G-Counter-Operationen umfassen das Inkrementieren und das Abrufen
des Wertes. Um den G-Counter zu inkrementieren, wird die lokale Replikation des betreffenden Knotens um eins erhöht. Um den Wert des G-Counters abzurufen, werden die Werte aller Replikationen summiert.
\paragraph{2P-Set)}\mbox{}\\
Ein weiteres Beispiel für einen CvRDT ist der 2P-Set (Zwei-Phasen-Set), der das Hinzufügen und Entfernen von Elementen in einem verteilten Set ermöglicht. Der Zustand des 2P-Set kann als Paar von Monoiden dargestellt werden, wobei das erste Monoid $(A, \cup, \emptyset)$ das Hinzufügen von Elementen und das zweite Monoid $(R, \cup, \emptyset)$ das Entfernen von Elementen repräsentiert. Hierbei ist $A$ das \enquote{add}-Set, $R$ das \enquote{remove}-Set, $\cup$ die Vereinigungsmenge und $\emptyset$ die leere Menge als neutrales Element.

Um ein Element $x$ zu einem 2P-Set hinzuzufügen, fügt man es dem \enquote{add}-Set $A$ hinzu. Um ein Element $x$ aus einem 2P-Set zu entfernen, fügt man es dem \enquote{remove}-Set $R$ hinzu. Um den aktuellen Zustand des Sets abzurufen, berechnet man die Differenz zwischen dem \enquote{add}-Set $A$ und dem \enquote{remove}-Set $R$, das heißt $A \setminus R$. Dabei ist es wichtig zu beachten, dass ein entferntes Element nicht erneut hinzugefügt werden kann, da es sich bereits im \enquote{remove}-Set befindet.
\paragraph{Konvergenzeigenschaften von CRDTs )}\mbox{}\\
Die Konvergenzeigenschaften von CRDTs ergeben sich aus den algebraischen Strukturen, auf denen sie basieren. Da sowohl Monoiden als auch Gitter Idempotenz-, Kommutativ- und Assoziativgesetze erfüllen, können Updates auf CRDTs in beliebiger Reihenfolge angewendet werden, ohne die Konsistenz der Daten zu beeinträchtigen. Solange alle Updates schließlich auf allen Replikationen angewendet werden, wird das verteilte System einen konsistenten Zustand erreichen.
\\\\
CRDTs und logische Uhren können gemeinsam verwendet werden, um verteilte Datenstrukturen zu entwickeln, die sowohl zeitliche Kausalität als auch Eventualkonsistenz gewährleisten. Eine Möglichkeit, logische Uhren in CRDTs zu integrieren, besteht darin, die Zustandsinformationen der CRDTs mit Version Vektoren oder Lamport-Zeitstempeln zu versehen.
Ein Version Vektor ist eine Datenstruktur, die für jeden Knoten im verteilten System einen Zähler enthält. Diese Zähler werden bei jedem Update des Knotens inkrementiert und ermöglichen es, die Kausalitätsbeziehungen zwischen den Ereignissen im verteilten System zu bestimmen. Lamport-Zeitstempel sind ähnlich, aber sie verwenden einzelne Zähler für das gesamte System und erhöhen den Zähler bei jedem Ereignis, das auftritt.
\\\\
Durch die Verwendung von logischen Uhren in Kombination mit CRDTs kann man verteilte Datenstrukturen entwickeln, die sowohl kausale Konsistenz als auch Eventualkonsistenz gewährleisten. Ein Beispiel dafür ist das Dot-Context Labeling Schema, das CRDTs mit logischen Uhren verbindet, um kausale verteilte Datenstrukturen zu erstellen, die Ereignisse im verteilten System in der richtigen zeitlichen Reihenfolge betrachten und dabei dennoch eine Eventualkonsistenz aufrechterhalten.

\paragraph{Dot-Context Labeling}\mbox{}\\
Das Dot-Context Labeling Schema wurde entwickelt, um die Schwierigkeiten bei der Verwaltung von verteilten Datenstrukturen zu bewältigen, die sowohl kausale Konsistenz als auch Eventualkonsistenz erfordern. Ein Dot besteht aus einem Paar (i, c), wobei i die ID des Knotens im verteilten System und c der logische Zeitstempel des Knotens zum Zeitpunkt der Erstellung des Elements ist.
\\\\
Die Verwendung von Dots ermöglicht es, den kausalen Zusammenhang zwischen den Elementen in der verteilten Datenstruktur zu bestimmen, indem man ihre Labels vergleicht. Wenn zwei Elemente denselben Dot haben, sind sie identisch. Wenn zwei Elemente unterschiedliche Dots haben und die logischen Zeitstempel ihrer Dots in einer kausalen Beziehung stehen, können sie in der richtigen zeitlichen Reihenfolge betrachtet werden.
\\\\
Um die Eventualkonsistenz aufrechtzuerhalten, verwendet das Dot-Context Labeling Schema auch CRDTs, um die Zustände der verteilten Datenstrukturen zu verwalten und Updates ohne Koordination durchzuführen. Updates auf der Datenstruktur werden durchgeführt, indem die Labels der beteiligten Elemente modifiziert oder die Elemente selbst hinzugefügt oder entfernt werden. Da die Labels der Elemente ihre Kausalitätsbeziehungen widerspiegeln, können diese Updates in beliebiger Reihenfolge angewendet werden, ohne die Konsistenz der Datenstruktur zu beeinträchtigen.
\\\\
Ein praktisches Beispiel, bei dem das Dot-Context Labeling Schema verwendet werden kann, ist ein verteiltes Texteditor-System, bei dem mehrere Benutzer gleichzeitig an einem gemeinsamen Textdokument arbeiten. Ziel ist es, Änderungen an dem Dokument, wie das Hinzufügen oder Entfernen von Text, auf eine kausale und eventual konsistente Weise zu verwalten.
\begin{itemize}
\item Zunächst initialisieren wir das verteilte System mit mehreren Knoten (Benutzern), die jeweils eine Replikation des Textdokuments haben.
\item Jeder Knoten hat eine eindeutige ID und eine logische Uhr, die als Zähler fungiert und bei jedem Update-Ereignis inkrementiert wird.
\item Jeder Buchstabe im Dokument ist ein Element, das ein Dot-Label enthält. Das Label besteht aus der Knoten-ID und dem logischen Zeitstempel, der zum Zeitpunkt der Erstellung des Buchstabens gültig war.
\item Wenn ein Benutzer einen neuen Buchstaben in das Dokument einfügt, erstellt sein Knoten ein neues Element mit einem Dot, das aus seiner Knoten-ID und dem aktuellen Wert seiner logischen Uhr besteht. Anschließend wird die logische Uhr inkrementiert.
\item Wenn ein Benutzer einen Buchstaben aus dem Dokument entfernt, wird das Element entfernt und seine Dot wird verwendet, um die Kausalitätsbeziehungen mit anderen Elementen im Dokument aufrechtzuerhalten.
\item Um Änderungen zwischen den Knoten zu synchronisieren, werden die Updates (einschließlich der hinzugefügten oder entfernten Elemente und ihrer Dots) an die anderen Knoten übermittelt. Da das Dot-Context Labeling Schema auf CRDTs basiert, können diese Updates in beliebiger Reihenfolge angewendet werden, ohne die Konsistenz des Dokuments zu beeinträchtigen.
\item Schließlich wird die kausale Ordnung der Elemente im Dokument anhand ihrer Dot-Labels bestimmt. Dadurch wird sichergestellt, dass das verteilte Textdokument sowohl kausale Konsistenz als auch Eventualkonsistenz aufweist.
\end{itemize}
Das Dot-Context Labeling Schema ermöglicht es in diesem Beispiel, Textänderungen in einem verteilten Texteditor-System effizient und konsistent zu verwalten. Es stellt sicher, dass die Änderungen in der richtigen kausalen Reihenfolge betrachtet werden und das System eine Eventualkonsistenz erreicht, sobald alle Updates auf allen Knoten angewendet wurden.

\subsubsection{Locking}
In verteilten Systemen ist die Koordination von Zugriffen auf gemeinsam genutzte Ressourcen eine wichtige Aufgabe, um Datenkonsistenz und Integrität zu gewährleisten. Eine weit verbreitete Technik zur Koordination solcher Zugriffe ist das \textit{Locking}. Dabei werden Ressourcen gesperrt, um gleichzeitige Zugriffe und damit verbundene Inkonsistenzen zu vermeiden. In diesem Abschnitt geben wir eine Einführung in Locking-Verfahren in verteilten Systemen und diskutieren grundlegende Konzepte und Herausforderungen.
\importantvs{
Ein Locking-Verfahren in verteilten Systemen basiert auf der Idee, dass ein Prozess, der auf eine gemeinsame Ressource zugreifen möchte, zunächst eine Erlaubnis (einen \textit{Lock}) anfordert und erhält. Während ein Prozess einen Lock auf einer Ressource hält, sind andere Prozesse daran gehindert, auf dieselbe Ressource zuzugreifen. Nach Abschluss der Operation gibt der Prozess den Lock wieder frei, sodass andere Prozesse darauf zugreifen können.
}
Es gibt verschiedene Locking-Verfahren, die je nach Anwendungsfall eingesetzt werden, wie beispielsweise \textit{Shared Locks} und \textit{Exclusive Locks}.
\\\\
Ein \textbf{Shared Lock}, auch bekannt als Lese-Sperre, erlaubt es mehreren Prozessen oder Threads, gleichzeitig auf eine bestimmte Ressource zuzugreifen, solange sie diese nur lesen und nicht verändern. Dies ist sinnvoll, wenn die Daten von mehreren Prozessen gleichzeitig gelesen werden müssen und es nicht wichtig ist, ob die Daten während des Lesevorgangs verändert werden. Shared Locks erhöhen die Konkurrenz und verbessern die Leistung, da sie den gleichzeitigen Zugriff auf Ressourcen erlauben, solange keine Änderungen vorgenommen werden.
\\\\
Ein \textbf{Exclusive Lock}, auch bekannt als Schreib-Sperre, erlaubt es dagegen nur einem einzigen Prozess oder Thread, auf eine bestimmte Ressource zuzugreifen. Dieser Lock wird verwendet, wenn ein Prozess oder Thread die Daten verändern muss. Während ein Exclusive Lock gehalten wird, können keine anderen Prozesse oder Threads, auch nicht solche, die nur lesen wollen, auf die Ressource zugreifen. Dies stellt sicher, dass die Daten konsistent bleiben und keine Konflikte oder unerwarteten Zustände auftreten.

In verteilten Systemen ist die Implementierung von Locking-Verfahren komplexer als in zentralisierten Systemen, da Prozesse und Ressourcen über mehrere Knoten verteilt sind. Eine der Herausforderungen besteht darin, einen globalen Zustand der Locks im gesamten verteilten System zu verwalten. Um dies zu erreichen, können zentrale oder dezentrale Koordinatoren verwendet werden. Zentrale Koordinatoren stellen einen einzelnen Anlaufpunkt für Lock-Anforderungen dar, was zu einem Engpass führen kann, während dezentrale Koordinatoren eine bessere Skalierbarkeit ermöglichen, aber auch eine höhere Komplexität aufweisen.

Ein weiteres Problem in verteilten Locking-Systemen ist die Vermeidung von Deadlocks, bei denen zwei oder mehr Prozesse in einem Zustand verharren, in dem jeder auf die Freigabe eines Locks wartet, der von einem anderen gehalten wird. Um Deadlocks zu verhindern oder aufzulösen, können verschiedene Strategien angewendet werden, wie zum Beispiel das Timeout-basierte Abbrechen von Lock-Anforderungen, das Erkennen von Deadlocks und das geordnete Anfordern von Locks.

In verteilten Systemen können verschiedene Locking-Ansätze eingesetzt werden, um den Zugriff auf gemeinsam genutzte Ressourcen zu koordinieren. Im Folgenden werden zwei praktische Beispiele für Locking-Implementierungen in verteilten Systemen vorgestellt.
\paragraph{Zentrale Lock-Manager }\mbox{}\\
Der zentrale Lock-Manager ist die einfachere Lösung, der für die Verwaltung und Zuweisung von Locks für gemeinsam genutzte Ressourcen verantwortlich sein kann. In einem verteilten Datenbankmanagementsystem kann beispielsweise ein zentraler Lock-Manager die Zugriffe auf Tabellen oder Zeilen in der Datenbank koordinieren.

Angenommen, mehrere Transaktionen möchten gleichzeitig auf eine bestimmte Zeile in einer verteilten Datenbank zugreifen. In diesem Fall senden die Transaktionen Lock-Anforderungen an den zentralen Lock-Manager. Der Lock-Manager entscheidet, welcher Transaktion der Zugriff gewährt wird, und sendet eine entsprechende Antwort zurück. Die anderen Transaktionen müssen warten, bis der Lock freigegeben wird. Sobald die Transaktion, die den Lock hält, ihre Arbeit abgeschlossen hat, gibt sie den Lock frei und informiert den zentralen Lock-Manager, der den Lock dann an eine wartende Transaktion weitergibt.
\paragraph{2PL}\mbox{}\\
Das \textbf{Zweiphasen-Locking-Protokoll} (2PL) ist eine gängige Technik zur Sicherstellung der Serialisierbarkeit von Transaktionen in Datenbanksystemen. Es kann auch in verteilten Systemen eingesetzt werden, um die Konsistenz der gemeinsam genutzten Ressourcen zu gewährleisten. Beim zweiphasigen Locking gibt es zwei Phasen: die Lock-Phase, in der Transaktionen Locks auf Ressourcen anfordern, und die Unlock-Phase, in der die Locks freigegeben werden.
\\\\
Angenommen, mehrere Transaktionen möchten in einem verteilten System auf verschiedene Ressourcen zugreifen. Jede Transaktion führt die folgenden Schritte aus:
\begin{itemize}
\item Lock-Phase: Die Transaktion fordert Locks auf den benötigten Ressourcen an. Sie kann entweder Shared Locks (für Lesezugriff) oder Exclusive Locks (für Schreibzugriff) anfordern. Solange die Transaktion weitere Ressourcen benötigt, bleibt sie in der Lock-Phase.
\item Unlock-Phase: Nachdem die Transaktion alle benötigten Ressourcen gesperrt hat, führt sie ihre Operationen aus und gibt anschließend die Locks in der Reihenfolge ihres Erwerbs frei.
\end{itemize}
2PL ist nicht auf einen  zentralen Lock-Manager angewiesen, macht die Implementierung aber bei Weitem einfacher. 

Locking in verteilten Systemen kann eine Reihe von Problemen verursachen, die die Leistung, Skalierbarkeit und Konsistenz des Systems beeinträchtigen können. Hier sind einige der häufigsten Probleme und mögliche Lösungsansätze:
\begin{itemize}
\item Deadlocks: Deadlocks entstehen, wenn zwei oder mehr Prozesse in einem Zustand verharren, in dem jeder auf die Freigabe eines Locks wartet, der von einem anderen gehalten wird. Um Deadlocks zu vermeiden oder aufzulösen, können verschiedene Strategien angewendet werden:
\begin{itemize}
\item Deadlock-Erkennung: Ein Deadlock-Erkennungsalgorithmus kann im System implementiert werden, um zyklische Abhängigkeiten zwischen Prozessen zu identifizieren. Wenn ein Deadlock erkannt wird, kann das System eine der beteiligten Transaktionen abbrechen und ihre Locks freigeben, um den Deadlock aufzulösen.

\item Timeout-basierte Lösung: Jede Transaktion, die auf einen Lock wartet, kann mit einem Timeout versehen werden. Wenn das Timeout abgelaufen ist, wird die Transaktion abgebrochen, und die angeforderten Locks werden freigegeben, wodurch potenzielle Deadlocks vermieden werden.

\item Lock-Hierarchie: Indem Locks in einer bestimmten Reihenfolge angefordert werden, können Deadlocks vermieden werden. Eine Hierarchie oder Ordnung der Ressourcen kann eingeführt werden, sodass Prozesse Locks immer in aufsteigender Reihenfolge anfordern.
\end{itemize}
\item Verzögerungen und Leistungsprobleme: Locking kann zu Verzögerungen und Leistungseinbußen führen, da Prozesse auf die Freigabe von Locks warten müssen. Um solche Probleme zu minimieren, können folgende Techniken eingesetzt werden:
\begin{itemize}
\item Optimistisches Locking: Bei optimistischem Locking werden Locks erst kurz vor der Ausführung der Operationen auf den Ressourcen erworben. Dabei wird angenommen, dass Konflikte selten sind und die Prozesse ohne Verzögerung weiterarbeiten können.

\item Lock-Eskalation: Bei der Lock-Eskalation wird die Granularität der Locks dynamisch angepasst, um die Anzahl der benötigten Locks zu reduzieren. Beispielsweise kann ein Lock auf Tabellenebene in einem Datenbanksystem auf Zeilenebene eskaliert werden, wenn die Anzahl der konkurrierenden Zugriffe abnimmt.
\end{itemize}
\item Verfügbarkeit: Locking kann die Verfügbarkeit von Ressourcen in einem verteilten System beeinträchtigen, insbesondere wenn es zu längeren Wartezeiten oder Knotenausfällen kommt. Um die Verfügbarkeit zu erhöhen, können die folgenden Techniken angewendet werden:
\begin{itemize}
\item Lease-basiertes Locking: Bei diesem Ansatz erhalten Prozesse Locks für einen begrenzten Zeitraum (Lease). Wenn ein Prozess seine Arbeit vor Ablauf der Lease nicht abschließen kann, muss er die Lease verlängern oder den Lock freigeben, wodurch anderen Prozessen der Zugriff ermöglicht wird.

\item Quorum-basiertes Locking: Anstelle von Locks auf einzelnen Knoten kann ein Quorum-basiertes Locking-Verfahren verwendet werden, bei dem eine Mehrheit der Knoten zustimmen muss, um einen Lock zu gewähren. Dadurch wird die Verfügbarkeit erhöht, da nicht auf den Ausfall einzelner Knoten gewartet werden muss.
\end{itemize}
\item Netzwerk-Overhead: Locking in verteilten Systemen kann zu erhöhtem Netzwerk-Overhead führen, insbesondere bei der Kommunikation zwischen Prozessen und Lock-Managern. Um den Netzwerk-Overhead zu minimieren, können folgende Techniken angewendet werden:
\begin{itemize}
\item Lock-Caching: Lock-Informationen können auf Knoten zwischengespeichert werden, um die Anzahl der Kommunikationsanforderungen zwischen Prozessen und Lock-Managern zu reduzieren.
\item Batch-Verarbeitung: Anstatt für jede Ressource einzeln Locks anzufragen, können Prozesse Lock-Anforderungen für mehrere Ressourcen gleichzeitig senden, um die Netzwerkbelastung zu reduzieren.
\end{itemize}
\end{itemize}
\paragraph{Philosophenproblem\\\\}
Das Philosophenproblem, ursprünglich von Edsger Dijkstra formuliert, ist ein klassisches Problem in der Informatik, das sich auf die Synchronisation und das Deadlock-Management in parallelen und verteilten Systemen konzentriert. Im Folgenden wird das Problem beschrieben und auf verteilte Systeme bezogen.
\\\\
Das Problem besteht aus fünf Philosophen, die um einen runden Tisch sitzen. Jeder Philosoph verbringt seine Zeit entweder damit, über philosophische Fragen nachzudenken oder Nudeln zu essen. Zwischen jedem Paar von benachbarten Philosophen liegt eine Gabel. Um Nudeln zu essen, benötigt ein Philosoph zwei Gabeln - die zu seiner Linken und die zu seiner Rechten. Ein Philosoph kann jedoch immer nur eine Gabel zur Verfügung haben, bevor er die andere ergreifen kann. Philosophen dürfen die Gabeln nur aufnehmen, wenn sie verfügbar sind, und müssen sie ablegen, wenn sie mit dem Essen fertig sind.

In verteilten Systemen stellt das Philosophenproblem eine Analogie zu konkurrierenden Prozessen oder Threads dar, die um den Zugriff auf gemeinsame Ressourcen (in diesem Fall Gabeln) konkurrieren. Das Problem veranschaulicht die Herausforderungen bei der Koordination und Synchronisation dieser Prozesse, um Deadlocks, Verhungern (Starvation) und Leistungsprobleme zu vermeiden.

Im Kontext verteilter Systeme können die Philosophen als verteilte Prozesse und die Gabeln als gemeinsame Ressourcen betrachtet werden. Die Hauptprobleme, die bei der Lösung des Philosophenproblems in verteilten Systemen auftreten, sind:
\begin{itemize}
\item Deadlocks: Wenn jeder Philosoph gleichzeitig eine Gabel aufnimmt und auf die andere wartet, entsteht ein Deadlock. Kein Philosoph kann mit dem Essen fortfahren, da jeder auf die Freigabe der anderen Gabel wartet.
\item Verhungern (Starvation): Ein Philosoph könnte verhungern, wenn er immer wieder von anderen Philosophen überstimmt wird, die die Gabeln ergreifen, bevor er sie erreichen kann. In solchen Fällen kommt der betroffene Philosoph möglicherweise nie zum Essen.
\item Leistungsprobleme: Die Leistung des Systems kann beeinträchtigt werden, wenn Philosophen zu lange auf den Zugriff auf Gabeln warten müssen oder wenn ineffiziente Synchronisationsstrategien eingesetzt werden.
\end{itemize}

Um das Philosophenproblem in verteilten Systemen zu lösen, müssen Strategien entwickelt werden, die Deadlocks verhindern, Verhungern minimieren und die Leistung optimieren. Einige mögliche Lösungsansätze sind die Verwendung eines zentralen Koordinators, die Implementierung einer Hierarchie von Ressourcen, die Anwendung von Timeout- oder Lease-basierten Mechanismen und die Nutzung von Quorum-basierten Verfahren. Jeder dieser Ansätze hat seine eigenen Vor- und Nachteile und kann je nach den Anforderungen des spezifischen verteilten Systems angepasst werden.
\importantvs{
Bei der zentralisierten Lösung wird ein zentraler Koordinator verwendet, um die Freigabe und Belegung der Ressourcen (in diesem Fall Gabeln) zu verwalten. Die Philosophen senden Anfragen an den Koordinator, bevor sie versuchen, Gabeln aufzunehmen oder abzulegen. Der Koordinator entscheidet, ob ein Philosoph die angeforderten Gabeln erhalten kann, und antwortet entsprechend.

Für die Implementierung in Java können Sie separate Task für jeden Philosophen erstellen und einen weiteren Task für den zentralen Koordinator. Die Kommunikation zwischen Philosophen und Koordinator kann über eine BlockingQueue erfolgen.
Es ist eine einfache Implementierung, da die Entscheidungslogik zentralisiert ist. Deadlocks können effektiv vermieden werden, indem der Koordinator die Anfragen zur Freigabe und Belegung von Ressourcen verwaltet.
Dennoch existiert ein Single Point of Failure, sprich wenn der zentrale Koordinator ausfällt, kann das gesamte System beeinträchtigt werden.
Ein zentraler Koordinator kann bei sehr großen Systemen mit vielen Prozessen oder Ressourcen zum Flaschenhals werden. Auch die Kommunikation zwischen den Philosophen und dem Koordinator kann zu Verzögerungen führen, insbesondere in weit verteilten Systemen.
Erweitert man diesen Ansatz um eine Hierarchie der Ressourcen sind einige Probleme gelöst, wie eine einfache und effektive Methode zur Vermeidung von Deadlocks.

Versucht man den Ansatz mit den Hierarchien in einen dezentralen Ansatz zu überführen, kann es dennoch zu Verhungern führen, wenn einige Philosophen immer wieder von anderen überstimmt werden.
}
\importantvs{
In der dezentralisierten Lösung gibt es keinen zentralen Koordinator. Stattdessen versuchen die Philosophen selbstständig, Gabeln aufzunehmen und abzulegen, indem sie einige Regeln befolgen, um Deadlocks und Verhungern zu vermeiden. Eine mögliche Strategie ist die Hierarchie der Ressourcen: Jede Gabel wird einer Priorität zugewiesen, und die Philosophen müssen die Gabeln in aufsteigender Reihenfolge der Priorität aufnehmen.

In Java können Sie auch für diesen Ansatz separate Tasks für jeden Philosophen erstellen. Die Philosophen können auf gemeinsame Ressourcen (Gabeln) zugreifen und Lock-Objekte verwenden, um den Zugriff auf die Gabeln zu synchronisieren.
}
Die Wahl des geeigneten Lösungsansatzes für das Philosophenproblem in verteilten Systemen hängt von den spezifischen Anforderungen des Systems und den damit verbundenen Herausforderungen ab. Einige Systeme können von zentralisierten Lösungen profitieren, während andere dezentrale oder quorum-basierte Ansätze bevorzugen. In jedem Fall sollte die Lösung sorgfältig abgewogen und an die Bedürfnisse des Systems angepasst werden, dieses Script bietet im nächsten Kapitel algorithmische Lösungsstrategien an.

\paragraph{Goldene Regel\\\\}
Eine goldene Regel bei physischen Uhren soll aber bereits jetzt herausgestellt werden. 
\warningvs{
Physische Uhren werden nicht zurückgestellt. 
}
Hier sind einige der Hauptgründe, warum das Zurückstellen von Uhren in einem verteilten System problematisch sein kann:
\begin{itemize}
\item Verletzung der Ordnung: Wenn eine Uhr zurückgestellt wird, kann dies dazu führen, dass die Ordnung der Ereignisse und Operationen verletzt wird. In einem verteilten System ist es wichtig, dass die Reihenfolge der Ereignisse und Operationen konsistent ist, um Inkonsistenzen zu vermeiden. Durch das Zurückstellen der Uhr kann es passieren, dass ein Ereignis, das später auftritt, einen älteren Zeitstempel erhält als ein früheres Ereignis, was zu Fehlern und Inkonsistenzen führen kann.
\item Doppelte Zeitstempel: Das Zurückstellen einer Uhr kann dazu führen, dass mehrere Ereignisse denselben Zeitstempel erhalten. Dies kann es schwierig machen, die tatsächliche Reihenfolge der Ereignisse zu bestimmen und kann zu Inkonsistenzen im verteilten System führen.
\item Fehler bei der Synchronisation: In verteilten Systemen, die eine Uhrensynchronisation verwenden, kann das Zurückstellen einer Uhr zu Fehlern bei der Synchronisation führen. Wenn eine Uhr zurückgestellt wird, kann dies dazu führen, dass die anderen Knoten im System ihre Uhren falsch synchronisieren, was zu Inkonsistenzen und Fehlern im gesamten System führen kann.
\item Korrektheitsprobleme: In verteilten Systemen, die auf korrekte zeitliche Abfolgen angewiesen sind, wie beispielsweise verteilte Datenbanken oder Transaktionssysteme, kann das Zurückstellen einer Uhr zu schwerwiegenden Korrektheitsproblemen führen. Beispielsweise können Transaktionen in einer inkorrekten Reihenfolge abgeschlossen werden, was zu Datenverlust oder -korruption führen kann.
\end{itemize}
Um diese Probleme zu vermeiden, ist es wichtig, dass die Uhren in verteilten Systemen nicht zurückgestellt werden. Stattdessen sollte eine geeignete Synchronisationsmethode verwendet werden, um sicherzustellen, dass alle Uhren im System konsistent sind und eine korrekte zeitliche Abfolge von Ereignissen und Operationen gewährleistet ist.

\label{Woche09}
\subsection{Konsensbildung}

In verteilten Systemen besteht eine grundlegende Herausforderung darin, sicherzustellen, dass die verschiedenen Knoten, die das System bilden, übereinstimmende Entscheidungen über ihren Zustand und die Aktionen, die sie ausführen, treffen. Dieser Prozess der Einigung zwischen den Knoten wird als Konsensbildung bezeichnet. Die Konsensbildung ist in solchen Systemen von entscheidender Bedeutung, um die Konsistenz und Verfügbarkeit der Daten und Dienste zu gewährleisten. In diesem Kontext untersuchen wir die Herausforderung der Konsensbildung und geben praktische Beispiele, bei denen diese Herausforderung von zentraler Bedeutung ist.
\subsubsection{Allgemein und klassische Anwendung}
Die Konsensbildung in verteilten Systemen ist aufgrund mehrerer Faktoren schwierig:
\begin{itemize}
\item  Fehlertoleranz: Verteilte Systeme müssen mit einer Vielzahl von Fehlern, wie z. B. Knotenausfällen oder Netzwerkproblemen, umgehen können. Die Konsensbildung muss sicherstellen, dass das System auch bei solchen Fehlern weiterhin konsistent und verfügbar bleibt.

\item Kommunikationslatenz: Die Kommunikation zwischen Knoten in einem verteilten System kann Verzögerungen aufweisen, die die Konsensbildung erschweren. Algorithmen zur Konsensbildung müssen diese Latenz berücksichtigen und dennoch zu einer Übereinkunft kommen.

\item  Sicherheit und Integrität: Die Konsensbildung muss die Integrität der Daten und Dienste gewährleisten und vor böswilligen Angriffen und Manipulationen schützen.
\end{itemize}

Einige praktische Beispiele, bei denen die Herausforderung der Konsensbildung von wesentlicher Bedeutung ist, umfassen:
\begin{itemize}
\item Datenbanken und verteilte Speichersysteme: In verteilten Datenbanken und Speichersystemen ist es entscheidend, dass alle Knoten eine konsistente Sicht auf die gespeicherten Daten haben. Konsensbildungsalgorithmen wie Paxos, Raft oder Zab (ZooKeeper Atomic Broadcast) werden verwendet, um sicherzustellen, dass Schreib- und Lesevorgänge korrekt repliziert und koordiniert werden. 
Paxos und Raft sind zwei bekannte Konsensbildungsalgorithmen, die in verteilten Datenbanken eingesetzt werden. Sie sind darauf ausgelegt, Fehlertoleranz und Konsistenz bei der Verarbeitung von Transaktionen sicherzustellen.

\item Blockchain-Technologie: In Blockchain-Systemen wie Bitcoin und Ethereum ist die Konsensbildung entscheidend, um sicherzustellen, dass alle Knoten im Netzwerk sich über die Gültigkeit von Transaktionen und den aktuellen Zustand der Blockchain einig sind. Die Konsensbildung in Blockchain-Systemen kann durch Proof-of-Work, Proof-of-Stake oder andere konsensbasierte Mechanismen erreicht werden.

\item Verteilte Rechensysteme: In verteilten Rechenumgebungen, wie z. B. Cloud-Plattformen oder High-Performance-Computing-Clustern, müssen die Knoten möglicherweise einen Konsens über den Zustand der Aufgaben und Ressourcen erreichen. Algorithmen zur Konsensbildung können verwendet werden, um die Zuweisung von Ressourcen, die Ausführung von Aufgaben und die Wiederherstellung von Fehlern zu koordinieren. Verteilte Dateisysteme, wie z.B. Hadoop Distributed FileSystem (HDFS) oder Google File System (GFS), erfordern einen Konsens über den Zustand der Dateien und Metadaten, um eine konsistente und effiziente Datenverwaltung zu gewährleisten.
\end{itemize}
Die Konsensbildung in verteilten Systemen ist eine zentrale Herausforderung, die sowohl theoretische als auch sehr praktische Aspekte umfasst. Algorithmen wie Bully, Paxos und Raft werden in den nächsten Kapiteln besprochen, hier soll zunächst ein grundsätzlicher Blick auf die Umsetzung gerichtet werden.

\subsubsection{Quorumsabstimmung}
Die Quorumsabstimmung ist eine Methode zur Erzielung von Konsens in verteilten Systemen. Ein Quorum bezieht sich auf eine minimale Anzahl von Knoten, die an einer Abstimmung teilnehmen müssen, um eine Entscheidung zu treffen.

Die Mathematik hinter Quorumsabstimmungen ist relativ einfach. In einem System mit N Knoten ist das Quorum normalerweise so definiert, dass jede Operation die Zustimmung von mehr als $N/2$ Knoten benötigt. Zum Beispiel, in einem System mit 5 Knoten, müssten mindestens 3 Knoten zustimmen, um ein Quorum zu bilden.
Es ist wichtig zu beachten, dass die Wahl des Quorums ein Kompromiss zwischen Leistung und Zuverlässigkeit darstellt. Ein kleineres Quorum würde die Leistung erhöhen, da weniger Knoten eine Zustimmung geben müssen. Aber es würde auch die Wahrscheinlichkeit erhöhen, dass konsistenzverletzende Operationen auftreten, besonders wenn Knotenausfälle oder Netzwerkpartitionen auftreten. Ein größeres Quorum würde die Zuverlässigkeit erhöhen, aber auch die Leistung beeinträchtigen, da mehr Knoten eine Zustimmung geben müssen.

Es gibt auch weitere fortgeschrittene Quorum-Techniken, wie z.B. gewichtete Quorums oder dynamische Quorums, die mehr Flexibilität bieten und besser auf bestimmte Situationen oder Anforderungen abgestimmt werden können. Aber das grundlegende Prinzip bleibt das gleiche: Eine Mehrheit der Knoten muss zustimmen, um einen Konsens zu erzielen.

Der Prozess der Abstimmung in einem verteilten System muss koordiniert werden, um sicherzustellen, dass alle Knoten eine gemeinsame Sicht auf den Zustand des Systems haben. Diese Koordination wird oft durch einen speziellen Knoten, den sogenannten \enquote{Koordinator} oder \enquote{Leader}, durchgeführt.

Beispielsweise könnte ein einfacher Koordinationsprozess folgendermaßen aussehen:
\begin{itemize}
\item Der Koordinator sendet eine Anfrage an alle anderen Knoten, um eine Abstimmung zu initiieren. Diese Anfrage enthält die Informationen, über die abgestimmt werden soll.
\item Jeder Knoten verarbeitet die Anfrage und sendet seine Stimme zurück an den Koordinator.
\item Der Koordinator sammelt alle Stimmen. Wenn die Mehrheit der Stimmen eine Zustimmung ist (d.h., das Quorum erreicht ist), wird die Operation ausgeführt und das Ergebnis an alle Knoten kommuniziert.
\end{itemize}

Es ist wichtig zu beachten, dass in der Praxis die Koordination von Abstimmungen in verteilten Systemen eine komplexe Aufgabe ist, insbesondere in Anbetracht von Knotenausfällen, Netzwerkverzögerungen und -partitionen. Daher sind Konsensprotokolle wie Paxos und Raft essentiell, um sicherzustellen, dass das System korrekt funktioniert, auch unter schwierigen Bedingungen.

\subsubsection{Zentrale vs dezentrale Konsensbildung}

In zentralisierten Ansätzen zur Konsensbildung in verteilten Systemen wird ein einzelner Knoten, oft als \enquote{Leader} oder \enquote{Koordinator} bezeichnet, verwendet, um die Konsensbildung zu steuern. Dieser Knoten ist verantwortlich für die Initiierung der Abstimmungen, die Sammlung der Stimmen der anderen Knoten und die Entscheidung, ob ein Konsens erreicht wurde. Der Vorteil dieses Ansatzes liegt in seiner Einfachheit, da die Koordination und Kontrolle auf einen einzigen Knoten konzentriert ist. Allerdings hat dieser Ansatz auch Nachteile. Der Koordinator stellt einen Single Point of Failure dar: Wenn der Koordinator ausfällt, kann das System nicht mehr funktionieren, bis der Koordinator wiederhergestellt ist oder ein neuer Koordinator gewählt wird. Zudem kann der Koordinator zu einem Flaschenhals für die Leistung des Systems werden, insbesondere wenn das System eine große Anzahl von Knoten hat oder wenn die Anforderungen an die Konsensbildung hoch sind.

Im Gegensatz dazu, verwendet der dezentralisierte Ansatz zur Konsensbildung keinen zentralen Koordinator. Stattdessen wird die Verantwortung für die Konsensbildung auf alle Knoten im System verteilt. In einem dezentralisierten System stimmt jeder Knoten unabhängig ab, basierend auf seinen eigenen Informationen und den Nachrichten, die er von anderen Knoten erhält. Der Vorteil dieses Ansatzes liegt in seiner Robustheit und Skalierbarkeit: Das System kann weiterhin funktionieren, auch wenn einige Knoten ausfallen, und es kann leicht auf eine große Anzahl von Knoten skaliert werden. Allerdings ist die dezentralisierte Konsensbildung oft komplexer zu implementieren und zu verwalten, und es kann schwieriger sein, sicherzustellen, dass alle Knoten eine konsistente Sicht auf den Zustand des Systems haben.

Hybride Ansätze wie im Raft-Konsensprotokoll angewendet, haben sich in der Praxis als sehr nützlich erwiesen und werden in vielen modernen verteilten Systemen eingesetzt.

Bevor im nächsten Kapitel auf die einzelnen Algorithmen im Detail eingegangen werden sollen, soll sich hier zunächst auf die Unterschiedlichen Ausprägungen konzentriert werden. Als relevante praktische Vertreter sind ZooKeeper Atomic Broadcast (ZAB) und die Blockchain-Mechanismen gewählt.

\subsubsection{Fallbeispiel Zentral: ZooKeeper Atomic Broadcast (ZAB)}

ZooKeeper Atomic Broadcast (ZAB) ist ein Konsensprotokoll, das von Apache ZooKeeper entwickelt wurde, einem verteilten Koordinationsdienst für verteilte Anwendungen. ZAB ermöglicht es den Knoten im ZooKeeper-Ensemble, eine zuverlässige und konsistente Replikation von Updates und eine geordnete Vereinbarung über Änderungen am Systemzustand zu erreichen. Das Ziel von ZAB ist es, die Konsistenz und Verfügbarkeit des Systems auch im Falle von Knotenausfällen oder Netzwerkproblemen aufrechtzuerhalten.

ZAB ist ein Crash-Recovery-Protokoll, was bedeutet, dass es darauf ausgelegt ist, auch dann einen Konsens zu erzielen, wenn Knoten ausfallen und später wiederhergestellt werden. Das Protokoll hat zwei Hauptphasen: die Entdeckungsphase und die Broadcastphase. In der Entdeckungsphase wählen die Knoten einen Anführer, der für das Koordinieren der Änderungen am Systemzustand verantwortlich ist. In der Broadcastphase überträgt der Anführer alle Updates an die Follower-Knoten und stellt sicher, dass die Updates in der richtigen Reihenfolge angewendet werden.
Ein Vorteil von ZAB im Vergleich zu anderen Konsensprotokollen wie Paxos oder Raft ist seine Einfachheit und Leistung, insbesondere in Bezug auf die Latenz bei der Verarbeitung von Updates. ZAB wurde speziell für ZooKeeper entwickelt und ist daher gut auf dessen Anforderungen abgestimmt.

Ein häufiges Anwendungsbeispiel für Apache ZooKeeper und ZAB ist das verteilte Konfigurationsmanagement. In solchen Systemen müssen verteilte Anwendungen und Dienste auf gemeinsame Konfigurationseinstellungen zugreifen und möglicherweise Änderungen an diesen Einstellungen vornehmen. Da mehrere Knoten auf die Konfiguration zugreifen und sie ändern können, ist es entscheidend, dass alle Knoten eine konsistente Sicht auf die Konfiguration haben und Änderungen in einer geordneten Weise repliziert werden.

In diesem Fallbeispiel stellt ZAB sicher, dass alle Änderungen an der verteilten Konfiguration atomar und in der richtigen Reihenfolge auf alle Knoten im ZooKeeper-Ensemble übertragen werden. Dies ermöglicht eine konsistente und zuverlässige Verwaltung der Konfiguration, auch wenn Knoten ausfallen oder Netzwerkprobleme auftreten.

\subsubsection{Fallbeispiel Dezentral: Blockchain-Mechanismen}

In der Welt der Blockchain-Technologie sind Konsensmechanismen entscheidend, um die Sicherheit und Integrität des Netzwerks zu gewährleisten. Sie ermöglichen es den Teilnehmern, eine gemeinsame Vereinbarung über den Zustand der Blockchain und die Gültigkeit von Transaktionen zu erreichen. Es soll versucht werden die Funktionsweise in eine Analogie zu packen. 

Stellen Sie sich eine kleine Gruppe von Menschen vor, die gemeinsam ein Dorf in einem abgelegenen Tal bewohnen. Sie handeln regelmäßig Waren und Dienstleistungen untereinander, um das Leben in ihrem Dorf zu gestalten. Um Transaktionen nachzuvollziehen und sicherzustellen, dass jeder seinen fairen Anteil erhält, haben sie ein System namens \enquote{Blockchain} entwickelt.

Die Blockchain ist wie ein digitales Kassenbuch, in dem alle Transaktionen der Dorfbewohner verzeichnet werden. Anstatt jedoch ein zentrales Kassenbuch zu führen, das von einer einzelnen Person verwaltet wird, gibt es mehrere Kopien, die gleichzeitig auf den Computern der Dorfbewohner gespeichert werden. Auf diese Weise trägt jeder zur Verwaltung und Sicherheit des Systems bei.

Immer wenn eine neue Transaktion stattfindet, wird sie zuerst den anderen Dorfbewohnern zur Überprüfung vorgelegt. Wenn die Mehrheit der Dorfbewohner zustimmt, dass die Transaktion gültig ist, wird sie in einem \enquote{Block} von Transaktionen gespeichert. Dieser Block wird dann an die bestehende Kette von Blöcken angehängt, wodurch eine fortlaufende Aufzeichnung aller Transaktionen entsteht. Um die Integrität der Kette zu gewährleisten, ist jeder Block mit dem vorherigen Block über eine komplexe mathematische Berechnung verknüpft.

Die Verwendung der Blockchain in diesem Szenario ermöglicht es den Dorfbewohnern, Transaktionen auf transparente und sichere Weise abzuwickeln, ohne dass eine zentrale Autorität erforderlich ist. Die Bedeutung von Blockchains für verteilte Systeme liegt in ihrer Fähigkeit, Vertrauen und Zusammenarbeit zwischen verschiedenen Teilnehmern zu fördern, indem sie einen Konsensmechanismus bieten, der Betrug und Manipulation erschwert.

Zu den bekanntesten Konsensmechanismen in Blockchain-Systemen gehören Proof-of-Work und Proof-of-Stake, aber es gibt auch andere Ansätze, die entwickelt wurden, um die Bedürfnisse verschiedener Blockchain-Anwendungen zu erfüllen.

Proof-of-Work (PoW) ist der Konsensmechanismus, der in der ursprünglichen Bitcoin-Blockchain eingesetzt wird. Bei PoW müssen die Teilnehmer des Netzwerks, auch Miner genannt, komplexe kryptografische Rätsel lösen, um neue Blöcke zur Blockchain hinzuzufügen. 

Die Art der Berechnungen soll folgende Erklärung verdeutlichen. Angenommen, wir haben eine Hash-Funktion $H(x)$, die einen Eingabewert $x$ nimmt und einen eindeutigen Hashwert $h$ ausgibt. Die Hash-Funktion hat die Eigenschaften, dass sie kollisionsresistent, deterministisch und rechentechnisch schwer umkehrbar ist.
Ein gültiger Proof-of-Work wird gefunden, indem ein Wert $n$ (genannt Nonce) gesucht wird, sodass der resultierende Hashwert $h$ eine bestimmte Anzahl von führenden Nullen aufweist. Die Schwierigkeit des Rätsels kann durch die Anzahl der erforderlichen führenden Nullen gesteuert werden. Formal kann das PoW-Rätsel wie folgt ausgedrückt werden:

Finden Sie einen Wert $n$ (Nonce), sodass: \\
$H(b \ \Vert \ t \ \Vert \ n) < T$
\begin{itemize}
\item $H(\cdot)$ die Hash-Funktion ist,
\item $b$ der vorherige Block-Hash ist,
\item $t$ die Transaktionen im aktuellen Block repräsentiert,
\item $n$ die Nonce ist,
\item $||$ die Verkettung der Werte darstellt, und
\item $T$ ein Zielwert ist, der die Schwierigkeit des Rätsels bestimmt.
\end{itemize}
Da die Hash-Funktion kryptografisch sicher und schwer umkehrbar ist, gibt es keine bekannte effiziente Methode, um $n$ direkt zu berechnen. Daher verwenden Miner im PoW-Ansatz eine \enquote{brute-force} Methode, bei der sie verschiedene Werte von $n$ ausprobieren, bis sie einen gültigen Hashwert finden, der die Schwierigkeitsanforderungen erfüllt.

Sobald ein Miner einen gültigen Proof-of-Work gefunden hat, wird der neue Block dem Netzwerk zur Validierung vorgelegt. Andere Teilnehmer im Netzwerk können den Proof-of-Work leicht überprüfen, indem sie die Hash-Funktion erneut auf die kombinierten Werte von $b$, $t$ und der vorgeschlagenen Nonce $n$ anwenden und sicherstellen, dass der resultierende Hashwert kleiner als das Ziel $T$ ist.

Dieser Prozess erfordert erhebliche Rechenleistung und Energie, wodurch eine hohe Eintrittsbarriere für potenzielle Angreifer geschaffen wird. Während PoW die Sicherheit des Netzwerks effektiv gewährleistet, führt es auch zu einem hohen Energieverbrauch und möglichen Zentralisierungstendenzen.

Proof-of-Stake (PoS) ist ein alternativer Konsensmechanismus, der entwickelt wurde, um die Energieeffizienz und Dezentralisierung in Blockchain-Netzwerken zu verbessern. Bei PoS basiert die Wahrscheinlichkeit, einen neuen Block zur Blockchain hinzufügen zu dürfen, auf dem Anteil, den ein Teilnehmer am Netzwerk hält. Anstelle von rechenintensiven Rätseln setzen PoS-Systeme auf ökonomische Anreize und Abschreckungsmechanismen, um die Netzwerksicherheit zu gewährleisten. Ethereum, eine der größten Blockchain-Plattformen, plant, von PoW zu PoS zu wechseln, um diese Vorteile zu nutzen.

Neben PoW und PoS gibt es auch andere konsensbasierte Mechanismen, die in verschiedenen Blockchain-Systemen eingesetzt werden. Einige Beispiele sind:
\begin{itemize}
\item Delegated \textbf{Proof-of-Stake} (DPoS): Hier wählen die Netzwerkteilnehmer Delegierte, die in ihrem Namen am Konsensprozess teilnehmen. Dies ermöglicht eine höhere Skalierbarkeit und Effizienz, kann jedoch zu einer gewissen Zentralisierung führen.
\item \textbf{Proof-of-Authority} (PoA): In PoA-Systemen sind vertrauenswürdige und identifizierbare Validatoren für den Konsens verantwortlich. Dies führt zu einer schnellen und effizienten Blockvalidierung, setzt jedoch voraus, dass den ausgewählten Validatoren vertraut wird.
\item \textbf{Practical Byzantine Fault Tolerance} (PBFT): PBFT ist ein Konsensalgorithmus, der darauf abzielt, Fehlertoleranz gegenüber byzantinischen Fehlern in verteilten Systemen zu bieten. PBFT wird in einigen permissioned oder privaten Blockchain-Systemen eingesetzt, in denen die Teilnehmerzahl begrenzt ist und Vertrauen zwischen ihnen besteht.
\end{itemize}
Obwohl Blockchains viele Vorteile bieten, gibt es auch einige Nachteile, die berücksichtigt werden müssen:
\begin{itemize}
\item Skalierbarkeit: Eine der größten Herausforderungen bei Blockchains ist die Skalierbarkeit. Da alle Teilnehmer eine Kopie der gesamten Blockchain besitzen, kann das Netzwerk mit zunehmender Größe und Anzahl der Transaktionen langsamer und weniger effizient werden. Dies kann zu Engpässen und höheren Transaktionskosten führen.
\item Energieverbrauch: Insbesondere bei Blockchains, die auf dem Proof-of-Work-Konsensmechanismus basieren, wie z.B. Bitcoin, ist der Energieverbrauch erheblich. Die Miner, die Transaktionen validieren und neue Blöcke erstellen, müssen komplexe mathematische Probleme lösen, was enorme Rechenleistung und Energie erfordert. Dies hat Umwelt- und Nachhaltigkeitsbedenken aufgeworfen.
\item Anfälligkeit für 51\%-Angriffe: Wenn ein Teilnehmer oder eine Gruppe von Teilnehmern die Kontrolle über mehr als 50\% der Rechenleistung eines Blockchain-Netzwerks erlangt, können sie die Integrität der Blockchain beeinträchtigen, indem sie Transaktionen rückgängig machen oder doppelt ausgeben. Obwohl solche Angriffe selten sind, stellen sie ein potenzielles  Sicherheitsrisiko dar, insbesondere für kleinere und weniger dezentralisierte Blockchains.
\item Datenunveränderlichkeit: Einer der Hauptvorteile von Blockchains ist die Unveränderlichkeit der Daten. Dies kann jedoch auch ein Nachteil sein, wenn fehlerhafte oder illegale Informationen in der Blockchain gespeichert werden, da diese Daten nur schwer zu entfernen oder zu ändern sind.
\item Komplexität und Benutzerfreundlichkeit: Die Technologie hinter Blockchains ist komplex, und für viele Menschen ist das Verständnis und die Nutzung von Blockchain-basierten Anwendungen und Diensten möglicherweise nicht einfach. Dies kann die Akzeptanz und Verbreitung von Blockchains in der breiten Öffentlichkeit einschränken.
\end{itemize}
In vielen Fällen arbeiten Entwickler und Forscher daran, Lösungen für diese Herausforderungen zu finden, um die Technologie noch effizienter und benutzerfreundlicher zu gestalten.

\subsection{Fehlertoleranz}

Selbstverständlich werden Mechanismen in verteilten Systemen in der Regel für voll funktionsfähige Systeme entworfen. Dennoch ist es wichtig zu betonen, dass in einem verteilten System die Fehlersemantik ebenso viel Aufmerksamkeit erfordert wie die Ablaufsemantik – möglicherweise sogar in gewissen Bereichen mehr. In diesem Zusammenhang sollte eine Fehlersituation nicht als Ausnahme angesehen werden, sondern eher als ein zu erwartendes Ereignis. Fehlverhalten gehört zur Anforderungsliste jedes verteilten Systems, da letztendlich jedes System anfällig für Fehler ist.

Kommunikationsprobleme und byzantinische Fehler können die Zuverlässigkeit, Verfügbarkeit und Leistung dieser Systeme beeinträchtigen. Daher ist es von entscheidender Bedeutung, Fehlertoleranztechniken zu implementieren, die solche Systeme in die Lage versetzen, ihre Funktionalität trotz auftretender Fehler aufrechtzuerhalten. Die Hauptziele von Fehlertoleranztechniken sind die Minimierung von Ausfallzeiten, die Sicherstellung von Datenintegrität und -konsistenz sowie die Aufrechterhaltung der Systemverfügbarkeit und Leistung. Grundsätzlich gibt es verschiedene Strategien die mit verschiedenen Fehlertoleranztechniken verbunden sind. Eine grundsätzliche Aufstellung der Fehlertoleranztechniken soll im Folgenden versucht werden. 

\begin{itemize}
\item Redundanz: Redundanz bezieht sich auf das Hinzufügen von zusätzlichen Ressourcen oder Komponenten, um die Auswirkungen von Fehlern zu reduzieren. Dazu gehören:
\begin{itemize}
\item Replikation: Das Duplizieren von Daten oder Diensten auf mehreren Knoten, um die Verfügbarkeit und Fehlertoleranz zu erhöhen.
\item Erasure Coding: Eine Technik zur Aufteilung von Daten in Fragmente, die auf verschiedene Knoten verteilt und später zur Wiederherstellung der Originaldaten verwendet werden.
\end{itemize}
\item Wiederherstellung: Techniken, die darauf abzielen, ein System nach einem Fehler in einen konsistenten Zustand zurückzuführen.
\begin{itemize}
\item Checkpointing: Das regelmäßige Speichern des Systemzustands, um bei Fehlern auf einen früheren, konsistenten Zustand zurückgreifen zu können.
\item Rollback und Rollforward: Mechanismen zur Wiederherstellung des Systemzustands durch Rückgängigmachung oder Wiederholung von Aktionen.
\end{itemize}
\item Fehlertolerante Kommunikationsprotokolle: Protokolle, die auf die Erkennung und Behebung von Kommunikationsfehlern abzielen.
\begin{itemize}
\item Timeout-basierte Protokolle: Verwendung von Zeitfenstern, um auf fehlende Antworten oder fehlgeschlagene Aktionen zu reagieren.
\item Bestätigungsbasierte Protokolle: Verwendung von Bestätigungsnachrichten, um den erfolgreichen Empfang von Informationen sicherzustellen.
\end{itemize}
\item Byzantinische Fehlertoleranz (BFT): Techniken zur Bewältigung von byzantinischen Fehlern, bei denen Knoten fehlerhafte oder böswillige Informationen weitergeben können. BFT-Algorithmen wie Practical Byzantine Fault Tolerance (PBFT) bieten Mechanismen, um den Konsens zwischen den Knoten auch in Gegenwart von byzantinischen Fehlern aufrechtzuerhalten.
\end{itemize}
Die Auswahl der richtigen Fehlertoleranztechniken hängt von den spezifischen Anforderungen des verteilten Systems ab, einschließlich der gewünschten Zuverlässigkeit, Verfügbarkeit und Leistung.

Bevor sich den einzelnen Techniken mit mehr Details gewidmet werden soll, soll der Blick zunächst auf die Diskussion eines Fehlers gerichtet werden. zunächst muss verstanden werden, das Fehler nicht gleich fehler ist. 
\subsubsection{Fehlerarten}
Die Charakterisierung der Fehlerarten hilft dabei, ihre möglichen Auswirkungen auf das System zu erkennen und angemessene Maßnahmen zur Fehlerbehebung und -vermeidung zu ergreifen.
In verteilten Systemen können Fehlerarten in vier Hauptkategorien eingeteilt werden:
\begin{itemize}
\item \textbf{Hardware-Fehler:} Diese Fehler treten auf, wenn die physischen Komponenten des Systems, wie Prozessoren, Speicher oder Netzwerkgeräte, versagen oder beschädigt werden. Hardware-Fehler können aufgrund von Alterung, Herstellungsfehlern, Umgebungseinflüssen oder externen Einwirkungen wie Stromausfällen auftreten.
\item \textbf{Software-Fehler:} Software-Fehler sind Fehler, die aufgrund von Fehlern im Code, Design oder der Implementierung der Software in einem verteilten System entstehen. Beispiele für Software-Fehler sind Programmierfehler, Logikfehler oder fehlerhafte Konfigurationen, die zu inkorrektem Verhalten, Systemabstürzen oder inkonsistenten Zuständen führen können.
\item \textbf{Kommunikationsfehler:} In verteilten Systemen ist die Kommunikation zwischen den Knoten von entscheidender Bedeutung. Kommunikationsfehler treten auf, wenn Nachrichten zwischen den Knoten verloren gehen, verzögert werden oder fehlerhaft sind. Dies kann aufgrund von Netzwerkproblemen, Überlastung oder Fehlern in den Kommunikationsprotokollen geschehen.
\item \textbf{Byzantinische Fehler:} Byzantinische Fehler sind eine besondere Art von Fehlern, bei denen Knoten im verteilten System fehlerhafte, inkonsistente oder böswillige Informationen weitergeben können. Diese Fehler sind schwer zu erkennen und zu beheben, da sie von Fehlern in der Hard- oder Software, menschlichen Fehlern oder sogar böswilligen Angriffen stammen können.
\end{itemize}
In der Literatur zu verteilten Systemen werden die Begriffe \enquote{failure}, \enquote{error} und \enquote{fault} oft verwendet, um unterschiedliche Aspekte von Fehlern und ihren Auswirkungen auf das System zu beschreiben. Es ist wichtig, diese Begriffe korrekt zu verwenden, um Missverständnisse zu vermeiden. Hier ist eine Differenzierung der Begriffe für verteilte Systeme:
\begin{itemize}
\item \textbf{Fault} (Fehler): Ein Fehler ist die zugrundeliegende Ursache für ein inkorrektes Verhalten in einem System. In verteilten Systemen kann ein Fehler aufgrund von Hardware-, Software- oder Kommunikationsproblemen auftreten. Fehler können auch auf menschliche Faktoren wie Fehlkonfiguration oder böswillige Handlungen zurückzuführen sein. Fehler sind der Beginn einer Kette von Ereignissen, die zu einem Ausfall führen können, und sie können auch latente Fehler sein, die erst später im System auftreten.
\item \textbf{Error} (Fehlzustand): Ein Fehlerzustand ist der Teil des Systemzustands, der direkt auf einen Fehler zurückzuführen ist. Wenn ein Fehler auftritt, kann dies dazu führen, dass das System in einen inkonsistenten oder unerwarteten Zustand übergeht. Fehlerzustände sind nicht immer offensichtlich oder sofort erkennbar und können sich im Laufe der Zeit im System ausbreiten oder zu weiteren Fehlern führen.
\item \textbf{Failure} (Ausfall): Ein Ausfall ist das beobachtbare Ergebnis eines Fehlers und tritt auf, wenn das System aufgrund eines Fehlers oder einer Folge von Fehlern nicht in der Lage ist, eine bestimmte Funktion oder Leistung zu erbringen. In verteilten Systemen kann ein Ausfall beispielsweise darin bestehen, dass ein Knoten nicht mehr reagiert, Daten verloren gehen oder inkonsistent sind, oder das gesamte System nicht mehr verfügbar ist.
\end{itemize}
In der Diskussion über verteilte Systeme ist es entscheidend, diese Begriffe klar zu differenzieren, um die verschiedenen Aspekte von Fehlern, ihren Ursachen und Auswirkungen besser zu verstehen und geeignete Fehlertoleranztechniken zu entwickeln, um die Zuverlässigkeit, Verfügbarkeit und Leistung des Systems zu gewährleisten.


\subsubsection{Fehlermodelle}

In verteilten Systemen sind die Begriffe Verfügbarkeit, Zuverlässigkeit, Sicherheit und Wartbarkeit von zentraler Bedeutung und unterscheiden sich in ihren spezifischen Anforderungen und Eigenschaften.
\importantvs{
Die \textbf{Verfügbarkeit} bezieht sich auf die Fähigkeit eines Systems, zu jedem gewünschten Zeitpunkt betriebsbereit und zugänglich zu sein. Verfügbarkeit ist besonders wichtig in Systemen, die kontinuierlichen Betrieb erfordern, wie etwa in Online-Handelsplattformen oder Flugverkehrskontrollsystemen. Verfügbarkeit wird oft in Prozentzahlen ausgedrückt, wobei ein \enquote{Five-Nines} System (99,999\% verfügbar) als hochverfügbar gilt.
}
\importantvs{
Die \textbf{Zuverlässigkeit}  beschäftigt sich mit der Fähigkeit eines Systems, korrekte und konsistente Ergebnisse zu liefern. Ein zuverlässiges System ist eines, das im Laufe der Zeit konsequent und vorhersehbar funktioniert, ohne unerwartete Ausfälle oder Fehlfunktionen. Es ist entscheidend, dass das System bei der Ausführung seiner Aufgaben korrekt und ohne Fehler arbeitet.
}
\importantvs{
\textbf{Sicherheit} bezieht sich auf den Schutz eines Systems vor böswilligen Angriffen oder unbeabsichtigten Schäden. Dies kann den Schutz von Daten vor unbefugtem Zugriff, die Vermeidung von Dienstunterbrechungen durch Angriffe und die Gewährleistung der Integrität von Transaktionen und Daten umfassen. Sicherheit ist in verteilten Systemen eine besondere Herausforderung, da die Daten über mehrere Standorte und möglicherweise über öffentliche Netzwerke hinweg verteilt sind.
}
\importantvs{
Die \textbf{Wartbarkeit} schließlich bezieht sich auf die Fähigkeit, Änderungen an einem System vorzunehmen, sei es zur Behebung von Fehlern, zur Verbesserung der Funktion oder zur Anpassung an neue Anforderungen. Ein gut wartbares System ist eines, das so konzipiert ist, dass es einfach zu verstehen, zu modifizieren und zu verbessern ist. 
}
Dies kann durch gute Software-Design-Praktiken, ausführliche Dokumentation und die Verwendung von Standards und Konventionen erreicht werden.
\begin{itemize}
\item \textbf{Crash failure} tritt auf, wenn ein System plötzlich und ohne Vorwarnung aufhört zu funktionieren, bis zu diesem Zeitpunkt jedoch korrekt gearbeitet hat. Ein Beispiel dafür könnte ein Webserver sein, der plötzlich aufhört, Anfragen zu bearbeiten, möglicherweise aufgrund eines Hardware-Ausfalls oder eines schwerwiegenden Softwarefehlers.
\item \textbf{Omission failure} tritt auf, wenn ein System nicht auf eingehende Anfragen reagiert. Ein Beispiel hierfür könnte ein E-Mail-Server sein, der aufhört, eingehende E-Mails zu akzeptieren, aber weiterhin ausgehende E-Mails sendet.
\item  \textbf{Receive omission} tritt auf, wenn ein System eingehende Nachrichten nicht empfängt. Ein praktisches Beispiel hierfür könnte ein Chat-Server sein, der aufgrund eines Netzwerkproblems keine Nachrichten von Benutzern empfängt.
\item \textbf{Send omission} tritt auf, wenn ein System keine Nachrichten sendet. In einem verteilten Datenbanksystem könnte ein solcher Fehler auftreten, wenn ein Knoten aufgrund eines Fehlers im Netzwerkprotokoll oder einer Fehlfunktion der Netzwerkhardware aufhört, Aktualisierungen an andere Knoten zu senden.
\item \textbf{Timing failure}  tritt auf, wenn eine Antwort außerhalb eines festgelegten Zeitintervalls liegt. Ein Beispiel hierfür wäre ein Online-Auktionshaus, bei dem Gebote, die nach Ablauf der Auktionszeit eintreffen, nicht berücksichtigt werden.
\item \textbf{Response failure} tritt auf, wenn die Antwort inkorrekt ist. Dies könnte in einem verteilten Berechnungssystem auftreten, wenn ein Knoten fehlerhafte Berechnungen durchführt und falsche Ergebnisse zurückgibt.
\item \textbf{Value failure}  tritt auf, wenn der Wert der Antwort falsch ist. Ein Beispiel hierfür könnte ein Währungsumrechnungsservice sein, der falsche Umrechnungsraten liefert.
\item \textbf{State-transition failure} tritt auf, wenn das System vom korrekten Ablauf der Steuerung abweicht. Ein Beispiel hierfür könnte ein verteiltes Workflow-System sein, in dem eine Aufgabe ausgelassen oder in der falschen Reihenfolge ausgeführt wird.
\item \textbf{Arbitrary failure} tritt auf, wenn das System in einer Weise versagt, die nicht durch die anderen Fehlermodelle erfasst wird. Dies könnte alles umfassen, von unvorhersehbarem Verhalten aufgrund von Software-Bugs bis hin zu unerwarteten Effekten aufgrund von Hardware-Ausfällen. Ein Beispiel für einen beliebigen Fehler könnte ein verteiltes File-Sharing-System sein, das aufgrund eines unerwarteten Datenkorruptionsproblems beginnt, beschädigte Dateien zu verteilen.
\end{itemize}
Die Fehlersemantik bei der Nachrichtenübertragung in asynchronen und synchronen Systemen kann sich aufgrund der unterschiedlichen Charakteristika und Anforderungen dieser Systeme erheblich unterscheiden.
\importantvs{
In einem \textbf{synchronen System} gibt es strenge Timing-Anforderungen, und Nachrichten müssen innerhalb einer bestimmten Zeit übertragen und verarbeitet werden. Fehler können hier zum Beispiel auftreten, wenn eine Nachricht nicht innerhalb des erwarteten Zeitintervalls ankommt oder wenn die Verarbeitung einer Nachricht zu lange dauert. In solchen Fällen kann das System ein Timeout implementieren, bei dem es einen Fehler meldet, wenn eine Nachricht nicht innerhalb einer bestimmten Zeit ankommt oder verarbeitet wird. Des Weiteren können Fehler bei der Synchronisation auftreten, wenn beispielsweise die Uhrzeiten der Systemkomponenten nicht korrekt synchronisiert sind.
}
\importantvs{
In \textbf{asynchronen Systemen} hingegen gibt es keine festen Timing-Anforderungen, und Nachrichten können zu beliebigen Zeiten übertragen und verarbeitet werden. Fehler können hier zum Beispiel auftreten, wenn eine Nachricht verloren geht oder in der falschen Reihenfolge ankommt. Da es keine festen Timing-Anforderungen gibt, können solche Fehler schwieriger zu erkennen und zu handhaben sein. Oftmals werden Techniken wie Sequenznummern oder Quittungen verwendet, um die korrekte Übertragung und Reihenfolge von Nachrichten zu gewährleisten.
}
Darüber hinaus kann es in beiden Arten von Systemen zu Übertragungsfehlern kommen, wenn beispielsweise Nachrichten aufgrund von Netzwerkproblemen verloren gehen oder beschädigt werden. In solchen Fällen können verschiedene Fehlererkennungs- und -korrekturtechniken verwendet werden, wie z. B. Prüfsummen, um die Integrität der übertragenen Daten zu überprüfen, oder Wiederholungsanfragen, um verlorene oder beschädigte Nachrichten erneut zu senden.
\\\\
Halting-Fehler oder Crash-Fehler in verteilten Systemen treten auf, wenn ein Knoten (oder mehrere Knoten) plötzlich und ohne Vorwarnung aufhört zu funktionieren, obwohl er bis zu diesem Zeitpunkt korrekt gearbeitet hat. Diese Art von Fehlern kann auf verschiedene Weisen klassifiziert werden, basierend auf verschiedenen Kriterien:
\begin{itemize}
\item Dauer des Ausfalls: Wenn der Ausfall vorübergehend ist und das System nach einer gewissen Zeit wieder normal funktioniert, spricht man von einem transienten Fehler. Ein permanentes Versagen tritt auf, wenn das System nicht in der Lage ist, sich selbst zu erholen und manuell repariert oder ersetzt werden muss.
\item Ursache des Ausfalls: Hardware-Fehler können aufgrund von physischen Schäden oder Verschleiß der Hardware-Komponenten auftreten. Software-Fehler können durch Bugs, Konfigurationsfehler oder andere Probleme in der Software entstehen. Netzwerkfehler treten auf, wenn Probleme in der Netzwerkkonnektivität dazu führen, dass Knoten nicht miteinander kommunizieren können.
\item Reichweite des Ausfalls: Ein Einzelpunktfehler tritt auf, wenn nur ein einzelner Knoten im System ausfällt. Bei einem koordinierten Ausfall fallen mehrere Knoten gleichzeitig aus, möglicherweise aufgrund eines gemeinsamen Problems wie eines Stromausfalls oder eines Netzwerkausfalls. Ein nicht-koordinierter Ausfall tritt auf, wenn mehrere Knoten unabhängig voneinander ausfallen.
\item Vorhersehbarkeit des Ausfalls: Ein deterministischer Ausfall tritt auf, wenn der Ausfall vorhersehbar ist, beispielsweise wenn ein Knoten aufgrund von bekannten Hardware-Problemen oder Software-Bugs ausfällt. Ein nicht-deterministischer Ausfall tritt auf, wenn der Ausfall nicht vorhersehbar ist, beispielsweise aufgrund von zufälligen Hardware-Fehlern oder unvorhergesehenen Software-Problemen.
\end{itemize} 
Diese Fehlerarten in einem System können jeweils durch unterschiedliche Verhaltensweisen und Auswirkungen gekennzeichnet sein.
\begin{itemize}
\item Ein Fail-Stop-Fehler tritt auf, wenn ein System bei einem Fehler aufhört zu funktionieren und diesen Zustand deutlich signalisiert. Andere Komponenten im System können diesen Ausfall erkennen und darauf reagieren. Ein Beispiel könnte ein Server sein, der bei einem Hardware-Fehler abstürzt und eine Fehlermeldung an ein Überwachungssystem sendet.

\item Fail-Noisy-Fehler sind solche, bei denen das System bei einem Fehler weiterhin aktiv bleibt, aber in einer Art und Weise funktioniert, die den Fehler deutlich erkennen lässt. Beispielsweise könnte ein Netzwerkgerät, das fehlerhafte Datenpakete sendet, als ein \enquote{lauter} Fehler betrachtet werden, da die beschädigten Datenpakete leicht erkennbar sind.

\item Fail-Silent-Fehler hingegen sind solche, bei denen das System bei einem Fehler aufhört zu funktionieren, ohne dass dies von anderen Komponenten im System erkannt werden kann. Ein Beispiel wäre ein Server, der plötzlich aufhört, auf Anfragen zu antworten, ohne einen erkennbaren Fehlerstatus zu senden.

\item Fail-Safe-Fehler beziehen sich auf Situationen, in denen ein System so ausgelegt ist, dass es bei einem Fehler in einen sicheren Zustand übergeht. Beispielsweise könnte ein verteiltes Steuerungssystem für eine Fabrik bei einem Fehler in einen Zustand übergehen, in dem alle Maschinen angehalten werden, um Schäden oder Gefahren zu vermeiden.

\item Fail-Arbitrary-Fehler, auch als Byzantinische Fehler bekannt, sind die schwerwiegendsten und schwierigsten zu handhaben. Bei dieser Art von Fehler kann das System in einer Weise ausfallen, die nicht vorhersehbar und möglicherweise irreführend ist. Ein Knoten in einem verteilten System könnte beispielsweise inkonsistente Informationen an andere Knoten senden, was zu Fehlern und Inkonsistenzen in der gesamten Systemoperation führen kann.
\end{itemize}
Jede dieser Fehlerarten erfordert unterschiedliche Strategien zur Fehlererkennung, -behandlung und -erholung. Bei der Gestaltung von verteilten Systemen müssen diese verschiedenen Arten von Fehlern berücksichtigt werden, um die Zuverlässigkeit und Robustheit des Systems zu gewährleisten.

\subsubsection{Redundanz}
Redundanz bezeichnet in der Informatik und speziell in verteilten Systemen die absichtliche Duplikation von Systemkomponenten, Informationen oder Funktionen zur Steigerung der Zuverlässigkeit und Verfügbarkeit. Redundanz kann dazu beitragen, Ausfälle zu überstehen, die Leistung zu verbessern und die Fehlertoleranz zu erhöhen.

In verteilten Systemen kann Redundanz auf verschiedenen Ebenen implementiert werden, einschließlich Datenredundanz, Rechenredundanz und Kommunikationsredundanz.
\begin{itemize}
\item \textbf{Datenredundanz:} Dabei werden mehrere Kopien der gleichen Daten auf unterschiedlichen Knoten im verteilten System gespeichert. Dies kann dazu beitragen, Datenverluste bei Ausfällen einzelner Knoten zu vermeiden und gleichzeitig die Datenverfügbarkeit zu erhöhen. Ein Beispiel für eine solche Strategie ist die Replikation von Daten in verteilten Datenbanksystemen. Hier werden die Daten auf mehrere Server repliziert, sodass bei Ausfall eines Servers die Daten auf den verbleibenden Servern weiterhin verfügbar sind.
\item \textbf{Rechenredundanz:} Bei dieser Art der Redundanz werden Berechnungen auf mehreren Knoten im verteilten System parallel ausgeführt. Dies erhöht die Zuverlässigkeit, da bei Ausfall eines Knotens andere Knoten die Ergebnisse liefern können. Ein Beispiel hierfür ist das MapReduce-Modell, das in groß angelegten Datenverarbeitungsaufgaben wie z.B. bei Google und Hadoop eingesetzt wird. Bei MapReduce werden die Daten auf mehrere Knoten aufgeteilt (Map-Phase), die ihre Teilaufgaben unabhängig voneinander ausführen. Die Ergebnisse werden dann in der Reduce-Phase zusammengeführt.
\item \textbf{Kommunikationsredundanz:} Diese Form der Redundanz beinhaltet die Bereitstellung von mehreren Kommunikationspfaden zwischen den Knoten in einem verteilten System. Im Falle eines Netzwerkausfalls können Nachrichten über alternative Pfade übertragen werden, was die Kommunikationszuverlässigkeit und -verfügbarkeit erhöht.
\end{itemize}
In verteilten Systemen ist die Widerstandsfähigkeit von Prozessen (Process Resilience) ein zentraler Aspekt der Redundanz und bezieht sich auf die Fähigkeit des Systems, trotz Prozessausfällen korrekt und effizient zu funktionieren. Ein solches System ist in der Lage, einzelne oder sogar mehrere gleichzeitige Prozessausfälle zu überstehen, ohne dass die Gesamtfunktionalität des Systems beeinträchtigt wird.

Die Widerstandsfähigkeit von Prozessen kann durch verschiedene Strategien verbessert werden, einschließlich Prozessreplikation, Prozessüberwachung und Wiederherstellung von Prozessen.
\begin{itemize}
\item Prozessreplikation: Bei dieser Strategie werden mehrere Instanzen eines Prozesses auf verschiedenen Knoten im verteilten System ausgeführt. Dies bedeutet, dass bei Ausfall einer Prozessinstanz eine andere Instanz den Betrieb fortsetzen kann. Die Replikation kann auf verschiedene Weisen erfolgen, beispielsweise durch aktive Replikation, bei der alle Prozessinstanzen die gleiche Arbeit parallel ausführen, oder passive Replikation, bei der eine Instanz (der Primärprozess) die Arbeit ausführt und die anderen Instanzen (Sekundärprozesse) bereitstehen, um im Falle eines Ausfalls des Primärprozesses die Arbeit zu übernehmen.
\item Prozessüberwachung: Hierbei werden die Prozesse im verteilten System ständig überwacht, um potenzielle Ausfälle zu erkennen. Bei Erkennung eines Prozessausfalls kann das System automatisch Gegenmaßnahmen einleiten, beispielsweise durch Starten einer neuen Prozessinstanz auf einem anderen Knoten.
\item Wiederherstellung von Prozessen: Wenn ein Prozess ausfällt, kann das System versuchen, den Prozess wiederherzustellen, beispielsweise durch Neustart des Prozesses oder durch Migration des Prozesses zu einem anderen, funktionierenden Knoten. Um den Zustand des ausgefallenen Prozesses wiederherzustellen, kann das System Checkpointing-Techniken verwenden, bei denen der Zustand des Prozesses in regelmäßigen Abständen gespeichert wird.
\end{itemize}
Die Implementierung von Prozessresilienz in verteilten Systemen kann jedoch auch Herausforderungen mit sich bringen, wie z.B. die Notwendigkeit zur Koordination zwischen Prozessinstanzen zur Aufrechterhaltung der Konsistenz, erhöhter Ressourcenverbrauch durch Prozessreplikation und Überwachung, und die Komplexität der Wiederherstellung von Prozessen. 

\subsubsection{Replikation}

Replikation ist eine grundlegende Technik in verteilten Systemen, die darauf abzielt, Daten und Dienste auf mehreren Knoten oder Komponenten zu duplizieren. Dies trägt dazu bei, die Zuverlässigkeit, Verfügbarkeit und Skalierbarkeit des Systems zu verbessern. Durch die Anwendung von Replikation in verteilten Systemen können verschiedene Vorteile erzielt werden.
\\\\
Zunächst erhöht die Replikation die Verfügbarkeit von Daten und Diensten. Indem mehrere Kopien von Daten und Diensten auf verschiedenen Knoten im System gespeichert werden, können Benutzer auch bei Ausfällen einzelner Knoten oder Netzwerkverbindungen weiterhin auf die benötigten Ressourcen zugreifen.

Ein weiterer Vorteil der Replikation besteht darin, dass sie die Zuverlässigkeit des verteilten Systems verbessert. Durch das Vorhandensein mehrerer Kopien von Daten und Diensten können Hardwarefehler oder Kommunikationsprobleme besser aufgefangen werden. Das System kann weiterhin funktionieren, indem es einfach auf eine andere, funktionierende Kopie der benötigten Daten oder Dienste zugreift.
\\\\
Die Skalierbarkeit von verteilten Systemen kann ebenfalls durch Replikation verbessert werden. Durch das Duplizieren von Daten und Diensten auf mehreren Knoten kann das System Leistungsengpässe vermeiden und eine größere Anzahl von Benutzeranfragen verarbeiten. Dies geschieht durch Lastverteilung, bei der Anfragen auf verschiedene Knoten verteilt werden, um die Arbeitslast effektiv zu bewältigen.

Schließlich ermöglicht Replikation auch eine schnellere Wiederherstellung nach Ausfällen. Wenn ein Knoten ausfällt, kann das System seine Daten und Dienste aus einer der anderen Repliken wiederherstellen und so die Ausfallzeit und den Datenverlust minimieren.
\\\\
Eine Möglichkeit, die Replikation umzusetzen, besteht darin, permanent Kopien der Daten auf mehreren Knoten im System zu halten. Dies stellt sicher, dass alle Replikate immer auf dem neuesten Stand sind und die Datenverfügbarkeit maximiert wird.
\importantvs{
Eine weitere Möglichkeit ist die \textbf{serverinitiierte Replikation}, bei der der Server eine Aktualisierung der Daten auf alle Knoten im System überträgt. Dies ist nützlich, wenn es eine zentrale Datenquelle gibt, von der aus alle Knoten aktualisiert werden müssen. Die serverinitiierte Replikation kann auch dazu beitragen, die Netzwerkbelastung zu reduzieren, da die Übertragung von Daten von einem zentralen Ort ausgeht.
}
\importantvs{
\textbf{Clientinitiierte Replikation} ist ein weiterer Ansatz, bei dem Clients selbstständig Änderungen an einer Kopie der Daten vornehmen und diese Änderungen an andere Knoten im System übertragen. Dies ist nützlich, wenn es viele Clients gibt, die auf die Daten zugreifen und Änderungen vornehmen müssen.
}
Anwendungsbeispiele für Replikation sind vielfältig und umfassen die Datenspeicherung in der Cloud, verteilte Datenbanken, Webanwendungen, Peer-to-Peer-Netzwerke und viele andere Anwendungen. Zum Beispiel kann eine verteilte Datenbank mithilfe von Replikation eine höhere Verfügbarkeit und Zuverlässigkeit erreichen, indem sie Kopien der Daten auf mehrere Knoten im System hält. Wenn ein Knoten ausfällt oder nicht erreichbar ist, können andere Knoten die Arbeit fortsetzen und auf die Daten zugreifen.

\paragraph{Passive und aktive Replikation}\mbox{}\\
Passive und aktive Replikation sind zwei weitere Ansätze, um Daten und Dienste in verteilten Systemen zu duplizieren. Beide haben unterschiedliche Vorteile und Herausforderungen.

\textbf{Passive Replikation}, auch als Primär-Backup-Replikation oder Master-Slave-Replikation bezeichnet, besteht darin, dass ein einziger Knoten, der Primärknoten, alle eingehenden Anfragen bearbeitet und die Änderungen auf die Daten anwendet. Die anderen Knoten, die sogenannten Backup-Knoten, halten Kopien der Daten und warten auf Aktualisierungen vom Primärknoten. Im Falle eines Ausfalls des Primärknotens wird einer der Backup-Knoten zum neuen Primärknoten. Der Hauptvorteil der passiven Replikation besteht darin, dass sie eine einfachere Konsistenzverwaltung ermöglicht, da alle Änderungen an den Daten durch den Primärknoten gesteuert werden. Allerdings kann dies auch zu einem Engpass in der Leistung führen, da alle Anfragen vom Primärknoten bearbeitet werden müssen.

\textbf{Aktive Replikation}, auch als Multi-Master- oder State-Machine-Replikation bezeichnet, bedeutet, dass alle Knoten im System gleichzeitig eingehende Anfragen bearbeiten und Änderungen auf ihren Daten vornehmen können. In diesem Ansatz muss das System sicherstellen, dass die Änderungen auf allen Knoten konsistent sind, was eine sorgfältige Koordination und Konsistenzverwaltung erfordert. Der Hauptvorteil der aktiven Replikation besteht darin, dass sie eine bessere Skalierbarkeit und Leistung bietet, da Anfragen auf mehrere Knoten verteilt werden können. Allerdings ist die Konsistenzverwaltung in diesem Ansatz komplexer und erfordert den Einsatz von Konsensalgorithmen und anderen Mechanismen, um die Konsistenz der Daten auf allen Knoten aufrechtzuerhalten.
\paragraph{Cold, warm, hot}\mbox{}\\
\textbf{Cold}, \textbf{Warm} und \textbf{Hot} Replikation sind Begriffe, die verwendet werden, um unterschiedliche Grade der Verfügbarkeit und Aktualität von replizierten Daten und Diensten in verteilten Systemen zu beschreiben. Diese Begriffe helfen dabei, die verschiedenen Replikationsstrategien hinsichtlich ihrer Leistung und Auswirkungen auf die Wiederherstellung nach Ausfällen besser zu verstehen.
\begin{itemize}
\item Cold Replikation (kalte Replikation): Bei der Cold Replikation werden die Daten in regelmäßigen Abständen, aber nicht in Echtzeit, zwischen dem Primärknoten und den Backup-Knoten synchronisiert. Kalte Replikation ist die am wenigsten aktuelle Form der Replikation und wird häufig für Backup- und Archivierungszwecke eingesetzt. Im Falle eines Ausfalls kann die Wiederherstellung der Daten aus einer Cold-Replikation mehr Zeit in Anspruch nehmen, da die Daten möglicherweise nicht auf dem neuesten Stand sind und zusätzliche Schritte erforderlich sind, um den Backup-Knoten in Betrieb zu nehmen.
\item Warm Replikation (warme Replikation): Warme Replikation ist ein Zwischenansatz, bei dem die Daten in relativ kurzen Intervallen, aber immer noch nicht in Echtzeit, zwischen den Knoten synchronisiert werden. Warme Replikation bietet eine höhere Verfügbarkeit als kalte Replikation und ist schneller bei der Wiederherstellung nach einem Ausfall. In diesem Szenario sind die Backup-Knoten in der Regel besser vorbereitet, um die Last des ausgefallenen Knotens zu übernehmen, und es besteht eine geringere Wahrscheinlichkeit, dass Datenverluste auftreten.
\item Hot Replikation (heiße Replikation): Bei der Hot Replikation werden die Daten nahezu in Echtzeit zwischen den Knoten synchronisiert, wodurch eine hohe Verfügbarkeit und Aktualität der replizierten Daten gewährleistet wird. Bei einem Ausfall kann ein Backup-Knoten sofort die Last des ausgefallenen Knotens übernehmen, wodurch die Ausfallzeit minimiert wird. Hot Replikation ist die anspruchsvollste Form der Replikation und erfordert eine engmaschige Koordination zwischen den Knoten, um die Konsistenz der Daten aufrechtzuerhalten.
\end{itemize}

\paragraph{Replilkation zum Mittel der Redundanz\\\\}
Replilkation ist neben Leistungssteigerung (Load Balancing) und zum Mittel der Redundanz auch geeignet mit Fehlersituation optimierter zu verfahren.
Die Anzahl der erforderlichen Replikationen hängt dann von der Art des Fehlers und den Anforderungen an die Zuverlässigkeit und Fehlertoleranz des verteilten Systems ab. Im Allgemeinen gilt: 
\begin{itemize}
\item \textbf{$2k$} Replikationen: Diese Anzahl von Replikationen ist typischerweise ausreichend für Systeme, die lediglich Crash-Fehler (auch Absturzfehler oder fail-stop-Fehler genannt) tolerieren müssen. Crash-Fehler treten auf, wenn ein Knoten plötzlich ausfällt und nicht mehr reagiert, aber keine inkorrekten Ergebnisse oder Informationen liefert. In einem System, das gegen k Crash-Fehler geschützt ist, sind $2k$ Replikationen ausreichend, um weiterhin korrekt zu funktionieren.
\item \textbf{$2k+1$} Replikationen: Für Systeme, die nicht nur Crash-Fehler, sondern auch sogenannte Omission-Fehler (Auslassungsfehler) tolerieren müssen, sind 2k+1 Replikationen erforderlich. Bei Omission-Fehlern liefert ein Knoten möglicherweise keine Informationen, auch wenn er dazu aufgefordert wird. Mit 2k+1 Replikationen kann das System in der Regel eine Mehrheitsentscheidung treffen und trotz $k$ fehlerhafter Knoten korrekt arbeiten.
\item \textbf{$3k+1$} Replikationen: Um byzantinische Fehler tolerieren zu können, bei denen ein Knoten unvorhersehbare, inkonsistente oder bösartige Informationen liefert, sind $3k+1$ Replikationen erforderlich. Dies ermöglicht eine Mehrheitsentscheidung (zwei Drittel der Knoten) und stellt sicher, dass das System auch bei einer Anzahl von bis zu k fehlerhaften Knoten korrekt funktioniert.
\end{itemize}
Die genaue Anzahl der erforderlichen Replikationen hängt von den spezifischen Anforderungen und der Fehlerart ab, gegen die das verteilte System abgesichert werden soll. Im Allgemeinen benötigen Systeme, die byzantinische Fehler tolerieren müssen, mehr Replikationen als solche, die nur Crash- oder Omission-Fehler berücksichtigen.

\subsubsection{Erasure Coding}
Erasure Coding ist eine Technik zur Datenredundanz und Fehlerkorrektur, die in verteilten Systemen und Speichersystemen eingesetzt wird. Im Gegensatz zur Replikation, bei der vollständige Kopien von Daten auf verschiedenen Knoten gespeichert werden, teilt Erasure Coding die Daten in kleinere Fragmente auf und erstellt zusätzliche kodierte Fragmente, die sogenannten Paritätsinformationen. Diese Fragmente werden dann auf verschiedene Knoten verteilt. Der Hauptvorteil von Erasure Coding besteht darin, dass es eine höhere Speichereffizienz und Widerstandsfähigkeit gegen Ausfälle bietet als herkömmliche Replikationsmethoden, da weniger Redundanz benötigt wird, um die gleiche Fehlertoleranz zu erreichen.

Ein Erasure Coding-Schema wird üblicherweise als (n, k)-Schema bezeichnet, wobei k die Anzahl der ursprünglichen Datenfragmente und n die Anzahl der insgesamt erstellten Fragmente (einschließlich der Paritätsfragmente) ist. Um die ursprünglichen Daten wiederherzustellen, sind mindestens k der n Fragmente erforderlich. Dies bedeutet, dass das System den Verlust von bis zu n-k Fragmenten tolerieren kann, ohne dass Datenverlust auftritt.
\\\\
Ein einfaches Anwendungsbeispiel für Erasure Coding ist ein verteiltes Speichersystem, das große Dateien speichert. Nehmen wir an, wir haben eine große Datei, die in vier Datenfragmente (k = 4) aufgeteilt wird. Anschließend erstellen wir zwei Paritätsfragmente (n-k = 2) mithilfe eines Erasure Coding-Verfahrens. Die Datei besteht nun aus insgesamt sechs Fragmenten (n = 6). Diese Fragmente werden auf sechs verschiedene Knoten in unserem verteilten Speichersystem verteilt.

Wenn nun einer oder sogar zwei der Knoten ausfallen, können wir die ursprüngliche Datei immer noch aus den verbleibenden vier Fragmenten rekonstruieren. Dies bietet eine höhere Speichereffizienz und Fehlertoleranz als eine vollständige Replikation der Datei auf mehreren Knoten, bei der mehr Speicherplatz und Bandbreite benötigt würden.

Erasure Coding wird häufig in verteilten Speichersystemen wie Hadoop HDFS, Ceph und verschiedenen Cloud-Speicherdiensten wie Amazon S3 und Google Cloud Storage eingesetzt, um eine effiziente Datenredundanz und Fehlertoleranz zu gewährleisten.
\\\\
Erasure Coding bietet verschiedene Vorteile gegenüber traditionellen Replikationsmethoden, insbesondere in Bezug auf Speichereffizienz und Widerstandsfähigkeit gegen Ausfälle. In Anbetracht der wachsenden Datenmengen und der steigenden Anforderungen an verteilte Systeme ist es wichtig, effiziente und fehlertolerante Speichertechniken zu nutzen, um eine hohe Verfügbarkeit und Zuverlässigkeit zu gewährleisten.

Es gibt verschiedene Erasure Coding-Verfahren, die auf unterschiedlichen mathematischen Grundlagen basieren. Zu den bekanntesten zählen Reed-Solomon-Codes, Cauchy-Reed-Solomon-Codes und Tornado-Codes. Die Wahl des richtigen Erasure Coding-Verfahrens hängt von den spezifischen Anforderungen des verteilten Systems und den Leistungszielen ab.
\\\\
Ein wichtiger Aspekt bei der Anwendung von Erasure Coding ist die fragmentierte Datenverarbeitung, insbesondere wenn es darum geht, Operationen wie Updates oder Lesezugriffe auf die Daten durchzuführen. Da die Daten in Fragmente aufgeteilt und verteilt gespeichert werden, müssen verteilte Systeme diese Fragmentierung berücksichtigen und Operationen entsprechend koordinieren. Dies kann zu einer erhöhten Komplexität in der Verarbeitung und Verwaltung von Daten führen, insbesondere in Systemen mit hoher Dynamik und ständig wechselnden Anforderungen.

Ein weiterer wichtiger Aspekt ist die Datenwiederherstellung nach Ausfällen. Obwohl Erasure Coding eine hohe Fehlertoleranz bietet, kann die Wiederherstellung der Daten unter Umständen zeitaufwändiger und rechenintensiver sein als bei traditionellen Replikationsmethoden. Dies liegt daran, dass die Paritätsinformationen zur Rekonstruktion der ursprünglichen Daten verwendet werden müssen, was zusätzliche Rechenressourcen erfordert.

\subsubsection{Fehlertoleranz durch Wiederherstellung}

Fehlertoleranz durch Wiederherstellung ist eine Methode, bei der verteilte Systeme in der Lage sind, nach einem Fehler oder Ausfall wieder in einen korrekten Zustand zurückzukehren. Dieser Ansatz konzentriert sich darauf, Systemausfälle zu erkennen und darauf zu reagieren, indem ein Verfahren zur Wiederherstellung des betroffenen Teils des Systems oder der gesamten Anwendung eingeleitet wird. Die Wiederherstellung kann auf verschiedenen Ebenen des verteilten Systems erfolgen, beispielsweise auf Prozessebene, Knotenebene oder auf der Ebene des gesamten verteilten Systems.

Einige gängige Techniken zur Fehlertoleranz durch Wiederherstellung sind:
\begin{itemize}
\item \textbf{Checkpointing:} Dabei handelt es sich um eine Technik, bei der der Zustand eines Systems oder einer Anwendung in regelmäßigen Abständen gespeichert wird. Im Falle eines Fehlers kann das System auf den zuletzt gespeicherten Zustand zurückgesetzt und von dort aus weitergeführt werden. Checkpointing kann auf Prozessebene, auf Knotenebene oder für das gesamte verteilte System angewendet werden.
\item \textbf{Nachrichtenprotokollierung:} Bei dieser Methode werden alle eingehenden und ausgehenden Nachrichten eines Knotens oder Prozesses protokolliert. Im Falle eines Ausfalls kann das System die protokollierten Nachrichten verwenden, um den Zustand des Knotens oder Prozesses wiederherzustellen und seine Ausführung fortzusetzen.
\item \textbf{Rollback-Recovery:} Hierbei handelt es sich um eine Technik, bei der das System nach einem Fehler auf einen früheren, konsistenten Zustand zurückgesetzt wird. Rollback-Recovery kann sowohl auf Prozessebene als auch auf Systemebene angewendet werden und verwendet häufig Checkpointing oder Nachrichtenprotokollierung, um den korrekten Zustand wiederherzustellen.
\end{itemize}  
Anwendungsbeispiele für Fehlertoleranz durch Wiederherstellung:
\begin{itemize}
\item Datenbankmanagementsysteme (DBMS): DBMS verwenden Transaktionsverwaltung und Wiederherstellungstechniken, um die Konsistenz und Integrität von Daten bei Systemausfällen oder Softwarefehlern zu gewährleisten. Beispiele hierfür sind das ARIES-Wiederherstellungsverfahren in relationalen Datenbanken und das Write-Ahead-Logging (WAL) in Systemen wie PostgreSQL.
\item HPC (High-Performance Computing): In HPC-Systemen, die häufig komplexe und rechenintensive Aufgaben ausführen, wird häufig Checkpointing eingesetzt, um den Fortschritt der Berechnungen zu speichern und im Falle eines Ausfalls wiederherzustellen.
\item Verteilte Dateisysteme: In verteilten Dateisystemen wie Hadoop HDFS oder Ceph werden Wiederherstellungstechniken eingesetzt, um die Verfügbarkeit und Zuverlässigkeit von Daten bei Knotenausfällen oder Netzwerkstörungen zu gewährleisten.
\end{itemize} 
Insgesamt ist Fehlertoleranz durch Wiederherstellung ein wichtiger Ansatz zur Gewährleistung der Zuverlässigkeit und Verfügbarkeit von verteilten Systemen. Durch die Kombination von Wiederherstellungstechniken mit anderen fehlertoleranten Strategien, wie zum Beispiel Replikation oder Erasure Coding, können verteilte Systeme eine hohe Verfügbarkeit und Robustheit gegenüber verschiedenen Arten von Fehlern und Ausfällen erreichen.
\begin{itemize}
\item Verteilte Messaging-Systeme: In verteilten Messaging-Systemen wie Apache Kafka oder RabbitMQ werden Wiederherstellungstechniken verwendet, um die Konsistenz und Integrität von Nachrichten in der Nachrichtenwarteschlange bei Systemausfällen oder Netzwerkstörungen sicherzustellen.
\item Cloud-Computing-Plattformen: Cloud-Anbieter wie Amazon Web Services (AWS), Google Cloud Platform (GCP) oder Microsoft Azure nutzen Wiederherstellungstechniken, um die Verfügbarkeit und Zuverlässigkeit von Diensten und Anwendungen in ihren verteilten Infrastrukturen zu gewährleisten. Beispiele hierfür sind automatische Backups und Snapshots von virtuellen Maschinen, die im Falle eines Ausfalls wiederhergestellt werden können.
\end{itemize}
Um Fehlertoleranz durch Wiederherstellung effektiv zu implementieren, sollten verteilte Systeme folgende Aspekte berücksichtigen:
\begin{itemize}
\item Die Auswahl der geeigneten Wiederherstellungstechnik, abhängig von den Anforderungen und der Art der Anwendung oder des Systems.
\item Die Kosten und der Zeitaufwand für die Wiederherstellung, insbesondere in Bezug auf die Speicherung und Verwaltung von Checkpoints, Nachrichtenprotokollen oder Backups.
\item Die Auswirkungen von Wiederherstellungsmaßnahmen auf die Leistung und Verfügbarkeit des verteilten Systems, insbesondere in Bezug auf die Latenz und den Durchsatz von Anwendungen oder Diensten.
\item Die Integration von Wiederherstellungstechniken in das verteilte System, um einen nahtlosen und automatisierten Wiederherstellungsprozess im Falle eines Ausfalls zu ermöglichen.
\end{itemize}
Durch die sorgfältige Planung und Implementierung von Wiederherstellungstechniken können verteilte Systeme eine hohe Fehlertoleranz erreichen und sicherstellen, dass sie auch unter ungünstigen Bedingungen weiterhin zuverlässig und effizient funktionieren.

\subsubsection{Fehlertolerante Kommunikationsprotokolle}

Fehlertolerante Kommunikationsprotokolle sind entscheidend für die Zuverlässigkeit und Verfügbarkeit von verteilten Systemen. Sie ermöglichen den Austausch von Informationen zwischen Knoten oder Prozessen, auch bei Fehlern, Ausfällen oder Netzwerkstörungen. Es gibt verschiedene Klassen von fehlertoleranten Kommunikationsprotokollen, die auf unterschiedlichen Strategien basieren, um Fehler zu erkennen und darauf zu reagieren. Dazu gehören Timeout-basierte Protokolle, Bestätigungsbasierte Protokolle und Protokolle für den Umgang mit Netzwerkpartitionen.

\begin{itemize}
\item Timeout-basierte Protokolle verwenden einen Timer, um die maximale Zeit festzulegen, die auf eine Antwort oder Aktion gewartet werden soll. Wenn die Antwort innerhalb des festgelegten Zeitfensters nicht eintrifft, wird angenommen, dass ein Fehler aufgetreten ist, und entsprechende Maßnahmen werden ergriffen, wie zum Beispiel das erneute Senden einer Nachricht oder das Auslösen einer Fehlermeldung. Timeout-basierte Protokolle sind nützlich, um Kommunikationsfehler oder Knotenausfälle zu erkennen, können jedoch bei falsch konfigurierten Timeout-Werten zu falschen Fehlererkennungen oder unnötigem Overhead führen.
\item Bestätigungsbasierte Protokolle nutzen Quittungen oder Bestätigungsnachrichten, um sicherzustellen, dass Informationen erfolgreich zwischen den Knoten ausgetauscht wurden. Bei diesem Ansatz sendet der Empfänger einer Nachricht eine Bestätigungsnachricht zurück, um dem Sender mitzuteilen, dass die Nachricht erfolgreich empfangen wurde. Wenn der Sender keine Bestätigung erhält, wird die Nachricht erneut gesendet oder ein Fehlerprotokoll erstellt. Bestätigungsbasierte Protokolle verbessern die Zuverlässigkeit der Kommunikation, indem sie sicherstellen, dass keine Nachrichten verloren gehen, können jedoch zu erhöhtem Nachrichtenaufkommen und Latenz führen.
\item Netzwerkpartitionen treten auf, wenn Teile eines verteilten Systems aufgrund von Netzwerkstörungen oder -ausfällen nicht miteinander kommunizieren können. Protokolle für den Umgang mit Netzwerkpartitionen zielen darauf ab, die Funktionsfähigkeit und Konsistenz des Systems auch bei solchen Ereignissen aufrechtzuerhalten. Beispiele für solche Protokolle sind das CAP-Theorem, das besagt, dass verteilte Systeme nur zwei von drei Eigenschaften – Konsistenz, Verfügbarkeit und Partitionstoleranz – gleichzeitig erfüllen können, oder das FLP-Unmöglichkeitsergebnis, das zeigt, dass in asynchronen verteilten Systemen kein deterministischer Konsens erreicht werden kann, wenn ein einziger Prozess ausfallen kann.
\end{itemize}
Insgesamt sind fehlertolerante Kommunikationsprotokolle von grundlegender Bedeutung für den Betrieb und die Zuverlässigkeit von verteilten Systemen. Durch den Einsatz dieser Protokolle können verteilte Systeme trotz möglicher Fehler und Störungen weiterhin effektiv und konsistent arbeiten. Bei der Auswahl und Implementierung von fehlertoleranten Kommunikationsprotokollen sollten Entwickler und Systemarchitekten die Anforderungen und Eigenschaften ihrer verteilten Systeme sorgfältig abwägen, um die beste Balance zwischen Zuverlässigkeit, Verfügbarkeit, Latenz und Overhead zu finden.
Einige bewährte Vorgehensweisen bei der Implementierung fehlertoleranter Kommunikationsprotokolle sind:
\begin{itemize}
\item Anpassung von Timeout-Werten: Die Auswahl angemessener Timeout-Werte ist entscheidend für die Leistung von Timeout-basierten Protokollen. Zu kurze Timeout-Werte können zu häufigen Fehlalarmen und unnötigem Overhead führen, während zu lange Werte die Fähigkeit des Systems beeinträchtigen können, auf Fehler schnell zu reagieren.
\item Verwendung von adaptiven Timeout-Strategien: In einigen Fällen kann es sinnvoll sein, adaptive Timeout-Strategien zu verwenden, bei denen die Timeout-Werte basierend auf beobachteten Latenzmustern oder Netzwerkbedingungen dynamisch angepasst werden.
\item Begrenzung der Anzahl der Wiederholungsversuche: Bei Bestätigungsbasierten Protokollen ist es wichtig, die Anzahl der Wiederholungsversuche zu begrenzen, um die Latenz und den Overhead zu minimieren. Eine zu hohe Anzahl von Wiederholungen kann zu Netzwerküberlastung und verschlechterter Systemleistung führen.
\item Berücksichtigung der Systemanforderungen und Trade-offs: Bei der Auswahl von fehlertoleranten Kommunikationsprotokollen sollten die Anforderungen und Trade-offs des verteilten Systems berücksichtigt werden, wie zum Beispiel die Notwendigkeit, Konsistenz, Verfügbarkeit oder Partitionstoleranz zu priorisieren.
\item Kombination von fehlertoleranten Protokollen: In vielen Fällen kann es sinnvoll sein, verschiedene fehlertolerante Protokolle zu kombinieren, um ein umfassendes Kommunikationssystem zu schaffen, das in der Lage ist, unterschiedliche Fehlerbedingungen und Anforderungen zu bewältigen.
\end{itemize}
Durch die Anwendung dieser bewährten Verfahren und die sorgfältige Auswahl der geeigneten fehlertoleranten Kommunikationsprotokolle können Entwickler und Systemarchitekten verteilte Systeme schaffen, die sowohl robust als auch zuverlässig sind, und den Herausforderungen einer fehleranfälligen, verteilten Umgebung erfolgreich begegnen.


\subsubsection{Lastverteilung}
Lastverteilung ist ein zentraler Aspekt in verteilten Systemen, um eine effiziente Nutzung der Ressourcen sicherzustellen und die Gesamtleistung des Systems zu optimieren. Sie ist besonders relevant im Kontext der Replikation, wo mehrere Kopien der gleichen Daten oder Prozesse auf verschiedenen Knoten im System vorhanden sind. Die Lastverteilung kann in zwei Haupttypen unterteilt werden: statische Lastverteilung und dynamische Lastverteilung.

Statische Lastverteilung beruht auf einer vorab festgelegten Strategie zur Zuweisung von Lasten (z.B. Anfragen oder Aufgaben) an die Knoten im System. Die Entscheidung, welche Last an welchen Knoten gesendet wird, wird in der Regel zum Zeitpunkt der Systeminitialisierung getroffen und bleibt während der Laufzeit des Systems unverändert. Eine häufig verwendete Methode für statische Lastverteilung ist die Round-Robin-Technik, bei der die Last gleichmäßig und in zyklischer Reihenfolge auf die Knoten verteilt wird.

Mathematisch lässt sich die statische Lastverteilung als eine Funktion $f: L \to N$ darstellen, wobei $L$ die Menge aller Lasten und $N$ die Menge aller Knoten repräsentiert. Die Funktion $f$ weist jeder Last $l \in L$ einen Knoten $n \in N$ zu, an den die Last gesendet wird.

Dynamische Lastverteilung hingegen passt die Lastzuweisung an die aktuellen Bedingungen im System an. Sie berücksichtigt Faktoren wie die aktuelle Auslastung der Knoten, die Netzwerklatenz und möglicherweise auch die Art der Last. Dynamische Lastverteilung erfordert ein System zur Überwachung der Systemzustände und eine Mechanik zur Neuzuweisung der Last basierend auf den überwachten Zuständen.

Mathematisch lässt sich die dynamische Lastverteilung als eine zeitabhängige Funktion $f(t): L \to N$ darstellen, wobei $t$ die Zeit darstellt. Die Funktion $f(t)$ weist jeder Last $l \in L$ zu jedem Zeitpunkt $t$ einen Knoten $n \in N$ zu.

In beiden Fällen ist das Ziel der Lastverteilung, eine gute Balance der Lasten auf den Knoten zu erreichen, um Engpässe zu vermeiden und die Ressourcen effizient zu nutzen. Im Kontext der Replikation kann die Lastverteilung dazu beitragen, die Verfügbarkeit und Leistung des Systems zu verbessern, indem sie die Last auf die replizierten Knoten verteilt und so die Wahrscheinlichkeit von Knotenausfällen reduziert. Jedoch erfordert dynamische Lastverteilung zusätzliche Ressourcen für die Überwachung des Systemzustands und die Entscheidungsfindung, während statische Lastverteilung möglicherweise nicht optimal auf Änderungen der Systembedingungen reagieren kann.

Angenommen, wir haben ein verteiltes System mit vier Knoten (N1, N2, N3 und N4) und eine Sammlung von Aufgaben, die ausgeführt werden müssen.

Im Fall der statischen Lastverteilung könnten wir eine Round-Robin-Strategie verwenden, um die Aufgaben gleichmäßig auf die Knoten zu verteilen. Angenommen, wir haben acht Aufgaben (A1 bis A8), dann könnten die Aufgaben wie folgt verteilt werden:
\begin{itemize}
\item N1 erhält A1 und A5
\item N2 erhält A2 und A6
\item N3 erhält A3 und A7
\item N4 erhält A4 und A8
\end{itemize}
Diese Art der Lastverteilung ist einfach zu implementieren und erfordert keine Überwachung der Systemzustände. Sie kann jedoch in Situationen, in denen die Knoten unterschiedlich leistungsfähig sind oder unterschiedliche Auslastungen aufweisen, zu ineffizienter Ressourcennutzung führen.

Angenommen, N1 und N2 sind leistungsstärker als N3 und N4. In diesem Fall würde die statische Lastverteilung dazu führen, dass N1 und N2 unterausgelastet sind, während N3 und N4 überlastet sind.

Im Fall der dynamischen Lastverteilung könnten wir eine Strategie verwenden, die die aktuelle Auslastung der Knoten berücksichtigt. Angenommen, wir haben ein Überwachungssystem, das die Auslastung der Knoten ermittelt und die Aufgaben auf der Grundlage dieser Informationen verteilt. Dann könnten die Aufgaben wie folgt verteilt werden:
\begin{itemize}
\item N1 erhält A1, A2 und A3 (da N1 leistungsstark und wenig ausgelastet ist)
\item N2 erhält A4, A5 und A6 (da N2 leistungsstark und wenig ausgelastet ist)
\item N3 erhält A7 (da N3 weniger leistungsstark und stärker ausgelastet ist)
\item N4 erhält A8 (da N4 weniger leistungsstark und stärker ausgelastet ist)
\end{itemize}
Diese Art der Lastverteilung kann zu einer effizienteren Ressourcennutzung führen, da sie die Leistungsfähigkeit und Auslastung der Knoten berücksichtigt. Sie erfordert jedoch ein Überwachungssystem und zusätzliche Ressourcen für die Entscheidungsfindung.

Alternative Umsetzungen könnten beispielsweise Least-Connection (der Knoten mit den wenigsten aktiven Verbindungen erhält die nächste Aufgabe), Weighted Distribution (jeder Knoten erhält Aufgaben entsprechend seinem zugewiesenen Gewicht, das seine Leistungsfähigkeit repräsentiert), oder Random Distribution (Aufgaben werden zufällig auf die Knoten verteilt) sein. Jede dieser Strategien hat ihre eigenen Vor- und Nachteile und kann je nach den spezifischen Anforderungen und Eigenschaften des verteilten Systems besser geeignet sein.

\subsubsection{Anti-Entropy-(Repair)}
Anti-Entropie ist ein Begriff, der in verteilten Systemen verwendet wird, um Verfahren zu beschreiben, die darauf abzielen, die Konsistenz zwischen verschiedenen Knoten oder Replikaten im System zu gewährleisten. Insbesondere bezieht sich Anti-Entropie auf Mechanismen, die dafür sorgen, dass alle Repliken eines bestimmten Datenelements den gleichen Zustand aufweisen, selbst in Anbetracht von Updates, Netzwerklatenzen oder Ausfällen.

In der Theorie der Information ist Entropie ein Maß für die Unsicherheit oder das Informationschaos. In diesem Kontext kann die \enquote{Entropie} in einem verteilten System als ein Zustand betrachtet werden, in dem verschiedene Repliken eines Datenelements unterschiedliche und inkonsistente Zustände aufweisen. Anti-Entropie-Verfahren wirken dieser \enquote{Entropie} entgegen, indem sie sicherstellen, dass alle Repliken eines Datenelements synchronisiert werden und den gleichen Zustand aufweisen.

Ein verbreitetes Anti-Entropie-Rpair-Verfahren ist das sogenannte \enquote{Read-Repair}. Wenn ein Knoten ein Datenelement liest und feststellt, dass seine Replik nicht mit anderen Repliken übereinstimmt, aktualisiert er seine Replik, um sie mit den anderen zu synchronisieren.

Ein weiteres Verfahren ist das \enquote{Anti-Entropy-Repair} (auch als \enquote{Anti-Entropy-Synchronisation} bezeichnet), bei dem Knoten periodisch oder auf Anforderung Paare von Repliken vergleichen und Unterschiede bereinigen. Dies kann zum Beispiel durch den Einsatz von Merkle-Bäumen geschehen, einer Datenstruktur, die effiziente Vergleiche und Synchronisationen ermöglicht.

Es ist wichtig zu beachten, dass Anti-Entropie-Verfahren in der Regel nicht sofortige Konsistenz garantieren, sondern stattdessen eine eventual consistency anstreben. Das bedeutet, dass es nach einem Update eine gewisse Zeit dauern kann, bis alle Repliken synchronisiert sind, aber das System schließlich einen konsistenten Zustand erreichen wird, vorausgesetzt es werden keine weiteren Updates vorgenommen.

In Systemen mit hohem Datenaufkommen und zahlreichen Schreiboperationen kann die Aufrechterhaltung der Konsistenz durch Anti-Entropie-Verfahren eine Herausforderung darstellen. Dies liegt daran, dass fortlaufende Schreiboperationen kontinuierlich neue Versionen der Daten erzeugen, was zu Inkonsistenzen zwischen den Repliken führen kann.

Ein weiterer wichtiger Aspekt von Anti-Entropie-Verfahren ist die Wahl des geeigneten Mechanismus zur Konfliktlösung. Bei der Synchronisation von Repliken können Konflikte auftreten, beispielsweise wenn zwei Knoten gleichzeitig unterschiedliche Updates auf die gleiche Datenreplik anwenden. Solche Konflikte müssen gelöst werden, um die Konsistenz zu gewährleisten. Es gibt verschiedene Strategien zur Konfliktlösung, darunter \enquote{last-writer-wins} (der Knoten, der das letzte Update durchgeführt hat, gewinnt den Konflikt) und \enquote{merge} (die Updates werden zusammengeführt, sofern dies möglich ist).

Anti-Entropie-Verfahren können auch durch die Wahl der Datenstruktur beeinflusst werden. Einige Datenstrukturen, wie beispielsweise konfliktfreie replizierte Datentypen (Conflict-free Replicated Data Types, CRDTs), sind speziell darauf ausgelegt, Anti-Entropie zu unterstützen und Konflikte zu vermeiden oder zu minimieren.

Schließlich ist es wichtig zu beachten, dass Anti-Entropie-Verfahren Ressourcen verbrauchen, einschließlich Netzwerkbandbreite und Rechenleistung. Daher ist es wichtig, sie sorgfältig zu planen und zu optimieren, um die Leistung und Effizienz des verteilten Systems zu maximieren.


\label{Woche10}	
\end{document}
